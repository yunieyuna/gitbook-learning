# 3. Understanding Data Types

### **3** **UNDERSTANDING DATA TYPES** <a href="#ch03" id="ch03"></a>

![image](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492067580/files/images/common01.jpg)

Whenever I dig into a new database, I check the _data type_ specified for each column in each table. If I’m lucky, I can get my hands on a _data dictionary_: a document that lists each column; specifies whether it’s a number, character, or other type; and explains the column values. Unfortunately, many organizations don’t create and maintain good documentation, so it’s not unusual to hear, “We don’t have a data dictionary.” In that case, I try to learn by inspecting the table structures in pgAdmin.

It’s important to understand data types because storing data in the appropriate format is fundamental to building usable databases and performing accurate analysis. In addition, a data type is a programming concept applicable to more than just SQL. The concepts you’ll explore in this chapter will transfer well to additional languages you may want to learn.

In a SQL database, each column in a table can hold one and only one data type, which is defined in the CREATE TABLE statement. You declare the data type after naming the column. Here’s a simple example that includes two columns, one a date and the other an integer:

CREATE TABLE eagle\_watch (\
&#x20;   observed\_date date,\
&#x20;   eagles\_seen integer\
);

In this table named eagle\_watch (for an annual inventory of bald eagles), the observed\_date column is declared to hold date values by adding the date type declaration after its name. Similarly, eagles\_seen is set to hold whole numbers with the integer type declaration.

These data types are among the three categories you’ll encounter most:

**Characters** Any character or symbol

**Numbers** Includes whole numbers and fractions

**Dates and times** Types holding temporal information

Let’s look at each data type in depth; I’ll note whether they’re part of standard ANSI SQL or specific to PostgreSQL.

#### Characters <a href="#lev31" id="lev31"></a>

_Character string types_ are general-purpose types suitable for any combination of text, numbers, and symbols. Character types include:

**char(**_**n**_**)**

A fixed-length column where the character length is specified by n. A column set at char(20) stores 20 characters per row regardless of how many characters you insert. If you insert fewer than 20 characters in any row, PostgreSQL pads the rest of that column with spaces. This type, which is part of standard SQL, also can be specified with the longer name character(n). Nowadays, char(n) is used infrequently and is mainly a remnant of legacy computer systems.

**varchar(**_**n**_**)**

A variable-length column where the _maximum_ length is specified by n. If you insert fewer characters than the maximum, PostgreSQL will not store extra spaces. For example, the string blue will take four spaces, whereas the string 123 will take three. In large databases, this practice saves considerable space. This type, included in standard SQL, also can be specified using the longer name character varying(n).

**text**

A variable-length column of unlimited length. (According to the PostgreSQL documentation, the longest possible character string you can store is about 1 gigabyte.) The text type is not part of the SQL standard, but you’ll find similar implementations in other database systems, including Microsoft SQL Server and MySQL.

According to PostgreSQL documentation at [_https://www.postgresql.org/docs/current/static/datatype-character.html_](https://www.postgresql.org/docs/current/static/datatype-character.html), there is no substantial difference in performance among the three types. That may differ if you’re using another database manager, so it’s wise to check the docs. The flexibility and potential space savings of varchar and text seem to give them an advantage. But if you search discussions online, some users suggest that defining a column that will always have the same number of characters with char is a good way to signal what data it should contain. For instance, you might use char(2) for U.S. state postal abbreviations.

To see these three character types in action, run the script in [Listing 3-1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03list1). This script will build and load a simple table and then export the data to a text file on your computer.

&#x20; CREATE TABLE char\_data\_types (\
&#x20;   ➊ varchar\_column varchar(10),\
&#x20;     char\_column char(10),\
&#x20;     text\_column text\
&#x20; );\
\
➋ INSERT INTO char\_data\_types\
&#x20; VALUES\
&#x20;     ('abc', 'abc', 'abc'),\
&#x20;     ('defghi', 'defghi', 'defghi');\
\
➌ COPY char\_data\_types TO '_C:\YourDirectory\\_typetest.txt'\
➍ WITH (FORMAT CSV, HEADER, DELIMITER '|');

_Listing 3-1: Character data types in action_

The script defines three character columns ➊ of different types and inserts two rows of the same string into each ➋. Unlike the INSERT INTO statement you learned in [Chapter 1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch01.xhtml#ch01), here we’re not specifying the names of the columns. If the VALUES statements match the number of columns in the table, the database will assume you’re inserting values in the order the column definitions were specified in the table.

Next, the script uses the PostgreSQL COPY keyword ➌ to export the data to a text file named typetest.txt in a directory you specify. You’ll need to replace C:\YourDirectory\ with the full path to the directory on your computer where you want to save the file. The examples in this book use Windows format and a path to a directory called YourDirectory on the C: drive. Linux and macOS file paths have a different format. On my Mac, the path to a file on the desktop is /Users/anthony/Desktop/. On Linux, my desktop is located at /home/anthony/Desktop/. The directory must exist already; PostgreSQL won’t create it for you.

In PostgreSQL, COPY table\_name FROM is the import function and COPY table\_name TO is the export function. I’ll cover them in depth in [Chapter 4](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch04.xhtml#ch04); for now, all you need to know is that the WITH keyword options ➍ will format the data in the file with each column separated by a _pipe_ character (|). That way, you can easily see where spaces fill out the unused portions of the char column.

To see the output, open _typetest.txt_ using a plain text editor (not Word or Excel, or another spreadsheet application). The contents should look like this:

varchar\_column|char\_column|text\_column\
abc|abc       |abc\
defghi|defghi    |defghi

Even though you specified 10 characters for both the varchar and char columns, only the char column outputs 10 characters every time, padding unused characters with spaces. The varchar and text columns store only the characters you inserted.

Again, there’s no real performance difference among the three types, although this example shows that char can potentially consume more storage space than needed. A few unused spaces in each column might seem negligible, but multiply that over millions of rows in dozens of tables and you’ll soon wish you had been more economical.

Typically, using varchar with an n value sufficient to handle outliers is a solid strategy.

#### Numbers <a href="#lev32" id="lev32"></a>

Number columns hold various types of (you guessed it) numbers, but that’s not all: they also allow you to perform calculations on those numbers. That’s an important distinction from numbers you store as strings in a character column, which can’t be added, multiplied, divided, or perform any other math operation. Also, as I discussed in [Chapter 2](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch02.xhtml#ch02), numbers stored as characters sort differently than numbers stored as numbers, arranging in text rather than numerical order. So, if you’re doing math or the numeric order is important, use number types.

The SQL number types include:

**Integers** Whole numbers, both positive and negative

**Fixed-point and floating-point** Two formats of fractions of whole numbers

We’ll look at each type separately.

_**Integers**_

The integer data types are the most common number types you’ll find when exploring data in a SQL database. Think of all the places integers appear in life: your street or apartment number, the serial number on your refrigerator, the number on a raffle ticket. These are _whole numbers_, both positive and negative, including zero.

The SQL standard provides three integer types: smallint, integer, and bigint. The difference between the three types is the maximum size of the numbers they can hold. [Table 3-1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03tab1) shows the upper and lower limits of each, as well as how much storage each requires in bytes.

**Table 3-1:** Integer Data Types

| **Data type** | **Storage size** | **Range**                                    |
| ------------- | ---------------- | -------------------------------------------- |
| smallint      | 2 bytes          | −32768 to +32767                             |
| integer       | 4 bytes          | −2147483648 to +2147483647                   |
| bigint        | 8 bytes          | −9223372036854775808 to +9223372036854775807 |

Even though it eats up the most storage, bigint will cover just about any requirement you’ll ever have with a number column. Its use is a must if you’re working with numbers larger than about 2.1 billion, but you can easily make it your go-to default and never worry. On the other hand, if you’re confident numbers will remain within the integer limit, that type is a good choice because it doesn’t consume as much space as bigint (a concern when dealing with millions of data rows).

When the data values will remain constrained, smallint makes sense: days of the month or years are good examples. The smallint type will use half the storage as integer, so it’s a smart database design decision if the column values will always fit within its range.

If you try to insert a number into any of these columns that is outside its range, the database will stop the operation and return an out of range error.

_**Auto-Incrementing Integers**_

In [Chapter 1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch01.xhtml#ch01), when you made the teachers table, you created an id column with the declaration of bigserial: this and its siblings smallserial and serial are not so much true data types as a special _implementation_ of the corresponding smallint, integer, and bigint types. When you add a column with a serial type, PostgreSQL will _auto-increment_ the value in the column each time you insert a row, starting with 1, up to the maximum of each integer type.

The serial types are implementations of the ANSI SQL standard for auto-numbered _identity columns_. Each database manager implements these in its own way. For example, Microsoft SQL Server uses an IDENTITY keyword to set a column to auto-increment.

To use a serial type on a column, declare it in the CREATE TABLE statement as you would an integer type. For example, you could create a table called people that has an id column in each row:

CREATE TABLE people (\
&#x20;   id serial,\
&#x20;   person\_name varchar(100)\
);

Every time a new person\_name is added to the table, the id column will increment by 1.

[Table 3-2](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03tab2) shows the serial types and the ranges they cover.

**Table 3-2:** Serial Data Types

| **Data type** | **Storage size** | **Range**                |
| ------------- | ---------------- | ------------------------ |
| smallserial   | 2 bytes          | 1 to 32767               |
| serial        | 4 bytes          | 1 to 2147483647          |
| bigserial     | 8 bytes          | 1 to 9223372036854775807 |

As with this example and in teachers in [Chapter 1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch01.xhtml#ch01), makers of databases often employ a serial type to create a unique ID number, also known as a key, for each row in the table. Each row then has its own ID that other tables in the database can reference. I’ll cover this concept of relating tables in [Chapter 6](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch06.xhtml#ch06). Because the column is auto-incrementing, you don’t need to insert a number into that column when adding data; PostgreSQL handles that for you.

**NOTE**

_Even though a column with a serial type auto-increments each time a row is added, some scenarios will create gaps in the sequence of numbers in the column. If a row is deleted, for example, the value in that row is never replaced. Or, if a row insert is aborted, the sequence for the column will still be incremented._

_**Decimal Numbers**_

As opposed to integers, _decimals_ represent a whole number plus a fraction of a whole number; the fraction is represented by digits following a _decimal point_. In a SQL database, they’re handled by _fixed-point_ and _floating-point_ data types. For example, the distance from my house to the nearest grocery store is 6.7 miles; I could insert 6.7 into either a fixed-point or floating-point column with no complaint from PostgreSQL. The only difference is how the computer stores the data. In a moment, you’ll see that has important implications.

**Fixed-Point Numbers**

The fixed-point type, also called the _arbitrary precision_ type, is numeric(precision,scale). You give the argument precision as the maximum number of digits to the left and right of the decimal point, and the argument scale as the number of digits allowable on the right of the decimal point. Alternately, you can specify this type using decimal(precision,scale). Both are part of the ANSI SQL standard. If you omit specifying a scale value, the scale will be set to zero; in effect, that creates an integer. If you omit specifying the precision and the scale, the database will store values of any precision and scale up to the maximum allowed. (That’s up to 131,072 digits before the decimal point and 16,383 digits after the decimal point, according to the PostgreSQL documentation at [_https://www.postgresql.org/docs/current/static/datatype-numeric.html_](https://www.postgresql.org/docs/current/static/datatype-numeric.html).)

For example, let’s say you’re collecting rainfall totals from several local airports—not an unlikely data analysis task. The U.S. National Weather Service provides this data with rainfall typically measured to two decimal places. (And, if you’re like me, you have a distant memory of your third-grade math teacher explaining that two digits after a decimal is the hundredths place.)

To record rainfall in the database using five digits total (the precision) and two digits maximum to the right of the decimal (the scale), you’d specify it as numeric(5,2). The database will always return two digits to the right of the decimal point, even if you don’t enter a number that contains two digits. For example, 1.47, 1.00, and 121.50.

**Floating-Point Types**

The two floating-point types are real and double precision. The difference between the two is how much data they store. The real type allows precision to six decimal digits, and double precision to 15 decimal points of precision, both of which include the number of digits on both sides of the point. These floating-point types are also called _variable-precision_ types. The database stores the number in parts representing the digits and an exponent—the location where the decimal point belongs. So, unlike numeric, where we specify fixed precision and scale, the decimal point in a given column can “float” depending on the number.

**Using Fixed- and Floating-Point Types**

Each type has differing limits on the number of total digits, or precision, it can hold, as shown in [Table 3-3](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03tab3).

**Table 3-3:** Fixed-Point and Floating-Point Data Types

| **Data type**    | **Storage size** | **Storage type** | **Range**                                                                                |
| ---------------- | ---------------- | ---------------- | ---------------------------------------------------------------------------------------- |
| numeric, decimal | variable         | Fixed-point      | Up to 131072 digits before the decimal point; up to 16383 digits after the decimal point |
| real             | 4 bytes          | Floating-point   | 6 decimal digits precision                                                               |
| double precision | 8 bytes          | Floating-point   | 15 decimal digits precision                                                              |

To see how each of the three data types handles the same numbers, create a small table and insert a variety of test cases, as shown in [Listing 3-2](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03list2):

&#x20; CREATE TABLE number\_data\_types (\
&#x20;   ➊ numeric\_column numeric(20,5),\
&#x20;     real\_column real,\
&#x20;     double\_column double precision\
&#x20; );\
➋ INSERT INTO number\_data\_types\
&#x20; VALUES\
&#x20;     (.7, .7, .7),\
&#x20;     (2.13579, 2.13579, 2.13579),\
&#x20;     (2.1357987654, 2.1357987654, 2.1357987654);\
\
&#x20; SELECT \* FROM number\_data\_types;

_Listing 3-2: Number data types in action_

We’ve created a table with one column for each of the fractional data types ➊ and loaded three rows into the table ➋. Each row repeats the same number across all three columns. When the last line of the script runs and we select everything from the table, we get the following:

numeric\_column    real\_column    double\_column\
\--------------    -----------    -------------\
&#x20;      0.70000            0.7              0.7\
&#x20;      2.13579        2.13579          2.13579\
&#x20;      2.13580         2.1358     2.1357987654

Notice what happened. The numeric column, set with a scale of five, stores five digits after the decimal point whether or not you inserted that many. If fewer than five, it pads the rest with zeros. If more than five, it rounds them—as with the third-row number with 10 digits after the decimal.

The real and double precision columns store only the number of digits present with no padding. Again on the third row, the number is rounded when inserted into the real column because that type has a maximum of six digits of precision. The double precision column can hold up to 15 digits, so it stores the entire number.

**Trouble with Floating-Point Math**

If you’re thinking, “Well, numbers stored as a floating-point look just like numbers stored as fixed,” tread cautiously. The way computers store floating-point numbers can lead to unintended mathematical errors. Look at what happens when we do some calculations on these numbers. Run the script in [Listing 3-3](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03list3).

&#x20; SELECT\
&#x20;   ➊ numeric\_column \* 10000000 AS "Fixed",\
&#x20;     real\_column  \* 10000000 AS "Float"\
&#x20; FROM number\_data\_types\
➋ WHERE numeric\_column = .7;

_Listing 3-3: Rounding issues with float columns_

Here, we multiply the numeric\_column and the real\_column by 10 million ➊ and use a WHERE clause to filter out just the first row ➋. We should get the same result for both calculations, right? Here’s what the query returns:

Fixed             Float\
\-------------     ----------------\
7000000.00000     6999999.88079071

Hello! No wonder floating-point types are referred to as “inexact.” It’s a good thing I’m not using this math to launch a mission to Mars or calculate the federal budget deficit.

The reason floating-point math produces such errors is that the computer attempts to squeeze lots of information into a finite number of bits. The topic is the subject of a lot of writings and is beyond the scope of this book, but if you’re interested, you’ll find the link to a good synopsis at [_https://www.nostarch.com/practicalSQL/_](https://www.nostarch.com/practicalSQL/).

The storage required by the numeric data type is variable, and depending on the precision and scale specified, numeric can consume considerably more space than the floating-point types. If you’re working with millions of rows, it’s worth considering whether you can live with relatively inexact floating-point math.

_**Choosing Your Number Data Type**_

For now, here are three guidelines to consider when you’re dealing with number data types:

1. Use integers when possible. Unless your data uses decimals, stick with integer types.
2. If you’re working with decimal data and need calculations to be exact (dealing with money, for example), choose numeric or its equivalent, decimal. Float types will save space, but the inexactness of floating-point math won’t pass muster in many applications. Use them only when exactness is not as important.
3. Choose a big enough number type. Unless you’re designing a database to hold millions of rows, err on the side of bigger. When using numeric or decimal, set the precision large enough to accommodate the number of digits on both sides of the decimal point. With whole numbers, use bigint unless you’re absolutely sure column values will be constrained to fit into the smaller integer or smallint types.

#### Dates and Times <a href="#lev41" id="lev41"></a>

Whenever you enter a date into a search form, you’re reaping the benefit of databases having an awareness of the current time (received from the server) plus the ability to handle formats for dates, times, and the nuances of the calendar, such as leap years and time zones. This is essential for storytelling with data, because the issue of _when_ something occurred is usually as valuable a question as who, what, or how many were involved.

PostgreSQL’s date and time support includes the four major data types shown in [Table 3-4](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03tab4).

**Table 3-4:** Date and Time Data Types

| **Data type** | **Storage size** | **Description** | **Range**             |
| ------------- | ---------------- | --------------- | --------------------- |
| timestamp     | 8 bytes          | Date and time   | 4713 BC to 294276 AD  |
| date          | 4 bytes          | Date (no time)  | 4713 BC to 5874897 AD |
| time          | 8 bytes          | Time (no date)  | 00:00:00 to 24:00:00  |
| interval      | 16 bytes         | Time interval   | +/− 178,000,000 years |

Here’s a rundown of data types for times and dates in PostgreSQL:

timestamp Records date and time, which are useful for a range of situations you might track: departures and arrivals of passenger flights, a schedule of Major League Baseball games, or incidents along a timeline. Typically, you’ll want to add the keywords with time zone to ensure that the time recorded for an event includes the time zone where it occurred. Otherwise, times recorded in various places around the globe become impossible to compare. The format timestamp with time zone is part of the SQL standard; with PostgreSQL you can specify the same data type using timestamptz.

date Records just the date.

time Records just the time. Again, you’ll want to add the with time zone keywords.

interval Holds a value representing a unit of time expressed in the format quantity unit. It doesn’t record the start or end of a time period, only its length. Examples include 12 days or 8 hours. (The PostgreSQL documentation at [_https://www.postgresql.org/docs/current/static/datatype-datetime.html_](https://www.postgresql.org/docs/current/static/datatype-datetime.html) lists unit values ranging from microsecond to millennium.) You’ll typically use this type for calculations or filtering on other date and time columns.

Let’s focus on the timestamp with time zone and interval types. To see these in action, run the script in [Listing 3-4](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03list4).

➊ CREATE TABLE date\_time\_types (\
&#x20;   timestamp\_column timestamp with time zone,\
&#x20;   interval\_column interval\
&#x20; );\
➋ INSERT INTO date\_time\_types\
&#x20; VALUES\
&#x20;     ('2018-12-31 01:00 EST','2 days'),\
&#x20;     ('2018-12-31 01:00 -8','1 month'),\
&#x20;     ('2018-12-31 01:00 Australia/Melbourne','1 century'),\
&#x20;   ➌ (now(),'1 week');\
\
&#x20; SELECT \* FROM date\_time\_types;

_Listing 3-4: The timestamp and interval types in action_

Here, we create a table with a column for both types ➊ and insert four rows ➋. For the first three rows, our insert for the timestamp\_column uses the same date and time (December 31, 2018 at 1 AM) using the International Organization for Standardization (ISO) format for dates and times: YYYY-MM-DD HH:MM:SS. SQL supports additional date formats (such as MM/DD/YYYY), but ISO is recommended for portability worldwide.

Following the time, we specify a time zone but use a different format in each of the first three rows: in the first row, we use the abbreviation EST, which is Eastern Standard Time in the United States.

In the second row, we set the time zone with the value -8. That represents the number of hours difference, or _offset_, from Coordinated Universal Time (UTC). UTC refers to an overall world time standard as well as the value of UTC +/− 00:00, the time zone that covers the United Kingdom and Western Africa. (For a map of UTC time zones, see [_https://en.wikipedia.org/wiki/Coordinated\_Universal\_Time#/media/File:Standard\_World\_Time\_Zones.png_](https://en.wikipedia.org/wiki/Coordinated\_Universal\_Time#/media/File:Standard\_World\_Time\_Zones.png).) Using a value of -8 specifies a time zone eight hours behind UTC, which is the Pacific time zone in the United States and Canada.

For the third row, we specify the time zone using the name of an area and location: Australia/Melbourne. That format uses values found in a standard time zone database often employed in computer programming. You can learn more about the time zone database at [_https://en.wikipedia.org/wiki/Tz\_database_](https://en.wikipedia.org/wiki/Tz\_database).

In the fourth row, instead of specifying dates, times, and time zones, the script uses PostgreSQL’s now() function ➌, which captures the current transaction time from your hardware.

After the script runs, the output should look similar to (but not exactly like) this:

timestamp\_column                 interval\_column\
\-----------------------------    ---------------\
2018-12-31 01:00:00-05           2 days\
2018-12-31 04:00:00-05           1 mon\
2018-12-30 09:00:00-05           100 years\
2019-01-25 21:31:15.716063-05    7 days

Even though we supplied the same date and time in the first three rows on the timestamp\_column, each row’s output differs. The reason is that pgAdmin reports the date and time relative to my time zone, which in the results shown is indicated by the UTC offset of -05 at the end of each timestamp. A UTC offset of -05 means five hours behind UTC time, equivalent to the U.S. Eastern time zone, where I live. If you live in a different time zone, you’ll likely see a different offset; the times and dates also may differ from what’s shown here. We can change how PostgreSQL reports these timestamp values, and I’ll cover how to do that plus other tips for wrangling dates and times in [Chapter 11](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch11.xhtml#ch11).

Finally, the interval\_column shows the values you entered. PostgreSQL changed 1 century to 100 years and 1 week to 7 days because of its preferred default settings for interval display. Read the “Interval Input” section of the PostgreSQL documentation at [_https://www.postgresql.org/docs/current/static/datatype-datetime.html_](https://www.postgresql.org/docs/current/static/datatype-datetime.html) to learn more about options related to intervals.

#### Using the interval Data Type in Calculations <a href="#lev42" id="lev42"></a>

The interval data type is useful for easy-to-understand calculations on date and time data. For example, let’s say you have a column that holds the date a client signed a contract. Using interval data, you can add 90 days to each contract date to determine when to follow up with the client.

To see how the interval data type works, we’ll use the date\_time\_types table we just created, as shown in [Listing 3-5](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03list5):

SELECT\
&#x20;   timestamp\_column\
&#x20;   interval\_column,\
&#x20; ➊ timestamp\_column - interval\_column AS new\_date\
FROM date\_time\_types;

_Listing 3-5: Using the interval data type_

This is a typical SELECT statement except we’ll compute a column called new\_date ➊ that contains the result of timestamp\_column minus interval\_column. (Computed columns are called _expressions_; we’ll use this technique often.) In each row, we subtract the unit of time indicated by the interval data type from the date. This produces the following result:

![image](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492067580/files/images/prog\_page\_34.jpg)

Note that the new\_date column by default is formatted as type timestamp with time zone, allowing for the display of time values as well as dates if the interval value uses them. Again, your output may be different based on your time zone.

#### Miscellaneous Types <a href="#lev43" id="lev43"></a>

The character, number, and date/time types you’ve learned so far will likely comprise the bulk of the work you do with SQL. But PostgreSQL supports many additional types, including but not limited to:

* A Boolean type that stores a value of true or false
* Geometric types that include points, lines, circles, and other two-dimensional objects
* Network address types, such as IP or MAC addresses
* A Universally Unique Identifier (UUID) type, sometimes used as a unique key value in tables
* XML and JSON data types that store information in those structured formats

I’ll cover these types as required throughout the book.

#### Transforming Values from One Type to Another with CAST <a href="#lev44" id="lev44"></a>

Occasionally, you may need to transform a value from its stored data type to another type; for example, when you retrieve a number as a character so you can combine it with text or when you must treat a date stored as characters as an actual date type so you can sort it in date order or perform interval calculations. You can perform these conversions using the CAST() function.

The CAST() function only succeeds when the target data type can accommodate the original value. Casting an integer as text is possible, because the character types can include numbers. Casting text with letters of the alphabet as a number is not.

[Listing 3-6](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03list6) has three examples using the three data type tables we just created. The first two examples work, but the third will try to perform an invalid type conversion so you can see what a type casting error looks like.

➊ SELECT timestamp\_column, CAST(timestamp\_column AS varchar(10))\
&#x20; FROM date\_time\_types;\
\
➋ SELECT numeric\_column,\
&#x20;        CAST(numeric\_column AS integer),\
&#x20;        CAST(numeric\_column AS varchar(6))\
&#x20; FROM number\_data\_types;\
\
➌ SELECT CAST(char\_column AS integer) FROM char\_data\_types;

_Listing 3-6: Three CAST() examples_

The first SELECT statement ➊ returns the timestamp\_column value as a varchar, which you’ll recall is a variable-length character column. In this case, I’ve set the character length to 10, which means when converted to a character string, only the first 10 characters are kept. That’s handy in this case, because that just gives us the date segment of the column and excludes the time. Of course, there are better ways to remove the time from a timestamp, and I’ll cover those in [“Extracting the Components of a timestamp Value”](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch11.xhtml#lev170) on [page 173](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch11.xhtml#page\_173).

The second SELECT statement ➋ returns the numeric\_column three times: in its original form and then as an integer and as a character. Upon conversion to an integer, PostgreSQL rounds the value to a whole number. But with the varchar conversion, no rounding occurs: the value is simply sliced at the sixth character.

The final SELECT doesn’t work ➌: it returns an error of invalid input syntax for integer because letters can’t become integers!

#### CAST Shortcut Notation <a href="#lev45" id="lev45"></a>

It’s always best to write SQL that can be read by another person who might pick it up later, and the way CAST() is written makes what you intended when you used it fairly obvious. However, PostgreSQL also offers a less-obvious shortcut notation that takes less space: the _double colon_.

Insert the double colon in between the name of the column and the data type you want to convert it to. For example, these two statements cast timestamp\_column as a varchar:

SELECT timestamp\_column, CAST(timestamp\_column AS varchar(10))\
FROM date\_time\_types;\
\
SELECT timestamp\_column::varchar(10)\
FROM date\_time\_types;

Use whichever suits you, but be aware that the double colon is a PostgreSQL-only implementation not found in other SQL variants.

#### Wrapping Up <a href="#lev46" id="lev46"></a>

You’re now equipped to better understand the nuances of the data formats you encounter while digging into databases. If you come across monetary values stored as floating-point numbers, you’ll be sure to convert them to decimals before performing any math. And you’ll know how to use the right kind of text column to keep your database from growing too big.

Next, I’ll continue with SQL foundations and show you how to import external data into your database.

**TRY IT YOURSELF**

Continue exploring data types with these exercises:

1. Your company delivers fruit and vegetables to local grocery stores, and you need to track the mileage driven by each driver each day to a tenth of a mile. Assuming no driver would ever travel more than 999 miles in a day, what would be an appropriate data type for the mileage column in your table? Why?
2. In the table listing each driver in your company, what are appropriate data types for the drivers’ first and last names? Why is it a good idea to separate first and last names into two columns rather than having one larger name column?
3. Assume you have a text column that includes strings formatted as dates. One of the strings is written as '4//2017'. What will happen when you try to convert that string to the timestamp data type?
