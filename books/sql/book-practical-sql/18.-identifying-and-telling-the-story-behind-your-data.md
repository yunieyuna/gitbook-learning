# 18. Identifying And Telling The Story Behind Your Data

### **18** **IDENTIFYING AND TELLING THE STORY BEHIND YOUR DATA** <a href="#ch18" id="ch18"></a>

![image](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492067580/files/images/common01.jpg)

Although learning SQL can be fun in and of itself, it serves a greater purpose: it helps uncover the hidden stories in your data. As you learned in this book, SQL gives you the tools to find interesting trends, insights, or anomalies in your data and then make smart decisions based on what you’ve learned. But how do you identify these trends just from a collection of rows and columns? And how can you glean meaningful insights from these trends after identifying them?

Identifying trends in your data set and creating a narrative of your findings sometimes requires considerable experimentation and enough fortitude to weather the occasional dead end. In this chapter, I outline a process I’ve used as an investigative journalist to discover stories in data and communicate my findings. I start with how to generate ideas by asking good questions as well as gathering and exploring data. Then I explain the analysis process, which culminates in presenting your findings clearly. These tips are less of a checklist and more of a general guideline that can help you avoid certain mistakes.

#### Start with a Question <a href="#lev318" id="lev318"></a>

Curiosity, intuition, or sometimes just dumb luck can often spark ideas for data analysis. If you’re a keen observer of your surroundings, you might notice changes in your community over time and wonder if you can measure that change. Consider your local real estate market as an example. If you see more “For Sale” signs popping up around town than usual, you might start asking questions. Is there a dramatic increase in home sales this year compared to last year? If so, by how much? Which neighborhoods are affected? These questions create a great opportunity for data analysis. If you’re a journalist, you might find a story. If you run a business, you might discover a new marketing opportunity.

Likewise, if you surmise that a trend is occurring in your industry, confirming it might provide you with a business opportunity. For example, if you suspect that sales of a particular product have become sluggish, you can use data analysis to confirm the hunch and adjust inventory or marketing efforts appropriately.

Keep track of these ideas and prioritize them according to their potential value. Analyzing data to satisfy your curiosity is perfectly fine, but if the answers can make your institution more effective or your company more profitable, that’s a sign they’re worth pursuing.

#### Document Your Process <a href="#lev319" id="lev319"></a>

Before you delve into analysis, consider how to make your process transparent and reproducible. For the sake of credibility, others in your organization as well as those outside it should be able to reproduce your work. In addition, make sure you document enough information so that if you set the project aside for several weeks, you won’t have a problem picking it up again.

There isn’t one right way to document your work. Taking notes on research or creating step-by-step SQL queries that another person could use to replicate your data import, cleaning, and analysis can make it easier for others to verify your findings. Some analysts store notes and code in a text file. Others use version control systems, such as GitHub. The important factor is that you create your own system of documentation and use it consistently.

#### Gather Your Data <a href="#lev320" id="lev320"></a>

After you’ve hatched an idea for analysis, the next step is to find data that relates to the trend or question. If you’re working in an organization that already has its own data on the topic, lucky you—you’re set! In that case, you might be able to tap into internal marketing or sales databases, customer relationship management (CRM) systems, or subscriber or event registration data. But if your topic encompasses broader issues involving demographics, the economy, or industry-specific subjects, you’ll need to do some digging.

A good place to start is to ask experts about the sources they use. Analysts, government decision-makers, and academics can often point you to available data and its usefulness. Federal, state, and local governments, as you’ve seen throughout the book, produce volumes of data on all kinds of topics. In the United States, check out the federal government’s data catalog site at [_https://www.data.gov/_](https://www.data.gov/) or individual agency sites, such as the National Center for Education Statistics (NCES) at [_https://nces.ed.gov/_](https://nces.ed.gov/).

You can also browse local government websites. Any time you see a form for users to fill out or a report formatted in rows and columns, those are signs that structured data might be available for analysis. But all is not lost if you only have access to unstructured data. As you learned in [Chapter 13](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch13.xhtml#ch13), you can even mine unstructured data, such as text files.

If the data you want to analyze was collected over multiple years, I recommend examining five or 10 years, or more, instead of just one or two, if possible. Although analyzing a snapshot of data collected over a month or a year can yield interesting results, many trends play out over a longer period of time and may not be evident if you look at a single year of data. I discuss this further in [“Identify Key Indicators and Trends over Time”](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch18.xhtml#lev325) on [page 329](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch18.xhtml#page\_329).

#### No Data? Build Your Own Database <a href="#lev321" id="lev321"></a>

Sometimes, no one has the data you need in a format you can use. But if you have time, patience, and a methodology, you might be able to build your own data set. That is what my _USA TODAY_ colleague, Robert Davis, and I did when we wanted to study issues related to the deaths of college students on campuses in the United States. Not a single organization—not the schools or state or federal officials—could tell us how many college students were dying each year from accidents, overdoses, or illnesses on campus. We decided to collect our own data and structure the information into tables in a database.

We started by researching news articles, police reports, and lawsuits related to student deaths. After finding reports of more than 600 student deaths from 2000 to 2005, we followed up with interviews with education experts, police, school officials, and parents. From each report, we cataloged details such as each student’s age, school, cause of death, year in school, and whether drugs or alcohol played a role. Our findings led to the publication of the article “In College, First Year Is by Far the Riskiest” in _USA TODAY_ in 2006. The story featured the key finding from the analysis of our SQL database: freshmen were particularly vulnerable and accounted for the highest percentage of the student deaths we studied.

You too can create a database if you lack the data you need. The key is to identify the pieces of information that matter, and then systematically collect them.

#### Assess the Data’s Origins <a href="#lev322" id="lev322"></a>

After you’ve identified a data set, find as much information about its origins and maintenance methods as you can. Governments and institutions gather data in all sorts of ways, and some methods produce data that is more credible and standardized than others.

For example, you’ve already seen that USDA food producer data includes the same company names spelled in multiple ways. It’s worth knowing why. (Perhaps the data is manually copied from a written form to a computer.) Similarly, the New York City taxi data you analyzed in [Chapter 11](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch11.xhtml#ch11) records the start and end times of each trip. This begs the question, does the timer start when the passenger gets in and out of the vehicle, or is there some other trigger? You should know these details not only to draw better conclusions from analysis but also to pass them along to others who might be interpreting your analysis.

The origins of a data set might also affect how you analyze the data and report your findings. For example, with U.S. Census data, it’s important to know that the Decennial Census conducted every 10 years is a complete count of the population, whereas the American Community Survey (ACS) is drawn from only a sample of households. As a result, ACS counts have a margin of error, but the Decennial Census doesn’t. It would be irresponsible to report on the ACS without considering how the margin of error could make differences between numbers insignificant.

#### Interview the Data with Queries <a href="#lev323" id="lev323"></a>

Once you have your data, understand its origins, and have loaded it into your database, you can explore it with queries. Throughout the book, I call this step “interviewing data,” which is what you should do to find out more about the contents of your data and whether they contain any red flags.

A good place to start is with aggregates. Counts, sums, sorting, and grouping by column values should reveal minimum and maximum values, potential issues with duplicate entries, and a sense of the general scope of your data. If your database contains multiple, related tables, try joins to make sure you understand how the tables relate. Using LEFT JOIN and RIGHT JOIN, as you learned in [Chapter 6](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch06.xhtml#ch06), should show whether key values from one table are missing in another. That may or may not be a concern, but at least you’ll be able to identify potential problems you might want to address. Jot down a list of questions or concerns you have, and then move on to the next step.

#### Consult the Data’s Owner <a href="#lev324" id="lev324"></a>

After exploring your database and forming early conclusions about the quality and trends you observed, take some time to bring any questions or concerns you have to a person who knows the data well. That person could work at the agency or firm that gave you the data, or the person might be an analyst who has worked with the data before. This step is your chance to clarify your understanding of the data, verify initial findings, and discover whether the data has any issues that make it unsuitable for your needs.

For example, if you’re querying a table and notice values in columns that seem to be gross outliers (such as dates in the future for events that were supposed to have happened in the past), you should ask about that discrepancy. Or, if you expect to find someone’s name in a table (perhaps even your own name), and it’s not there, that should prompt another question. Is it possible you don’t have the whole data set, or is there a problem with data collection?

The goal is to get expert help to do the following:

* **Understand the limits of the data.** Make sure you know what the data includes, what it excludes, and any caveats about content that might affect how you perform your analysis.
* **Make sure you have a complete data set.** Verify that you have all the records you should expect to see and that if any data is missing, you understand why.
* **Determine whether the data set suits your needs.** Consider looking elsewhere for more reliable data if your source acknowledges problems with the data’s quality.

Every data set and situation is unique, but consulting another user or owner of the data can help you avoid unnecessary missteps.

#### Identify Key Indicators and Trends over Time <a href="#lev325" id="lev325"></a>

When you’re satisfied that you understand the data and are confident in its trustworthiness, completeness, and appropriateness to your analysis, the next step is to run queries to identify key indicators and, if possible, trends over time.

Your goal is to unearth data that you can summarize in a sentence or present as a slide in a presentation. An example finding would be something like this: “After five years of declines, the number of people enrolling in Widget University has increased by 5 percent for two consecutive semesters.”

To identify this type of trend, you’ll follow a two-step process:

1. Choose an indicator to track. In U.S. Census data, it might be the percentage of the population that is over age 60. Or in the New York City taxi data, it could be the median number of weekday trips over the span of one year.
2. Track that indicator over multiple years to see how it has changed, if at all.

In fact, these are the steps we used in [Chapter 6](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch06.xhtml#ch06) to apply percent change calculations to multiple years of census data contained in joined tables. In that case, we looked at the change in population in counties between 2000 and 2010. The population count was the key indicator, and the percent change showed the trend over the 10-year span for each county.

One caveat about measuring change over time: even when you see a dramatic change between any two years, it’s worth digging into as many years’ worth of data as possible to understand the shorter-term change in the context of a long-term trend. Although a year-to-year change might seem dramatic, seeing it in context of multiyear activity can help you assess its true significance.

For example, the U.S. National Center for Health Statistics releases data on the number of babies born each year. As a data nerd, I like to keep tabs on indicators like these, because births often reflect broader trends in culture or the economy. [Figure 18-1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch18.xhtml#ch18fig1) shows the annual number of births from 1910 to 2016.

![image](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492067580/files/images/f0330-01.jpg)

_Figure 18-1: U.S. births from 1910 to 2016. Source: U.S. National Center for Health Statistics_

Looking at only the last five years of this graph (shaded in gray), we see that the number of births hovered steadily at approximately 3.9 million with small decreases in the last two years. Although the recent drops seem noteworthy (likely reflecting continuing decreases in birth rates for teens and women in their 20s), in the long-term context, they’re less interesting given that the number of births has remained near or over 4 million for the last 20 years. In fact, U.S. births have seen far more dramatic increases and decreases. One example you can see in [Figure 18-1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch18.xhtml#ch18fig1) is the major rise in the mid-1940s following World War II, which signaled the start of the Baby Boom generation.

By identifying key indicators and looking at change over time, both short term and long term, you might uncover one or more findings worth presenting to others or acting on.

**NOTE**

_Any time you work with data from a survey, poll, or other sample, it’s important to test for statistical significance. Are the results actually a trend or just the result of chance? Significance testing is a statistical concept beyond the scope of this book but one that data analysts should know. See the Appendix for PostgreSQL resources for advanced statistics._

#### Ask Why <a href="#lev326" id="lev326"></a>

Data analysis can tell you what happened, but it doesn’t usually indicate why something happened. To learn why something happened, it’s worth revisiting the data with experts in the topic or the owners of the data. In the U.S. births data, it’s easy to calculate year-to-year percent change from those numbers. But the data doesn’t tell us why births steadily increased from the early 1980s to 1990. For that information, you might need to consult a demographer who would most likely explain that the rise in births during those years coincided with more Baby Boomers entering their childbearing years.

When you share your findings and methodology with experts, ask them to note anything that seems unlikely or worthy of further examination. For the findings they can corroborate, ask them to help you understand the forces behind those findings. If they’re willing to be cited, you can use their comments to supplement your report or presentation. This is a standard approach journalists often use to quote experts’ reactions to data trends.

#### Communicate Your Findings <a href="#lev327" id="lev327"></a>

How you share the results of your analysis depends on your role. A student might present their results in a paper or dissertation. A person who works in a corporate setting might present their findings using PowerPoint, Keynote, or Google Slides. A journalist might write a story or produce a data visualization. Regardless of the end product, here are my tips for presenting the information well (using a fictional home sales analysis as an example):

* **Identify an overarching theme based on your findings.** Make the theme the title of your presentation, paper, or visualization. For example, for a presentation on real estate, you might use, “Home sales rise in suburban neighborhoods, fall in cities.”
* **Present overall numbers to show the general trend.** Highlight the key findings from your analysis. For example, “All suburban neighborhoods saw sales up 5 percent each of the last two years, reversing three years of declines. Meanwhile, city neighborhoods saw a decline of 2 percent.”
* **Highlight specific examples that support the trend.** Describe one or two relevant cases. For example, “In Smithtown, home sales increased 15 percent following the relocation of XYZ Corporation’s headquarters last year.”
* **Acknowledge examples counter to the overall trend.** Use one or two relevant cases here as well. For example, “Two city neighborhoods did show growth in home sales: Arvis (up 4.5 percent) and Zuma (up 3 percent).”
* **Stick to the facts.** Avoid distorting or exaggerating any findings.
* **Provide expert opinion.** Use quotes or citations.
* **Visualize numbers using bar charts or line charts.** Tables are helpful for giving your audience specific numbers, but it’s easier to understand trends from a visualization.
* **Cite the source of the data and what your** **analysis includes or omits.** Provide dates covered, the name of the provider, and any distinctions that affect the analysis. For example, “Based on Walton County tax filings in 2015 and 2016. Excludes commercial properties.”
* **Share your data.** Post data online for download, including the queries you used. Nothing says transparency more than sharing the data you analyzed with others so they can perform their own analysis and corroborate your findings.

Generally, a short presentation that communicates your findings clearly and succinctly, and then invites dialogue from your audience thereafter, works best. Of course, you can follow your own preferred pattern for working with data and presenting your conclusions. But over the years, these steps have helped me avoid bad data and mistaken assumptions.

#### Wrapping Up <a href="#lev328" id="lev328"></a>

At last, you’ve reached the end of our practical exploration of SQL! Thank you for reading this book, and I welcome your suggestions and feedback on my website at [_https://www.anthonydebarros.com/contact/_](https://www.anthonydebarros.com/contact/). At the end of this book is an appendix that lists additional PostgreSQL-related tools you might want to try.

I hope you’ve come away with data analysis skills you can start using immediately on the data you encounter. More importantly, I hope you’ve seen that each data set has a story, or several stories, to tell. Identifying and telling these stories is what makes working with data worthwhile; it’s more than just combing through a collection of rows and columns. I look forward to hearing about what you discover!

**TRY IT YOURSELF**

It’s your turn to find and tell a story using the SQL techniques we’ve covered. Using the process outlined in this chapter, consider a local or national topic and search for available data. Assess its quality, the questions it might answer, and its timeliness. Consult with an expert who knows the data and the topic well. Load the data into PostgreSQL and interview it using aggregate queries and filters. What trends can you discover? Summarize your findings in a short presentation.
