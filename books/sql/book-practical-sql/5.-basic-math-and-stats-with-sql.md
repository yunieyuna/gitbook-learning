# 5. Basic Math And Stats With SQL

### **5** **BASIC MATH AND STATS WITH SQL** <a href="#ch05" id="ch05"></a>

![image](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492067580/files/images/common01.jpg)

If your data includes any of the number data types we explored in [Chapter 3](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#ch03)—integers, decimals, or floating points—sooner or later your analysis will include some calculations. For example, you might want to know the average of all the dollar values in a column, or add values in two columns to produce a total for each row. SQL handles calculations ranging from basic math through advanced statistics.

In this chapter, I’ll start with the basics and progress to math functions and beginning statistics. I’ll also discuss calculations related to percentages and percent change. For several of the exercises, we’ll use the 2010 Decennial Census data you imported in [Chapter 4](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch04.xhtml#ch04).

#### Math Operators <a href="#lev63" id="lev63"></a>

Let’s start with the basic math you learned in grade school (and all’s forgiven if you’ve forgotten some of it). [Table 5-1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05tab1) shows nine math operators you’ll use most often in your calculations. The first four (addition, subtraction, multiplication, and division) are part of the ANSI SQL standard that are implemented in all database systems. The others are PostgreSQL-specific operators, although if you’re using another database, it likely has functions or operators to perform those operations. For example, the modulo operator (%) works in Microsoft SQL Server and MySQL as well as with PostgreSQL. If you’re using another database system, check its documentation.

**Table 5-1:** Basic Math Operators

| **Operator** | **Description**                                    |
| ------------ | -------------------------------------------------- |
| +            | Addition                                           |
| -            | Subtraction                                        |
| \*           | Multiplication                                     |
| /            | Division (returns the quotient only, no remainder) |
| %            | Modulo (returns just the remainder)                |
| ^            | Exponentiation                                     |
| \|/          | Square root                                        |
| \|\|/        | Cube root                                          |
| !            | Factorial                                          |

We’ll step through each of these operators by executing simple SQL queries on plain numbers rather than operating on a table or another database object. You can either enter the statements separately into the pgAdmin query tool and execute them one at a time, or if you copied the code for this chapter from the resources at [_https://www.nostarch.com/practicalSQL/_](https://www.nostarch.com/practicalSQL/), you can highlight each line before executing it.

_**Math and Data Types**_

As you work through the examples, note the data type of each result, which is listed beneath each column name in the pgAdmin results grid. The type returned for a calculation will vary depending on the operation and the data type of the input numbers.

In calculations with an operator between two numbers—addition, subtraction, multiplication, and division—the data type returned follows this pattern:

* Two integers return an integer.
* A numeric on either side of the operator returns a numeric.
* Anything with a floating-point number returns a floating-point number of type double precision.

However, the exponentiation, root, and factorial functions are different. Each takes one number either before or after the operator and returns numeric and floating-point types, even when the input is an integer.

Sometimes the result’s data type will suit your needs; other times, you may need to use CAST to change the data type, as mentioned in [“Transforming Values from One Type to Another with CAST”](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#lev44) on [page 35](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch03.xhtml#page\_35), such as if you need to feed the result into a function that takes a certain type. I’ll note those times as we work through the book.

_**Adding, Subtracting, and Multiplying**_

Let’s start with simple integer addition, subtraction, and multiplication. [Listing 5-1](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list1) shows three examples, each with the SELECT keyword followed by the math formula. Since [Chapter 2](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch02.xhtml#ch02), we’ve used SELECT for its main purpose: to retrieve data from a table. But with PostgreSQL, Microsoft’s SQL Server, MySQL, and some other database management systems, it’s possible to omit the table name for math and string operations while testing, as we do here. For readability’s sake, I recommend you use a single space before and after the math operator; although using spaces isn’t strictly necessary for your code to work, it is good practice.

➊ SELECT 2 + 2;\
➋ SELECT 9 - 1;\
➌ SELECT 3 \* 4;

_Listing 5-1: Basic addition, subtraction, and multiplication with SQL_

None of these statements are rocket science, so you shouldn’t be surprised that running SELECT 2 + 2; ➊ in the query tool shows a result of 4. Similarly, the examples for subtraction ➋ and multiplication ➌ yield what you’d expect: 8 and 12. The output displays in a column, as with any query result. But because we’re not querying a table and specifying a column, the results appear beneath a ?column? name, signifying an unknown column:

?column?\
\--------\
&#x20;      4

That’s okay. We’re not affecting any data in a table, just displaying a result.

_**Division and Modulo**_

Division with SQL gets a little trickier because of the difference between math with integers and math with decimals, which was mentioned earlier. Add in _modulo_, an operator that returns just the _remainder_ in a division operation, and the results can be confusing. So, to make it clear, [Listing 5-2](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list2) shows four examples:

➊ SELECT 11 / 6;\
➋ SELECT 11 % 6;\
➌ SELECT 11.0 / 6;\
➍ SELECT CAST (11 AS numeric(3,1)) / 6;

_Listing 5-2: Integer and decimal division with SQL_

The first statement uses the / operator ➊ to divide the integer 11 by another integer, 6. If you do that math in your head, you know the answer is 1 with a remainder of 5. However, running this query yields 1, which is how SQL handles division of one integer by another—by reporting only the integer _quotient_. If you want to retrieve the _remainder_ as an integer, you must perform the same calculation using the modulo operator %, as in ➋. That statement returns just the remainder, in this case 5. No single operation will provide you with both the quotient and the remainder as integers.

Modulo is useful for more than just fetching a remainder: you can also use it as a test condition. For example, to check whether a number is even, you can test it using the % 2 operation. If the result is 0 with no remainder, the number is even.

If you want to divide two numbers and have the result return as a numeric type, you can do so in two ways: first, if one or both of the numbers is a numeric, the result will by default be expressed as a numeric. That’s what happens when I divide 11.0 by 6 ➌. Execute that query, and the result is 1.83333. The number of decimal digits displayed may vary according to your PostgreSQL and system settings.

Second, if you’re working with data stored only as integers and need to force decimal division, you can CAST one of the integers to a numeric type ➍. Executing this again returns 1.83333.

_**Exponents, Roots, and Factorials**_

Beyond the basics, PostgreSQL-flavored SQL also provides operators to square, cube, or otherwise raise a base number to an exponent, as well as find roots or the factorial of a number. [Listing 5-3](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list3) shows these operations in action:

➊ SELECT 3 ^ 4;\
➋ SELECT |/ 10;\
&#x20; SELECT sqrt(10);\
➌ SELECT ||/ 10;\
➍ SELECT 4 !;

_Listing 5-3: Exponents, roots, and factorials with SQL_

The exponentiation operator (^) allows you to raise a given base number to an exponent, as in ➊, where 3 ^ 4 (colloquially, we’d call that three to the fourth power) returns 81.

You can find the square root of a number in two ways: using the |/ operator ➋ or the sqrt(n) function. For a cube root, use the ||/ operator ➌. Both are _prefix operators_, named because they come before a single value.

To find the _factorial_ of a number, use the ! operator. It’s a _suffix operator_, coming after a single value. You’ll use factorials in many places in math, but perhaps the most common is to determine how many ways a number of items can be ordered. Say you have four photographs. How many ways could you order them next to each other on a wall? To find the answer, you’d calculate the factorial by starting with the number of items and multi­plying all the smaller positive integers. So, at ➍, the factorial statement of 4 ! is equivalent to 4 × 3 × 2 × 1. That’s 24 ways to order four photos. No wonder decorating takes so long sometimes!

Again, these operators are specific to PostgreSQL; they’re not part of the SQL standard. If you’re using another database application, check its documentation for how it implements these operations.

_**Minding the Order of Operations**_

Can you recall from your earliest math lessons what the order of operations, or _operator precedence_, is on a mathematical expression? When you string together several numbers and operators, which calculations does SQL execute first? Not surprisingly, SQL follows the established math standard. For the PostgreSQL operators discussed so far, the order is:

1. Exponents and roots
2. Multiplication, division, modulo
3. Addition and subtraction

Given these rules, you’ll need to encase an operation in parentheses if you want to calculate it in a different order. For example, the following two expressions yield different results:

SELECT 7 + 8 \* 9;\
SELECT (7 + 8) \* 9;

The first expression returns 79 because the multiplication operation receives precedence and is processed before the addition. The second returns 135 because the parentheses force the addition operation to occur first.

Here’s a second example using exponents:

SELECT 3 ^ 3 - 1;\
SELECT 3 ^ (3 - 1);

Exponent operations take precedence over subtraction, so without parentheses the entire expression is evaluated left to right and the operation to find 3 to the power of 3 happens first. Then 1 is subtracted, returning 26. In the second example, the parentheses force the subtraction to happen first, so the operation results in 9, which is 3 to the power of 2.

Keep operator precedence in mind to avoid having to correct your analysis later!

#### Doing Math Across Census Table Columns <a href="#lev69" id="lev69"></a>

Let’s try to use the most frequently used SQL math operators on real data by digging into the 2010 Decennial Census population table, us\_counties\_2010, that you imported in [Chapter 4](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch04.xhtml#ch04). Instead of using numbers in queries, we’ll use the names of the columns that contain the numbers. When we execute the query, the calculation will occur on each row of the table.

To refresh your memory about the data, run the script in [Listing 5-4](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list4). It should return 3,143 rows showing the name and state of each county in the United States, and the number of people who identified with one of six race categories or a combination of two or more races.

The 2010 Census form received by each household—the so-called “short form”—allowed people to check either just one or multiple boxes under the question of race. (You can review the form at [_https://www.census.gov/2010census/pdf/2010\_Questionnaire\_Info.pdf_](https://www.census.gov/2010census/pdf/2010\_Questionnaire\_Info.pdf).) People who checked one box were counted in categories such as “White Alone” or “Black or African American Alone.” Respondents who selected more than one box were tabulated in the overall category of “Two or More Races,” and the census data set breaks those down in detail.

SELECT geo\_name,\
&#x20;      state\_us\_abbreviation AS "st",\
&#x20;      p0010001 AS➊ "Total Population",\
&#x20;      p0010003 AS "White Alone",\
&#x20;      p0010004 AS "Black or African American Alone",\
&#x20;      p0010005 AS "Am Indian/Alaska Native Alone",\
&#x20;      p0010006 AS "Asian Alone",\
&#x20;      p0010007 AS "Native Hawaiian and Other Pacific Islander Alone",\
&#x20;      p0010008 AS "Some Other Race Alone",\
&#x20;      p0010009 AS "Two or More Races"\
FROM us\_counties\_2010;

_Listing 5-4: Selecting census population columns by race with aliases_

In us\_counties\_2010, each race and household data column contains a census code. For example, the “Asian Alone” column is reported as p0010006. Although those codes might be economical and compact, they make it difficult to understand which column is which when the query returns with just that code. In [Listing 5-4](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list4), I employ a little trick to clarify the output by using the AS keyword ➊ to give each column a more readable alias in the result set. We could rename all the columns upon import, but with the census it’s best to use the code to refer to the same column names in the documentation if needed.

_**Adding and Subtracting Columns**_

Now, let’s try a simple calculation on two of the race columns in [Listing 5-5](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list5), adding the number of people who identified as white alone or black alone in each county.

&#x20; SELECT geo\_name,\
&#x20;        state\_us\_abbreviation AS "st",\
&#x20;        p0010003 AS "White Alone",\
&#x20;        p0010004 AS "Black Alone",\
➊        p0010003 + p0010004 AS "Total White and Black"\
&#x20; FROM us\_counties\_2010;

_Listing 5-5: Adding two columns in us\_counties\_2010_

Providing p0010003 + p0010004 ➊ as one of the columns in the SELECT statement handles the calculation. Again, I use the AS keyword to provide a readable alias for the column. If you don’t provide an alias, PostgreSQL uses the label ?column?, which is far less than helpful.

Run the query to see the results. The first few rows should resemble this output:

![image](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492067580/files/images/prog\_page\_61.jpg)

A quick check with a calculator or pencil and paper confirms that the total column equals the sum of the columns you added. Excellent!

Now, let’s build on this to test our data and validate that we imported columns correctly. The six race “Alone” columns plus the “Two or More Races” column should add up to the same number as the total population. The code in [Listing 5-6](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list6) should show that it does:

&#x20; SELECT geo\_name,\
&#x20;        state\_us\_abbreviation AS "st",\
&#x20;      ➊ p0010001 AS "Total",\
&#x20;      ➋ p0010003 + p0010004 + p0010005 + p0010006 + p0010007\
&#x20;             \+ p0010008 + p0010009 AS "All Races",\
&#x20;      ➌ (p0010003 + p0010004 + p0010005 + p0010006 + p0010007\
&#x20;             \+ p0010008 + p0010009) - p0010001 AS "Difference"\
&#x20; FROM us\_counties\_2010\
➍ ORDER BY "Difference" DESC;

_Listing 5-6: Checking census data totals_

This query includes the population total ➊, followed by a calculation adding the seven race columns as All Races ➋. The population total and the races total should be identical, but rather than manually check, we also add a column that subtracts the population total column from the sum of the race columns ➌. That column, named Difference, should contain a zero in each row if all the data is in the right place. To avoid having to scan all 3,143 rows, we add an ORDER BY clause ➍ on the named column. Any rows showing a difference should appear at the top or bottom of the query result.

Run the query; the first few rows should provide this result:

geo\_name           st     Total      All Races     Difference\
\--------------     --     ------     ---------     ----------\
Autauga County     AL      54571         54571              0\
Baldwin County     AL     182265        182265              0\
Barbour County     AL      27457         27457              0

With the Difference column showing zeros, we can be confident that our import was clean. Whenever I encounter or import a new data set, I like to perform little tests like this. They help me better understand the data and head off any potential issues before I dig into analysis.

_**Finding Percentages of the Whole**_

Let’s dig deeper into the census data to find meaningful differences in the population demographics of the counties. One way to do this (with any data set, in fact) is to calculate what percentage of the whole a particular variable represents. With the census data, we can learn a lot by comparing percentages from county to county and also by examining how percentages vary over time.

To figure out the percentage of the whole, divide the number in question by the total. For example, if you had a basket of 12 apples and used 9 in a pie, that would be 9 / 12 or .75—commonly expressed as 75 percent.

To try this on the census counties data, use the code in [Listing 5-7](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list7), which calculates for each county the percentage of the population that reported their race as Asian:

SELECT geo\_name,\
&#x20;      state\_us\_abbreviation AS "st",\
&#x20;      (CAST ➊(p0010006 AS numeric(8,1)) / p0010001) \* 100 AS "pct\_asian"\
FROM us\_counties\_2010\
ORDER BY "pct\_asian" DESC;

_Listing 5-7: Calculating the percentage of the population that is Asian by county_

The key piece of this query divides p0010006, the column with the count of Asian alone, by p0010001, the column for total population ➊.

If we use the data as their original integer types, we won’t get the fractional result we need: every row will display a result of 0, the quotient. Instead, we force decimal division by using CAST on one of the integers. The last part multiplies the result by 100 to present the result as a fraction of 100—the way most people understand percentages.

By sorting from highest to lowest percentage, the top of the output is as follows:

geo\_name                       st     pct\_asian\
\--------------------------     --     -----------------------\
Honolulu County                HI     43.89497769109962474000\
Aleutians East Borough         AK     35.97580388411333970100\
San Francisco County           CA     33.27165361664607226500\
Santa Clara County             CA     32.02237037519322063600\
Kauai County                   HI     31.32461880132953749400\
Aleutians West Census Area     AK     28.87969789606185937800

_**Tracking Percent Change**_

Another key indicator in data analysis is percent change: how much bigger, or smaller, is one number than another? Percent change calculations are often employed when analyzing change over time, and they’re particularly useful for comparing change among similar items.

Some examples include:

* The year-over-year change in the number of vehicles sold by each automobile maker.
* The monthly change in subscriptions to each email list owned by a marketing firm.
* The annual increase or decrease in enrollment at schools across the nation.

The formula to calculate percent change can be expressed like this:

(_new number_ – _old number_) / _old number_

So, if you own a lemonade stand and sold 73 glasses of lemonade today and 59 glasses yesterday, you’d figure the day-to-day percent change like this:

(73 – 59) / 59 = .237 = 23.7%

Let’s try this with a small collection of test data related to spending in departments of a hypothetical local government. [Listing 5-8](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list8) calculates which departments had the greatest percentage increase and loss:

➊ CREATE TABLE percent\_change (\
&#x20;     department varchar(20),\
&#x20;     spend\_2014 numeric(10,2),\
&#x20;     spend\_2017 numeric(10,2)\
&#x20; );\
\
➋ INSERT INTO percent\_change\
&#x20; VALUES\
&#x20;     ('Building', 250000, 289000),\
&#x20;     ('Assessor', 178556, 179500),\
&#x20;     ('Library', 87777, 90001),\
&#x20;     ('Clerk', 451980, 650000),\
&#x20;     ('Police', 250000, 223000),\
&#x20;     ('Recreation', 199000, 195000);\
\
&#x20; SELECT department,\
&#x20;        spend\_2014,\
&#x20;        spend\_2017,\
&#x20;      ➌ round( (spend\_2017 - spend\_2014) /\
&#x20;                     spend\_2014 \* 100, 1) AS "pct\_change"\
&#x20; FROM percent\_change;

_Listing 5-8: Calculating percent change_

[Listing 5-8](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list8) creates a small table called percent\_change ➊ and inserts six rows ➋ with data on department spending for the years 2014 and 2017. The percent change formula ➌ subtracts spend\_2014 from spend\_2017 and then divides by spend\_2014. We multiply by 100 to express the result as a portion of 100.

To simplify the output, this time I’ve added the round() function to remove all but one decimal place. The function takes two arguments: the column or expression to be rounded, and the number of decimal places to display. Because both numbers are type numeric, the result will also be a numeric.

The script creates this result:

department     spend\_2014     spend\_2017     pct\_change\
\----------     ----------     ----------     ----------\
Building        250000.00      289000.00           15.6\
Assessor        178556.00      179500.00            0.5\
Library          87777.00       90001.00            2.5\
Clerk           451980.00      650000.00           43.8\
Police          250000.00      223000.00          -10.8\
Recreation      199000.00      195000.00           -2.0

Now, it’s just a matter of finding out why the Clerk department’s spending has outpaced others in the town.

#### Aggregate Functions for Averages and Sums <a href="#lev73" id="lev73"></a>

So far, we’ve performed math operations across columns in each row of a table. SQL also lets you calculate a result from values within the same column using _aggregate functions_. You can see a full list of PostgreSQL aggregates, which calculate a single result from multiple inputs, at [_https://www.postgresql.org/docs/current/static/functions-aggregate.html_](https://www.postgresql.org/docs/current/static/functions-aggregate.html). Two of the most-used aggregate functions in data analysis are avg() and sum().

Returning to the us\_counties\_2010 census table, it’s reasonable to want to calculate the total population of all counties plus the average population of all counties. Using avg() and sum() on column p0010001 (the total population) makes it easy, as shown in [Listing 5-9](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list9). Again, we use the round() function to remove numbers after the decimal point in the average calculation.

SELECT sum(p0010001) AS "County Sum",\
&#x20;      round(avg(p0010001), 0) AS "County Average"\
FROM us\_counties\_2010;

_Listing 5-9: Using the sum() and avg() aggregate functions_

This calculation produces the following result:

County Sum     County Average\
\----------     --------------\
&#x20;308745538              98233

The population for all counties in the United States in 2010 added up to approximately 308.7 million, and the average county population was 98,233.

#### Finding the Median <a href="#lev74" id="lev74"></a>

The _median_ value in a set of numbers is as important an indicator, if not more so, than the average. Here’s the difference between median and average, and why median matters:

**Average** The sum of all the values divided by the number of values

**Median** The “middle” value in an ordered set of values

Why is median important for data analysis? Consider this example: let’s say six kids, ages 10, 11, 10, 9, 13, and 12, go on a field trip. It’s easy to add the ages and divide by six to get the group’s average age:

(10 + 11 + 10 + 9 + 13 + 12) / 6 = 10.8

Because the ages are within a narrow range, the 10.8 average is a good representation of the group. But averages are less helpful when the values are bunched, or skewed, toward one end of the distribution, or if the group includes outliers.

For example, what if an older chaperone joins the field trip? With ages of 10, 11, 10, 9, 13, 12, and 46, the average age increases considerably:

(10 + 11 + 10 + 9 + 13 + 12 + 46) / 7 = 15.9

Now the average doesn’t represent the group well because the outlier skews it, making it an unreliable indicator.

This is where medians shine. The median is the midpoint in an ordered list of values—the point at which half the values are more and half are less. Using the field trip, we order the attendees’ ages from lowest to highest:

9, 10, 10, 11, 12, 13, 46

The middle (median) value is 11. Half the values are higher, and half are lower. Given this group, the median of 11 is a better picture of the typical age than the average of 15.9.

If the set of values is an even number, you average the two middle numbers to find the median. Let’s add another student (age 12) to the field trip:

9, 10, 10, 11, 12, 12, 13, 46

Now, the two middle values are 11 and 12. To find the median, we average them: 11.5.

Medians are reported frequently in financial news. Reports on housing prices often use medians because a few sales of McMansions in a ZIP Code that is otherwise modest can make averages useless. The same goes for sports player salaries: one or two superstars can skew a team’s average.

A good test is to calculate the average and the median for a group of values. If they’re close, the group is probably normally distributed (the familiar bell curve), and the average is useful. If they’re far apart, the values are not normally distributed and the median is the better representation.

_**Finding the Median with Percentile Functions**_

PostgreSQL (as with most relational databases) does not have a built-in median() function, similar to what you’d find in Excel or other spreadsheet programs. It’s also not included in the ANSI SQL standard. But we can use a SQL _percentile_ function to find the median as well as other _quantiles_ or _cut points_, which are the points that divide a group of numbers into equal sizes. Percentile functions are part of standard ANSI SQL.

In statistics, percentiles indicate the point in an ordered set of data below which a certain percentage of the data is found. For example, a doctor might tell you that your height places you in the 60th percentile for an adult in your age group. That means 60 percent of people are your height or shorter.

The median is equivalent to the 50th percentile—again, half the values are below and half above. SQL’s percentile functions allow us to calculate that easily, although we have to pay attention to a difference in how the two versions of the function—percentile\_cont(n) and percentile\_disc(n)—handle calculations. Both functions are part of the ANSI SQL standard and are present in PostgreSQL, Microsoft SQL Server, and other databases.

The percentile\_cont(n) function calculates percentiles as _continuous_ values. That is, the result does not have to be one of the numbers in the data set but can be a decimal value in between two of the numbers. This follows the methodology for calculating medians on an even number of values, where the median is the average of the two middle numbers. On the other hand, percentile\_disc(n) returns only _discrete_ values. That is, the result returned will be rounded to one of the numbers in the set.

To make this distinction clear, let’s use [Listing 5-10](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list10) to make a test table and fill in six numbers.

CREATE TABLE percentile\_test (\
&#x20;   numbers integer\
);\
\
INSERT INTO percentile\_test (numbers) VALUES\
&#x20;   (1), (2), (3), (4), (5), (6);\
\
SELECT\
&#x20; ➊ percentile\_cont(.5)\
&#x20;   WITHIN GROUP (ORDER BY numbers),\
&#x20; ➋ percentile\_disc(.5)\
&#x20;   WITHIN GROUP (ORDER BY numbers)\
FROM percentile\_test;

_Listing 5-10: Testing SQL percentile functions_

In both the continuous ➊ and discrete ➋ percentile functions, we enter .5 to represent the 50th percentile, which is equivalent to the median. Running the code returns the following:

percentile\_cont     percentile\_disc\
\---------------     ---------------\
&#x20;           3.5                   3

The percentile\_cont() function returned what we’d expect the median to be: 3.5. But because percentile\_disc() calculates discrete values, it reports 3, the last value in the first 50 percent of the numbers. Because the accepted method of calculating medians is to average the two middle values in an even-numbered set, use percentile\_cont(.5) to find a median.

_**Median and Percentiles with Census Data**_

Our census data can show how a median tells a different story than an average. [Listing 5-11](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list11) adds percentile\_cont() alongside the sum() and avg() aggregates we’ve used so far:

SELECT sum(p0010001) AS "County Sum",\
&#x20;      round(avg(p0010001), 0) AS "County Average",\
&#x20;      percentile\_cont(.5)\
&#x20;      WITHIN GROUP (ORDER BY p0010001) AS "County Median"\
FROM us\_counties\_2010;

_Listing 5-11: Using sum(), avg(), and percentile\_cont() aggregate functions_

Your result should equal the following:

County Sum     County Average     County Median\
\----------     --------------     -------------\
&#x20;308745538              98233             25857

The median and average are far apart, which shows that averages can mislead. As of 2010, half the counties in America had fewer than 25,857 people, whereas half had more. If you gave a presentation on U.S. demographics and told the audience that the “average county in America had 98,200 people,” they’d walk away with a skewed picture of reality. Nearly 40 counties had a million or more people as of the 2010 Decennial Census, and Los Angeles County had close to 10 million. That pushes the average higher.

_**Finding Other Quantiles with Percentile Functions**_

You can also slice data into smaller equal groups. Most common are _quartiles_ (four equal groups), _quintiles_ (five groups), and _deciles_ (10 groups). To find any individual value, you can just plug it into a percentile function. For example, to find the value marking the first quartile, or the lowest 25 percent of data, you’d use a value of .25:

percentile\_cont(.25)

However, entering values one at a time is laborious if you want to generate multiple cut points. Instead, you can pass values into percentile\_cont() using an _array_, a SQL data type that contains a list of items. [Listing 5-12](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list12) shows how to calculate all four quartiles at once:

SELECT percentile\_cont(➊array\[.25,.5,.75])\
&#x20;      WITHIN GROUP (ORDER BY p0010001) AS "quartiles"\
FROM us\_counties\_2010;

_Listing 5-12: Passing an array of values to percentile\_cont()_

In this example, we create an array of cut points by enclosing values in a _constructor_ ➊ called array\[]. Inside the square brackets, we provide comma-separated values representing the three points at which to cut to create four quartiles. Run the query, and you should see this output:

quartiles\
\---------------------\
{11104.5,25857,66699}

Because we passed in an array, PostgreSQL returns an array, denoted by curly brackets. Each quartile is separated by commas. The first quartile is 11,104.5, which means 25 percent of counties have a population that is equal to or lower than this value. The second quartile is the same as the median: 25,857. The third quartile is 66,699, meaning the largest 25 percent of counties have at least this large of a population.

Arrays come with a host of functions (noted for PostgreSQL at [_https://www.postgresql.org/docs/current/static/functions-array.html_](https://www.postgresql.org/docs/current/static/functions-array.html)) that allow you to perform tasks such as adding or removing values or counting the elements. A handy function for working with the result returned in [Listing 5-12](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list12) is unnest(), which makes the array easier to read by turning it into rows. [Listing 5-13](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list13) shows the code:

SELECT unnest(\
&#x20;           percentile\_cont(array\[.25,.5,.75])\
&#x20;           WITHIN GROUP (ORDER BY p0010001)\
&#x20;           ) AS "quartiles"\
FROM us\_counties\_2010;

_Listing 5-13: Using unnest() to turn an array into rows_

Now the output should be in rows:

quartiles\
\---------\
&#x20; 11104.5\
&#x20;   25857\
&#x20;   66699

If we were computing deciles, pulling them from the resulting array and displaying them in rows would be especially helpful.

_**Creating a median() Function**_

Although PostgreSQL does not have a built-in median() aggregate function, if you’re adventurous, the PostgreSQL wiki at [_http://wiki.postgresql.org/wiki/Aggregate\_Median_](http://wiki.postgresql.org/wiki/Aggregate\_Median) provides a script to create one. [Listing 5-14](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list14) shows the script:

➊ CREATE OR REPLACE FUNCTION \_final\_median(anyarray)\
&#x20;    RETURNS float8 AS\
&#x20; \$$\
&#x20;   WITH q AS\
&#x20;   (\
&#x20;      SELECT val\
&#x20;      FROM unnest($1) val\
&#x20;      WHERE VAL IS NOT NULL\
&#x20;      ORDER BY 1\
&#x20;   ),\
&#x20;   cnt AS\
&#x20;   (\
&#x20;     SELECT COUNT(\*) AS c FROM q\
&#x20;   )\
&#x20;   SELECT AVG(val)::float8\
&#x20;   FROM\
&#x20;   (\
&#x20;     SELECT val FROM q\
&#x20;     LIMIT  2 - MOD((SELECT c FROM cnt), 2)\
&#x20;     OFFSET GREATEST(CEIL((SELECT c FROM cnt) / 2.0) - 1,0)\
&#x20;   ) q2;\
&#x20; \$$\
&#x20; LANGUAGE sql IMMUTABLE;\
\
➋ CREATE AGGREGATE median(anyelement) (\
&#x20;   SFUNC=array\_append,\
&#x20;   STYPE=anyarray,\
&#x20;   FINALFUNC=\_final\_median,\
&#x20;   INITCOND='{}'\
&#x20; );

_Listing 5-14: Creating a median() aggregate function in PostgreSQL_

Given what you’ve learned so far, the code for making a median() aggregate function may look inscrutable. I’ll cover functions in more depth later in the book, but for now note that the code contains two main blocks: one to make a function called \_final\_median ➊ that sorts the values in the column and finds the midpoint, and a second that serves as the callable aggregate function median() ➋ and passes values to \_final\_median. For now, you can skip reviewing the script line by line and simply execute the code.

Let’s add the median() function to the census query and try it next to percentile\_cont(), as shown in [Listing 5-15](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list15):

SELECT sum(p0010001) AS "County Sum",\
&#x20;      round(AVG(p0010001), 0) AS "County Average",\
&#x20;      median(p0010001) AS "County Median",\
&#x20;      percentile\_cont(.5)\
&#x20;      WITHIN GROUP (ORDER BY p0010001) AS "50th Percentile"\
FROM us\_counties\_2010;

_Listing 5-15: Using a median() aggregate function_

The query results show that the median function and the percentile function return the same value:

County Sum     County Average     County Median     50th Percentile\
\----------     --------------     -------------     ---------------\
&#x20;308745538              98233             25857               25857

So when should you use median() instead of a percentile function? There is no simple answer. The median() syntax is easier to remember, albeit a chore to set up for each database, and it’s specific to PostgreSQL. Also, in practice, median() executes more slowly and may perform poorly on large data sets or slow machines. On the other hand, percentile\_cont() is portable across several SQL database managers, including Microsoft SQL Server, and allows you to find any percentile from 0 to 100. Ultimately, you can try both and decide.

#### Finding the Mode <a href="#lev79" id="lev79"></a>

Additionally, we can find the _mode_, the value that appears most often, using the PostgreSQL mode() function. The function is not part of standard SQL and has a syntax similar to the percentile functions. [Listing 5-16](https://learning.oreilly.com/library/view/practical-sql/9781492067580/xhtml/ch05.xhtml#ch05list16) shows a mode() calculation on p0010001, the total population column:

SELECT mode() WITHIN GROUP (ORDER BY p0010001)\
FROM us\_counties\_2010;

_Listing 5-16: Finding the most frequent value with mode()_

The result is 21720, a population count shared by counties in Mississippi, Oregon, and West Virginia.

#### Wrapping Up <a href="#lev80" id="lev80"></a>

Working with numbers is a key step in acquiring meaning from your data, and with the math skills covered in this chapter, you’re ready to handle the foundations of numerical analysis with SQL. Later in the book, you’ll learn about deeper statistical concepts including regression and correlation. At this point, you have the basics of sums, averages, and percentiles. You’ve also learned how a median can be a fairer assessment of a group of values than an average. That alone can help you avoid inaccurate conclusions.

In the next chapter, I’ll introduce you to the power of joining data in two or more tables to increase your options for data analysis. We’ll use the 2010 Census data you’ve already loaded into the analysis database and explore additional data sets.

**TRY IT YOURSELF**

Here are three exercises to test your SQL math skills:

1. Write a SQL statement for calculating the area of a circle whose radius is 5 inches. (If you don’t remember the formula, it’s an easy web search.) Do you need parentheses in your calculation? Why or why not?
2. Using the 2010 Census county data, find out which New York state county has the highest percentage of the population that identified as “American Indian/Alaska Native Alone.” What can you learn about that county from online research that explains the relatively large proportion of American Indian population compared with other New York counties?
3. Was the 2010 median county population higher in California or New York?
