# 10. Vectorized Backtesting

## Chapter 10. Vectorized Backtesting

> Tesla’s chief executive and serial technology entrepreneur, Elon Musk, has said his company’s cars will be able to be summoned and drive autonomously across the US to pick up their owners within the next two years.
>
> Samuel Gibbs (2016)

> Big money is made in the stock market by being on the right side of the major moves.
>
> Martin Zweig

The term _vectorized backtesting_ refers to a technical approach to backtesting algorithmic trading strategies, such as those based on a dense neural network (DNN) for market prediction. The books by Hilpisch (2018, ch. 15; 2020, ch. 4) cover vectorized backtesting based on a number of concrete examples. _Vectorized_ in this context refers to a programming paradigm that relies heavily or even exclusively on vectorized code (that is, code without any looping on the Python level). Vectorization of code is good practice with such packages such as `Numpy` or `pandas` in general and has been used intensively in previous chapters as well. The benefits of vectorized code are more concise and easy-to-read code, as well as faster execution in many important scenarios. On the other hand, it might not be as flexible in backtesting trading strategies as, for example, event-based backtesting, which is introduced and used in [Chapter 11](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch11.html#risk\_management).

Having a good AI-powered predictor available that beats a simple baseline predictor is important but is generally not enough to generate _alpha_ (that is, above-market returns, possibly adjusted for risk). For example, it is also important for a prediction-based trading strategy to predict the large market movements correctly and not just the majority of the (potentially pretty small) market movements. Vectorized backtesting is an easy and fast way of figuring out the economic potential of a trading strategy.

Compared to autonomous vehicles (AVs), vectorized backtesting is like testing the AI of AVs in virtual environments just to see how it performs “in general” in a risk-free environment. However, for the AI of an AV it is not only important to perform well _on average_, but it is also of paramount importance to see how it masters critical or even extreme situations. Such an AI is supposed to cause “zero casualties” on average, not 0.1 or 0.5. For a financial AI, it is similarly—even if not equally—important to get the large market movements correct. Whereas this chapter focuses on the pure performance of financial AI agents (trading bots), [Chapter 11](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch11.html#risk\_management) goes deeper into risk assessment and the backtesting of standard risk measures.

[“Backtesting an SMA-Based Strategy”](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#vb\_sma\_eod\_exmple) introduces vectorized backtesting based on a simple example using simple moving averages as technical indicators and end-of-day (EOD) data. This allows for insightful visualizations and an easier understanding of the approach when getting started. [“Backtesting a Daily DNN-Based Strategy”](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#vb\_dnn\_eod\_example) trains a DNN based on EOD data and backtests the resulting prediction-based strategy for its economic performance. [“Backtesting an Intraday DNN-Based Strategy”](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#vb\_dnn\_id\_example) then does the same with intraday data. In all examples, proportional transaction costs are included in the form of assumed bid-ask spreads.

## Backtesting an SMA-Based Strategy

This section introduces vectorized backtesting based on a classical trading strategy that uses simple moving averages (SMAs) as technical indicators. The following code realizes the necessary imports and configurations and retrieves EOD data for the EUR/USD currency pair:

```
In [1]: import os
        import math
        import numpy as np
        import pandas as pd
        from pylab import plt, mpl
        plt.style.use('seaborn')
        mpl.rcParams['savefig.dpi'] = 300
        mpl.rcParams['font.family'] = 'serif'
        pd.set_option('mode.chained_assignment', None)
        pd.set_option('display.float_format', '{:.4f}'.format)
        np.set_printoptions(suppress=True, precision=4)
        os.environ['PYTHONHASHSEED'] = '0'

In [2]: url = 'http://hilpisch.com/aiif_eikon_eod_data.csv'  

In [3]: symbol = 'EUR='  

In [4]: data = pd.DataFrame(pd.read_csv(url, index_col=0,
                                        parse_dates=True).dropna()[symbol])  

In [5]: data.info()  
        <class 'pandas.core.frame.DataFrame'>
        DatetimeIndex: 2516 entries, 2010-01-04 to 2019-12-31
        Data columns (total 1 columns):
         #   Column  Non-Null Count  Dtype
        ---  ------  --------------  -----
         0   EUR=    2516 non-null   float64
        dtypes: float64(1)
        memory usage: 39.3 KB
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO1-1)

Retrieves EOD data for EUR/USD

The idea of the strategy is the following. Calculate a shorter `SMA1`, say for 42 days, and a longer `SMA2`, say for 258 days. Whenever `SMA1` is above `SMA2`, go long on the financial instrument. Whenever `SMA1` is below `SMA2`, go short on the financial instrument. Because the example is based on EUR/USD, going long or short is easily accomplished.

The following Python code calculates in vectorized fashion the SMA values and visualizes the resulting time series alongside the original time series (see [Figure 10-1](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_01)):

```
In [6]: data['SMA1'] = data[symbol].rolling(42).mean()  

In [7]: data['SMA2'] = data[symbol].rolling(258).mean()  

In [8]: data.plot(figsize=(10, 6));  
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO2-1)

Calculates the shorter `SMA1`

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO2-2)

Calculates the longer `SMA2`

[![3](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/3.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO2-3)

Visualizes the three time series

Equipped with the SMA time series data, the resulting positions can, again in vectorized fashion, be derived. Note the shift of the resulting position time series by one day to avoid foresight bias in the data. This shift is necessary since the calculation of the SMAs includes the closing values from the same day. Therefore, the position derived from the SMA values from one day needs to be applied to the next day for the whole time series.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1001.png" alt="aiif 1001" height="1397" width="2415"><figcaption></figcaption></figure>

**Figure 10-1. Time series data for EUR/USD and SMAs**

[Figure 10-2](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_02) visualizes the resulting positions as an overlay to the other time series:

```
In [9]: data.dropna(inplace=True)  

In [10]: data['p'] = np.where(data['SMA1'] > data['SMA2'], 1, -1)  

In [11]: data['p'] = data['p'].shift(1)  

In [12]: data.dropna(inplace=True)  

In [13]: data.plot(figsize=(10, 6), secondary_y='p');  
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO3-1)

Deletes rows containing `NaN` values

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO3-2)

Derives the position values based on same-day SMA values

[![3](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/3.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO3-3)

Shifts the position values by one day to avoid foresight bias

[![4](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/4.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO3-5)

Visualizes the position values as derived from the SMAs

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1002.png" alt="aiif 1002" height="1397" width="2569"><figcaption></figcaption></figure>

**Figure 10-2. Time series data for EUR/USD, SMAs, and resulting positions**

One crucial step is missing: the combination of the positions with the returns of the financial instrument. Since positions are conveniently represented by a `+1` for a long position and a `-1` for a short position, this step boils down to multiplying two columns of the `DataFrame` object—in vectorized fashion again. The SMA-based trading strategy outperforms the passive benchmark investment by a considerable margin, as [Figure 10-3](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_03) illustrates:

```
In [14]: data['r'] = np.log(data[symbol] / data[symbol].shift(1))  

In [15]: data.dropna(inplace=True)

In [16]: data['s'] = data['p'] * data['r']  

In [17]: data[['r', 's']].sum().apply(np.exp)  
Out[17]: r   0.8640
         s   1.3773
         dtype: float64

In [18]: data[['r', 's']].sum().apply(np.exp) - 1  
Out[18]: r   -0.1360
         s    0.3773
         dtype: float64

In [19]: data[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));  
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO4-1)

Calculates the log returns

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO4-2)

Calculates the strategy returns

[![3](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/3.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO4-3)

Calculates the gross performances

[![4](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/4.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO4-4)

Calculates the net performances

[![5](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/5.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO4-5)

Visualizes the gross performances over time

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1003.png" alt="aiif 1003" height="1394" width="2418"><figcaption></figcaption></figure>

**Figure 10-3. Gross performance of passive benchmark investment and SMA strategy**

So far, the performance figures are not considering transaction costs. These are, of course, a crucial element when judging the economic potential of a trading strategy. In the current setup, proportional transaction costs can be easily included in the calculations. The idea is to determine when a trade takes place and to reduce the performance of the trading strategy by a certain value to account for the relevant bid-ask spread. As the following calculations show, and as is obvious from [Figure 10-2](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_02), the trading strategy does not change positions too often. Therefore, in order to have some meaningful effects of transaction costs, they are assumed to be quite a bit higher than typically seen for EUR/USD. The net effect of subtracting transaction costs is a few percentage points under the given assumptions (see [Figure 10-4](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_04)):

```
In [20]: sum(data['p'].diff() != 0) + 2  
Out[20]: 10

In [21]: pc = 0.005  

In [22]: data['s_'] = np.where(data['p'].diff() != 0,
                               data['s'] - pc, data['s'])  

In [23]: data['s_'].iloc[0] -= pc  

In [24]: data['s_'].iloc[-1] -= pc  

In [25]: data[['r', 's', 's_']][data['p'].diff() != 0]  
Out[25]:                  r       s      s_
         Date
         2011-01-12  0.0123  0.0123  0.0023
         2011-10-10  0.0198 -0.0198 -0.0248
         2012-11-07 -0.0034 -0.0034 -0.0084
         2014-07-24 -0.0001  0.0001 -0.0049
         2016-03-16  0.0102  0.0102  0.0052
         2016-11-10 -0.0018  0.0018 -0.0032
         2017-06-05 -0.0025 -0.0025 -0.0075
         2018-06-15  0.0035 -0.0035 -0.0085

In [26]: data[['r', 's', 's_']].sum().apply(np.exp)
Out[26]: r    0.8640
         s    1.3773
         s_   1.3102
         dtype: float64

In [27]: data[['r', 's', 's_']].sum().apply(np.exp) - 1
Out[27]: r    -0.1360
         s     0.3773
         s_    0.3102
         dtype: float64

In [28]: data[['r', 's', 's_']].cumsum().apply(np.exp).plot(figsize=(10, 6));
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO5-1)

Calculates the number of trades, including entry and exit trade

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO5-2)

Fixes the proportional transaction costs (deliberately set quite high)

[![3](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/3.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO5-3)

Adjusts the strategy performance for the transaction costs

[![4](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/4.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO5-4)

Adjusts the strategy performance for the _entry_ trade

[![5](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/5.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO5-5)

Adjusts the strategy performance for the _exit_ trade

[![6](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/6.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO5-6)

Shows the adjusted performance values for the regular trades

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1004.png" alt="aiif 1004" height="1394" width="2418"><figcaption></figcaption></figure>

**Figure 10-4. Gross performance of the SMA strategy before and after transaction costs**

What about the resulting risk of the trading strategy? For a trading strategy that is based on directional predictions and that takes long or short positions only, the risk, expressed as the volatility (standard deviation of the log returns), is exactly the same as for the passive benchmark investment:

```
In [29]: data[['r', 's', 's_']].std()  
Out[29]: r    0.0054
         s    0.0054
         s_   0.0054
         dtype: float64

In [30]: data[['r', 's', 's_']].std() * math.sqrt(252)  
Out[30]: r    0.0853
         s    0.0853
         s_   0.0855
         dtype: float64
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO6-1)

Daily volatility

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO6-2)

Annualized volatility

## VECTORIZED BACKTESTING

Vectorized backtesting is a powerful and efficient approach to backtesting the “pure” performance of a prediction-based trading strategy. It can also accommodate proportional transaction costs, for instance. However, it is not well suited to including typical risk management measures, such as (trailing) stop loss orders or take profit orders. This is addressed in [Chapter 11](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch11.html#risk\_management).

## Backtesting a Daily DNN-Based Strategy

The previous section lays out the blueprint for vectorized backtesting on the basis of a simple, easy-to-visualize trading strategy. The same blueprint can be applied, for example, to DNN-based trading strategies with minimal technical adjustments. The following trains a `Keras` DNN model, as discussed in [Chapter 7](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch07.html#dense\_networks). The data that is used is the same as in the previous example. However, as in [Chapter 7](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch07.html#dense\_networks), different features and lags thereof need to be added to the `DataFrame` object:

```
In [31]: data = pd.DataFrame(pd.read_csv(url, index_col=0,
                                         parse_dates=True).dropna()[symbol])

In [32]: data.info()
         <class 'pandas.core.frame.DataFrame'>
         DatetimeIndex: 2516 entries, 2010-01-04 to 2019-12-31
         Data columns (total 1 columns):
          #   Column  Non-Null Count  Dtype
         ---  ------  --------------  -----
          0   EUR=    2516 non-null   float64
         dtypes: float64(1)
         memory usage: 39.3 KB

In [33]: lags = 5

In [34]: def add_lags(data, symbol, lags, window=20):
             cols = []
             df = data.copy()
             df.dropna(inplace=True)
             df['r'] = np.log(df / df.shift(1))
             df['sma'] = df[symbol].rolling(window).mean()
             df['min'] = df[symbol].rolling(window).min()
             df['max'] = df[symbol].rolling(window).max()
             df['mom'] = df['r'].rolling(window).mean()
             df['vol'] = df['r'].rolling(window).std()
             df.dropna(inplace=True)
             df['d'] = np.where(df['r'] > 0, 1, 0)
             features = [symbol, 'r', 'd', 'sma', 'min', 'max', 'mom', 'vol']
             for f in features:
                 for lag in range(1, lags + 1):
                     col = f'{f}_lag_{lag}'
                     df[col] = df[f].shift(lag)
                     cols.append(col)
             df.dropna(inplace=True)
             return df, cols

In [35]: data, cols = add_lags(data, symbol, lags, window=20)
```

The following Python code accomplishes additional imports and defines the `set_seeds()` and `create_model()` functions:

```
In [36]: import random
         import tensorflow as tf
         from keras.layers import Dense, Dropout
         from keras.models import Sequential
         from keras.regularizers import l1
         from keras.optimizers import Adam
         from sklearn.metrics import accuracy_score
         Using TensorFlow backend.

In [37]: def set_seeds(seed=100):
             random.seed(seed)
             np.random.seed(seed)
             tf.random.set_seed(seed)
         set_seeds()

In [38]: optimizer = Adam(learning_rate=0.0001)

In [39]: def create_model(hl=2, hu=128, dropout=False, rate=0.3,
                         regularize=False, reg=l1(0.0005),
                         optimizer=optimizer, input_dim=len(cols)):
             if not regularize:
                 reg = None
             model = Sequential()
             model.add(Dense(hu, input_dim=input_dim,
                          activity_regularizer=reg,
                          activation='relu'))
             if dropout:
                 model.add(Dropout(rate, seed=100))
             for _ in range(hl):
                 model.add(Dense(hu, activation='relu',
                              activity_regularizer=reg))
                 if dropout:
                     model.add(Dropout(rate, seed=100))
             model.add(Dense(1, activation='sigmoid'))
             model.compile(loss='binary_crossentropy',
                           optimizer=optimizer,
                           metrics=['accuracy'])
             return model
```

Based on a sequential train-test split of the historical data, the following Python code first trains the DNN model based on normalized features data:

```
In [40]: split = '2018-01-01'  

In [41]: train = data.loc[:split].copy()  

In [42]: np.bincount(train['d'])  
Out[42]: array([ 982, 1006])

In [43]: mu, std = train.mean(), train.std()  

In [44]: train_ = (train - mu) / std  

In [45]: set_seeds()
         model = create_model(hl=2, hu=64)  

In [46]: %%time
         model.fit(train_[cols], train['d'],
                 epochs=20, verbose=False,
                 validation_split=0.2, shuffle=False)  
         CPU times: user 2.93 s, sys: 574 ms, total: 3.5 s
         Wall time: 1.93 s

Out[46]: <keras.callbacks.callbacks.History at 0x7fc9392f38d0>

In [47]: model.evaluate(train_[cols], train['d'])  
         1988/1988 [==============================] - 0s 17us/step

Out[47]: [0.6745863538872549, 0.5925553441047668]
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO7-1)

Splits the data into training and test data

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO7-3)

Shows the frequency of the labels classes

[![3](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/3.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO7-4)

Normalizes the training features data

[![4](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/4.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO7-6)

Creates the DNN model

[![5](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/5.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO7-7)

Trains the DNN model on the training data

[![6](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/6.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO7-8)

Evaluates the performance of the model on the training data

So far, this basically repeats the core approach of [Chapter 7](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch07.html#dense\_networks). Vectorized backtesting can now be applied to judge the economic performance of the DNN-based trading strategy _in-sample_ based on the model’s predictions (see [Figure 10-5](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_05)). In this context, an upward prediction is naturally interpreted as a long position and a downward prediction as a short position:

```
In [48]: train['p'] = np.where(model.predict(train_[cols]) > 0.5, 1, 0)  

In [49]: train['p'] = np.where(train['p'] == 1, 1, -1)  

In [50]: train['p'].value_counts()  
Out[50]: -1    1098
          1     890
         Name: p, dtype: int64

In [51]: train['s'] = train['p'] * train['r']  

In [52]: train[['r', 's']].sum().apply(np.exp)  
Out[52]: r   0.8787
         s   5.0766
         dtype: float64

In [53]: train[['r', 's']].sum().apply(np.exp)  - 1  
Out[53]: r   -0.1213
         s    4.0766
         dtype: float64

In [54]: train[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));  
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO8-1)

Generates the binary predictions

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO8-2)

Translates the predictions into position values

[![3](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/3.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO8-3)

Shows the number of long and short positions

[![4](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/4.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO8-4)

Calculates the strategy performance values

[![5](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/5.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO8-5)

Calculates the gross and net performances (in-sample)

[![6](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/6.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO8-7)

Visualizes the gross performances over time (in-sample)

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1005.png" alt="aiif 1005" height="1394" width="2379"><figcaption></figcaption></figure>

**Figure 10-5. Gross performance of the passive benchmark investment and the daily DNN strategy (in-sample)**

Next is the same sequence of calculations for the test data set. Whereas the out-performance in-sample is significant, the numbers out-of-sample are not as impressive but are still convincing (see [Figure 10-6](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_06)):

```
In [55]: test = data.loc[split:].copy()  

In [56]: test_ = (test - mu) / std  

In [57]: model.evaluate(test_[cols], test['d'])  
         503/503 [==============================] - 0s 17us/step

Out[57]: [0.6933823573897421, 0.5407554507255554]

In [58]: test['p'] = np.where(model.predict(test_[cols]) > 0.5, 1, -1)

In [59]: test['p'].value_counts()
Out[59]: -1    406
          1     97
         Name: p, dtype: int64

In [60]: test['s'] = test['p'] * test['r']

In [61]: test[['r', 's']].sum().apply(np.exp)
Out[61]: r   0.9345
         s   1.2431
         dtype: float64

In [62]: test[['r', 's']].sum().apply(np.exp) - 1
Out[62]: r   -0.0655
         s    0.2431
         dtype: float64

In [63]: test[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO9-1)

Generates the test data sub-set

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO9-2)

Normalizes the test data

[![3](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/3.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO9-3)

Evaluates the model performance on the test data

The DNN-based trading strategy leads to a larger number of trades as compared to the SMA-based strategy. This makes the inclusion of transaction costs an even more important aspect when judging the economic performance.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1006.png" alt="aiif 1006" height="1428" width="2444"><figcaption></figcaption></figure>

**Figure 10-6. Gross performance of the passive benchmark investment and the daily DNN strategy (out-of-sample)**

The following code assumes now realistic bid-ask spreads for EUR/USD on the level of 1.2 pips (that is, 0.00012 in terms of currency units).[1](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#idm46319949574456) To simplify the calculations, an average value for the proportional transaction costs `pc` is calculated based on the average closing price for EUR/USD (see [Figure 10-7](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_07)):

```
In [64]: sum(test['p'].diff() != 0)
Out[64]: 147

In [65]: spread = 0.00012  
         pc = spread / data[symbol].mean()  
         print(f'{pc:.6f}')
         0.000098

In [66]: test['s_'] = np.where(test['p'].diff() != 0,
                               test['s'] - pc, test['s'])

In [67]: test['s_'].iloc[0] -= pc

In [68]: test['s_'].iloc[-1] -= pc

In [69]: test[['r', 's', 's_']].sum().apply(np.exp)
Out[69]: r    0.9345
         s    1.2431
         s_   1.2252
         dtype: float64

In [70]: test[['r', 's', 's_']].sum().apply(np.exp) - 1
Out[70]: r    -0.0655
         s     0.2431
         s_    0.2252
         dtype: float64

In [71]: test[['r', 's', 's_']].cumsum().apply(np.exp).plot(figsize=(10, 6));
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO10-1)

Fixes the average bid-ask spread

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO10-2)

Calculates the average proportional transaction costs

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1007.png" alt="aiif 1007" height="1428" width="2444"><figcaption></figcaption></figure>

**Figure 10-7. Gross performance of the daily DNN strategy before and after transaction costs (out-of-sample)**

The DNN-based trading strategy seems promising both before and after typical transaction costs. However, would a similar strategy be economically viable intraday as well, when even more trades are observed? The next section analyzes a DNN-based intraday strategy.

## Backtesting an Intraday DNN-Based Strategy

To train and backtest a DNN model on intraday data, another data set is required:

```
In [72]: url = 'http://hilpisch.com/aiif_eikon_id_eur_usd.csv'  

In [73]: symbol = 'EUR='  

In [74]: data = pd.DataFrame(pd.read_csv(url, index_col=0,
                             parse_dates=True).dropna()['CLOSE'])  
         data.columns = [symbol]

In [75]: data = data.resample('5min', label='right').last().ffill()  

In [76]: data.info()  
         <class 'pandas.core.frame.DataFrame'>
         DatetimeIndex: 26486 entries, 2019-10-01 00:05:00 to 2019-12-31 23:10:00
         Freq: 5T
         Data columns (total 1 columns):
          #   Column  Non-Null Count  Dtype
         ---  ------  --------------  -----
          0   EUR=    26486 non-null  float64
         dtypes: float64(1)
         memory usage: 413.8 KB

In [77]: lags = 5

In [78]: data, cols = add_lags(data, symbol, lags, window=20)
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO11-1)

Retrieves intraday data for EUR/USD and picks the closing prices

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO11-4)

Resamples the data to five-minute bars

The procedure of the previous section can now be repeated with the new data set. First, train the DNN model:

```
In [79]: split = int(len(data) * 0.85)

In [80]: train = data.iloc[:split].copy()

In [81]: np.bincount(train['d'])
Out[81]: array([16284,  6207])

In [82]: def cw(df):
             c0, c1 = np.bincount(df['d'])
             w0 = (1 / c0) * (len(df)) / 2
             w1 = (1 / c1) * (len(df)) / 2
             return {0: w0, 1: w1}

In [83]: mu, std = train.mean(), train.std()

In [84]: train_ = (train - mu) / std

In [85]: set_seeds()
         model = create_model(hl=1, hu=128,
                              reg=True, dropout=False)

In [86]: %%time
         model.fit(train_[cols], train['d'],
                   epochs=40, verbose=False,
                   validation_split=0.2, shuffle=False,
                   class_weight=cw(train))
         CPU times: user 40.6 s, sys: 5.49 s, total: 46 s
         Wall time: 25.2 s

Out[86]: <keras.callbacks.callbacks.History at 0x7fc91a6b2a90>

In [87]: model.evaluate(train_[cols], train['d'])
         22491/22491 [==============================] - 0s 13us/step

Out[87]: [0.5218664327576152, 0.6729803085327148]
```

In-sample, the performance looks promising, as illustrated in [Figure 10-8](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_08):

```
In [88]: train['p'] = np.where(model.predict(train_[cols]) > 0.5, 1, -1)

In [89]: train['p'].value_counts()
Out[89]: -1    11519
          1    10972
         Name: p, dtype: int64

In [90]: train['s'] = train['p'] * train['r']

In [91]: train[['r', 's']].sum().apply(np.exp)
Out[91]: r   1.0223
         s   1.6665
         dtype: float64

In [92]: train[['r', 's']].sum().apply(np.exp) - 1
Out[92]: r   0.0223
         s   0.6665
         dtype: float64

In [93]: train[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));
```

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1008.png" alt="aiif 1008" height="1570" width="2415"><figcaption></figcaption></figure>

**Figure 10-8. Gross performance of the passive benchmark investment and the DNN intraday strategy (in-sample)**

Out-of-sample, the performance also looks promising before transaction costs. The strategy seems to systematically outperform the passive benchmark investment (see [Figure 10-9](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_09)):

```
In [94]: test = data.iloc[split:].copy()

In [95]: test_ = (test - mu) / std

In [96]: model.evaluate(test_[cols], test['d'])
         3970/3970 [==============================] - 0s 19us/step

Out[96]: [0.5226116042706168, 0.668513834476471]

In [97]: test['p'] = np.where(model.predict(test_[cols]) > 0.5, 1, -1)

In [98]: test['p'].value_counts()
Out[98]: -1    2273
          1    1697
         Name: p, dtype: int64

In [99]: test['s'] = test['p'] * test['r']

In [100]: test[['r', 's']].sum().apply(np.exp)
Out[100]: r   1.0071
          s   1.0658
          dtype: float64

In [101]: test[['r', 's']].sum().apply(np.exp) - 1
Out[101]: r   0.0071
          s   0.0658
          dtype: float64

In [102]: test[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));
```

The final litmus test with regard to pure economic performance comes when adding transaction costs. The strategy leads to hundreds of trades over a relatively short period of time. As the following analysis suggests, based on standard retail bid-ask spreads, the DNN-based strategy is not viable.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1009.png" alt="aiif 1009" height="1559" width="2442"><figcaption></figcaption></figure>

**Figure 10-9. Gross performance of the passive benchmark investment and the DNN intraday strategy (out-of-sample)**

Reducing the spread to a level that professional, high-volume traders might achieve, the strategy still does not break even but rather loses a large proportion of the profits to the transaction costs (see [Figure 10-10](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#figure\_vb\_10)):

```
In [103]: sum(test['p'].diff() != 0)
Out[103]: 1303

In [104]: spread = 0.00012  
          pc_1 = spread / test[symbol]  

In [105]: spread = 0.00006  
          pc_2 = spread / test[symbol]  

In [106]: test['s_1'] = np.where(test['p'].diff() != 0,
                                 test['s'] - pc_1, test['s'])  

In [107]: test['s_1'].iloc[0] -= pc_1.iloc[0]  
          test['s_1'].iloc[-1] -= pc_1.iloc[0]  

In [108]: test['s_2'] = np.where(test['p'].diff() != 0,
                                 test['s'] - pc_2, test['s'])  

In [109]: test['s_2'].iloc[0] -= pc_2.iloc[0]  
          test['s_2'].iloc[-1] -= pc_2.iloc[0]  

In [110]: test[['r', 's', 's_1', 's_2']].sum().apply(np.exp)
Out[110]: r     1.0071
          s     1.0658
          s_1   0.9259
          s_2   0.9934
          dtype: float64

In [111]: test[['r', 's', 's_1', 's_2']].sum().apply(np.exp) - 1
Out[111]: r      0.0071
          s      0.0658
          s_1   -0.0741
          s_2   -0.0066
          dtype: float64

In [112]: test[['r', 's', 's_1', 's_2']].cumsum().apply(
              np.exp).plot(figsize=(10, 6), style=['-', '-', '--', '--']);
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/1.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO12-1)

Assumes bid-ask spread on retail level

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/2.png)](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#co\_vectorized\_backtesting\_CO12-3)

Assumes bid-ask spread on professional level

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781492055426/files/assets/aiif_1010.png" alt="aiif 1010" height="1559" width="2444"><figcaption></figcaption></figure>

**Figure 10-10. Gross performance of the DNN intraday strategy before and after higher/lower transaction costs (out-of-sample)**

## INTRADAY TRADING

Intraday algorithmic trading in the form discussed in this chapter often seems appealing from a statistical point of view. Both in-sample and out-of-sample, the DNN model reaches a high accuracy when predicting the market direction. Excluding transaction costs, this also translates both in-sample and out-of-sample into a significant outperformance of the DNN-based strategy when compared to the passive benchmark investment. However, adding transaction costs to the mix reduces the performance of the DNN-based strategy considerably, making it unviable for typical retail bid-ask spreads and not really attractive for lower, high-volume bid-ask spreads.

## Conclusions

Vectorized backtesting proves to be an efficient and valuable approach for backtesting the performance of AI-powered algorithmic trading strategies. This chapter first explains the basic idea behind the approach based on a simple example using two SMAs to derive signals. This allows for a simple visualization of the strategy and resulting positions. It then proceeds by backtesting a DNN-based trading strategy, as discussed in detail in [Chapter 7](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch07.html#dense\_networks), in combination with EOD data. Both before and after transaction costs, the _statistical inefficiencies_ as discovered in [Chapter 7](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch07.html#dense\_networks) translate into _economic inefficiencies_, which means profitable trading strategies. When using the same vectorized backtesting approaches with intraday data, the DNN strategy also shows a significant outperformance both in- and out-of-sample when compared to the passive benchmark investment—at least before transaction costs. Adding transaction costs to the backtesting illustrates that these must be pretty low, on a level often not even achieved by big professional traders, to render the trading strategy economically viable.

## References

Books and papers cited in this chapter:

* Gibbs Samuel. 2016. “Elon Musk: Tesla Cars Will Be Able to Cross Us with No Driver in Two Years.” _The Guardian_. January 11, 2016. [_https://oreil.ly/C508Q_](https://oreil.ly/C508Q).
* Hilpisch, Yves. 2018. _Python for Finance: Mastering Data-Driven Finance._ 2nd ed. Sebastopol: O’Reilly.
* ⸻. 2020. _Python for Algorithmic Trading: From Idea to Cloud Deployment._ Sebastopol: O’Reilly.

[1](https://learning.oreilly.com/library/view/artificial-intelligence-in/9781492055426/ch10.html#idm46319949574456-marker) This, for example, is a typical spread that [Oanda](http://oanda.com/) offers retail traders.
