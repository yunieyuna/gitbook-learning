# 6. Introductory Python for Data Science

## Chapter 6. Introductory Python for Data Science

One more stop to go before diving into the realm of machine and deep learning. This chapter is optional for experienced Python developers but is important for anyone without a solid programming background. Understanding the intuition behind the algorithms is a great advantage but it will not get you far if you fail to properly implement them. After all, these algorithms need ro be coded to work and do not function manually. Make sure you understand the basic syntax and how to manipulate data and transform it.

As the book is not meant to be an A-Z guide to programming in Python, this chapter gently brushes on some essentials and a few more techniques that should help you navigate smoothly the subsequent chapters.

## Downloading Python

_Coding_ is defined as a set of instructions designed to be executed by a computer. Generally, specific syntax is required so that the computer applies the set of instructions without errors. There are many coding languages and they are divided into two broad categories:

Low-level coding languagesThese are machine languages usually for operating systems and firmwares. They are very difficult to read. These languages have a sizable level of control over hardware. Assembly language is an example of a low-level language.High-level coding languagesThese are user-friendly languages (with a high level of abstraction). They are generally used to code programs and softwares. Examples of high-level languages include Python and Julia.

The coding language used in this book is Python, a popular and versatile language with many advantages and wide adoption in the research and professional trading communities. As you have probably gathered from the chapter’s name, you will get an introduction to Python with the necessary tools to start building your own scripts. But before that, you should download Python.

A _Python interpreter_ is a software used to write and execute code written using Python syntax. I use a software called Spyder. Some people may be more familiar with other interpreters such as Jupyter and PyCharm, but the process is the same. You can download Spyder from the [official website](https://www.spyder-ide.org/) or, even better, download it as part of a bigger package called [Anaconda](https://oreil.ly/nI8Ed), which facilitates installation and offers more tools. Note that it is open source and free-to-use.

_Spyder’s_ interface is split into three windows, as you can see in [Figure 6-1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#figure-6-1). The window on the left is used to write the code that is later executed (the algorithm is told to run and apply the code) when the user confirms it. Typically, you will see multiple lines of code in that area.

The window on the upper right is the _variable explorer_. Every time a variable is stored (defined), you can see it there. The window on the lower right is the _console_ that shows the result of the code, whether it is an error or an output (it also shows the code that has been executed).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0601.png" alt="" height="338" width="600"><figcaption></figcaption></figure>

**Figure 6-1. Spyder’s interface**

Python files have the extension _name.py_ and they allow you to save the code and refer to it at a later stage. You can also open multiple files of code and navigate between them.

The outline of this chapter is as follows:

1. Understand the language of Python and how to write error-free code.
2. Understand how to use control flow and its importance with time series analysis.
3. Understand what are libraries and functions and their role in facilitating coding.
4. Understand how to handle errors and their different types.&#x20;
5. Understand how to use data manipulation libraries such as `numpy` and `pandas`.
6. Finally, see how to import historical financial time series data into Python so that it gets analyzed with the proper tools that you have seen in previous chapters but also in the coming chapters.

## Basic Operations and Syntax

_Syntax_ is the proper way of writing error-free code; it is the structure of statements needed to write code that functions. When you are communicating with a computer, you have to make sure it understands you, and therefore having a solid understanding of syntax is important.

Understanding code is helped by a useful feature called comments. A _comment_ is a non-executable code used to explain the executable code right after. Commens are used so other programmers understand the code. Comments in Python are preceded by a hashtag (**#**):

<pre><code><strong># This is a comment. Comments are ignored by the interpreter
</strong><strong># Comments explain the code or give more details about its use
</strong><strong># Comments are written in one line, otherwise, you have to re-write '#'
</strong></code></pre>

**NOTE**

Make sure you understand that comments are non-executable. This means that when you run (execute) the code, they will be ignored by the interpreter and they will not return an error.

Sometimes you need to write documentation for your code, which may require multiple lines of code (even paragraphs in some instances). Writing the hashtag symbol at every line can be tedious and cluttersome. This is why there is a way to write long comments. To do this, write your comments between three single quotes at every end as follows:

```
'''
Python was created in the late 1980s by Guido van Rossum
The name "Python" was inspired by the comedy group Monty Python
'''
```

It is worth noting that triple quotes are called _docstrings_ and not really comments (according to the official Python documentation).

Let’s discuss variables and constants. A _constant_ is a fixed value that does not change, whereas a _variable_ takes on different values given an event. A constant can be the number 6, while a variable can be the letter _x_ which takes on any number given a set of conditions or a state. A variable is defined using the `=` operator:

<pre><code><strong># Defining a variable
</strong>x = 10
<strong># Writing a constant
</strong>6
</code></pre>

Running (executing) the previous code will store the variable _x_ with its respective value in the variable explorer. Simultaneously, the output of the code will be 6. Variables are case sensitive, therefore:

<pre><code><strong># Declaring my_variable
</strong>my_variable = 1
<strong># Declaring My_variable
</strong>My_variable = 2
<strong># The variable my_variable is different from My_variable
</strong></code></pre>

Variable declaration cannot start with a number but it can contain one in the middle or the end of its name:

<pre><code><strong># Returns a SyntaxError
</strong>1x = 5
<strong># Valid declaration
</strong>x1 = 5
<strong># Valid declaration
</strong>x1x = 5
</code></pre>

Variables can also contain underscores, but nothing else:

<pre><code><strong># Returns a SyntaxError
</strong>x-y = 5
<strong># Valid declaration
</strong>x_y = 5
</code></pre>

It is heavily recommended that variables have short and straightforward names. For example, consider creating the variable that holds the lookback period of a certain moving average (a technical indicator introduced in [Chapter 5](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch05.html#ch05)):

<pre><code><strong># Recommended name
</strong>ma_lookback = 10
<strong># Not recommended name
</strong>the_lookback_on_that_moving_average = 10
</code></pre>

There are several different data types with different characteristics:

_Numerical data types_This is simplest data type. It is formed exclusively from numbers. Numerical data types are divided into integers, float numbers, and complex numbers. _Integers_ are simple whole numbers (positive or negative). An example of an integer would be 6 or -19. _Float numbers_ are more precise than integers as they incorporate the values after the comma. An example of a float number would be 2.7 and -8.09. _Complex numbers_ include imaginary numbers[1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#id249)._Strings_As you have seen previously with comments and docstrings, it is possible to write text next to the code without it interfering with the execution process. _Strings_ are text structures that represent sequences of characters. Strings can be inputs and arguments of functions and not necessarily just comments._Booleans_Boleans are a binary (true or false) data type used to evaluate the truth value of the given expression or condition. For example, you can use Booleans to evaluate whether the market price is above or below the 100-period moving average._Data collection_These are sequences that contain multiple data with each having a different and unique usage. An _array_ is a sequence of elements of the same type (mostly numerical). Arrays will be used frequently in this book (with a Python library called `numpy` that is discussed in this chapter). A _data frame_ is a two-dimensional table of structured data that is also frequently used in this book (with a Python library called `pandas` also discussed in this chapter). A _set_ is a sequence of unordered elements. A _list_ is an ordered collection of elements that can be of different data types. A _tuple_ is an ordered, immutable collection of elements that may be of different data types. It is used for storing a fixed sequence of values. A _dictionary_ represents a collection of key-value pairs grouped together.

The following code snippet shows a few examples of the numerical data type:

<pre><code><strong># Creating a variable that holds an integer
</strong>my_integer = 1
<strong># Creating a variable that holds a float number
</strong>my_float_number = 1.2
<strong># Using the built-in Python function type() to verify the variables
</strong>type(my_integer)
type(my_float_number)
</code></pre>

The output should be as follows (note that the two created variables will appear in the variable explorer):

<pre><code><strong>int # The output of type(my_integer)
</strong><strong>float # The output of type(my_float_number)
</strong></code></pre>

Strings are simply text. The most famous example of explaining a string is the "_Hello World_" phrase:

<pre><code><strong># Outputting the phrase Hello World
</strong>print('Hello World')
</code></pre>

The output should be as follows:

```
Hello World
```

Strings can also be used as arguments in functions, as you will see later in this chapter.

Booleans are either true or false values. The following code snippet shows an example of using them:

<pre><code><strong># Make a statement that the type of my_integer is integer
</strong>type(my_integer) is int
<strong># Make a statement that the type of my_float_number is float
</strong>type(my_float_number) is float
<strong># Make a statement that the type of my_integer is float
</strong>type(my_integer) is float
'''
Intuitively, the two first statements will return True as they are 
indeed true. The third statement is False as the variable my_integer
is an integer and not a float number
'''
</code></pre>

The output of the previous code is as follows:

```
True
True
False
```

Let’s discuss how operators work. You have actually already seen an example of an operator, which is the assignement operator `=` used to defined variables. _Operators_ perform special mathematical and other tasks between variables, constants, and even data structures. There are different types of operators. Let’s start with _arithmetic operators_ as shown in the following snippet:

<pre><code><strong># Arithmetic operator - Addition
</strong><strong>1 + 1 # The line outputs 2
</strong><strong># Arithmetic operator - Subtraction
</strong><strong>1 - 1 # The line outputs 0
</strong><strong># Arithmetic operator - Multiplication
</strong><strong>2 * 2 # The line outputs 4
</strong><strong># Arithmetic operator - Division
</strong><strong>4 / 2 # The line outputs 2.0 as a float number
</strong><strong># Arithmetic operator - Exponents
</strong><strong>2 ** 4 # The line outputs 16
</strong></code></pre>

The next type of operators is the _comparison operators,_ which are used to compare different elements. They are mostly used in control flow events as explained in the next section of this chapter. The following snippet shows a few comparison operators:

<pre><code><strong># Comparison operator - Equality
</strong><strong>2 == 2 # The line outputs True
</strong><strong># Comparison operator - Non equality
</strong><strong>2 != 3 # The line outputs True
</strong><strong># Comparison operator - Greater than
</strong><strong>2 > 3 # The line outputs False
</strong><strong># Comparison operator - Greater than or equal to
</strong><strong>2 >= 2 # The line outputs True
</strong><strong># Comparison operator - Less than
</strong><strong>2 &#x3C; 3 # The line outputs True
</strong><strong># Comparison operator - Less than or equal to
</strong><strong>2 &#x3C;= 2 # The line outputs True
</strong></code></pre>

_Logical operators_ combine two or more conditions that are later evaluated. There are three logical operators: `and`, `or`, and `not`. The following code block shows an example of logical operators:

<pre><code><strong># Logical operator - and
</strong><strong>2 and 1 &#x3C; 4 # The line outputs True
</strong><strong>2 and 5 &#x3C; 4 # The line outputs False
</strong><strong># Logical operator - or
</strong><strong>2 or 5 &#x3C; 4 # The line outputs 2 which is the integer less than 4
</strong></code></pre>

Data collection structures (arrays and data frames) are discussed in a later section, as they require an in-depth presentation due to their complexity and unique tools. Let’s end this section with code that combines what has been discussed so far:

<pre><code><strong># Declaring two variables x and y and assigning them values
</strong>x = 10
y = 2.5
<strong># Checking the types of the variables
</strong><strong>type(x) # Returns int
</strong><strong>type(y) # Returns float
</strong><strong># Taking x to the power of y and storing it in a variable z
</strong><strong>z = x ** y # Returns 316.22
</strong><strong># Checking if the result is greater than or equal to 100
</strong><strong>z >= 100 # Returns True as 316.22 >= 100
</strong></code></pre>

## Control Flow

Conditional statements form the first part of what is known as _control flow_ (the second part is _loops_). _Conditional statements_ are the ancestors of today’s artificial intelligence as they only execute code if certain conditions are met.

Conditional statements are managed using `if`, `elif`, and `else`. Take the following code snippet as an example:

<pre><code><strong># Declaring the variables
</strong>a = 9
b = 2
<strong># First condition (specific)
</strong>if a > b:  
    print('a is greater than b')
<strong># Second condition (specific)    
</strong>elif a &#x3C; b:  
    print('a is lower than b')
<strong># Third condition (general)    
</strong>else:  
    print('a is equal to b')
</code></pre>

Therefore, conditional statements start with `if`, and then for every new unique and specific condition, `elif` is used (it is a fusion between _else if_), until it makes sense to use the rest of the probability universe as a condition on its own, which is used by the `else` statement. Note that the `else` statement does not need a condition as it exists to cover the rest of the uncovered universe.

_Loops_ are used to execute blocks of code repeatedly until a pre-defined condition is met. Loops are heavily used with time series to calculate indicators, verify states, and to back-test trading strategies.

Loops are managed using `for` (for iterating over a finite and defined sequence or a range of elements) and `while` (used to continue the iteration until a condition is met) statements. For example, the following code prints the values {1, 2, 3, 4} using a loop:

<pre><code><strong># Using a for loop
</strong>for i in range(1, 5):
    print(i) 
<strong># Using a while loop  
</strong>i = 1    
while i &#x3C; 5:
    print(i)
    i = i + 1
</code></pre>

The `for` loop when translated is simply saying that for every element which is called `i` (or any other letter depending on the coder) in the range that starts at 1 and ends at 5 (excluded), print the value of `i` at every loop (hence, in the first loop, the value of `i` is equal to 1 and in the second loop, it is equal to 2).

The `while` loop says that starting from a value of `i = 1`, while looping, print its value and then add 1 to it before finishing the first loop. End the loop when `i` becomes greater than 4.

**NOTE**

Theoretically, a `while` loop is infinite until told otherwise.

It is worth noting that `i = i + 1` can also be expressed as `i += 1`. The goal of an algorithm is the ability to apply many operations recursively in an objective way, which makes loops extremly useful especially when combined with conditional statements. Let’s look at an example of a financial time series:

1. Create a range of values to simulate hypothetical prices.
2. Loop through the range of the data while creating the condition that if the price rose from the last period, print 1. Similarly, if the price fell from the last period, print -1. Lastly, print 0 if the price didn’t change from last period.

This can be done in the following code block:

<pre><code><strong># Creating the time series
</strong>time_series = [1, 3, 5, 2, 4, 1, 6, 4, 2, 4, 4, 4]
for i in range(len(time_series)):
<strong>    # The condition where the current price rose
</strong>    if time_series[i] > time_series[i - 1]:  
        print(1)
<strong>    # The condition where the current price fell
</strong>    elif time_series[i] &#x3C; time_series[i - 1]:
        print(-1) 
<strong>    # The condition where the current price hasn't changed
</strong>    else: 
        print(0)
</code></pre>

The code defines a list of values (in this case, a time series called `time_series`), then loops around its length using the `len()` function to apply the conditions. Notice how at every loop, the current time step is referred to as `i` , thus making the previous time step `i - 1`.

## Libraries and Functions

A _library_ in Python is a group of pieces of pre-written code that offers functionality to make the creation of applications easier. _Modules_, which are individual Python files with reusable code and data that can be imported and used in other Python code, are commonly found in libraries. A module is therefore a single Python file that contains functions and other types of code that may be used and imported by other Python programs. Large code bases are often easier to manage and maintain by using modules to divide similar code into different files.

Coding is all about simplifying tasks and making them clearer. When you have a recurring task such as calculating a moving average of a time series, you can use a function so that you do not have to write the moving average code all over again every time you want to use it. Instead, you define the function with the original code and then, you call it whenever you need to calculate the moving average. But what is a _function_? It is a block of reusable code that performs a specific task when called. It needs to be defined once.

Multiple functions form a module, and multiple modules form a library. A library is generally theme-oriented. For example, in this book, `sklearn` library will be used with machine learning models. Similarly, data manipulation and importing are done using `numpy` and `pandas`, two libraries discussed in a later section of this chapter. Plotting and charting are done using `matplotlib` library.

Libraries must be imported first to the Python interpreter before you can use them (this is the equivalent of acknowledging their existence). The syntax for doing this is as follows:

<pre><code><strong># The import statement must be followed by the name of the library
</strong>import numpy
<strong># Optionally, you can give the library a shortcut for easier references
</strong>import numpy as np
</code></pre>

Sometimes, you need to import just one function or module from a library. For this, you don’t need to import the totality of the library:

<pre><code><strong># Importing one function from a library
</strong>from math import sqrt
</code></pre>

So, it is established that `math` is a Python library that harbors many mathematical functions, namely the `sqrt` function which is used to find the square root of a given number.

Let’s see how to define a function. A function is defined using `def` followed by the name of the function and any optional arguments. The following example creates a function that sums any two given variables:

<pre><code><strong># Defining the function sum_operation and giving it two arguments
</strong>def sum_operation(first_variable, second_variable):
<strong>    # Outputing the sum of the two variables
</strong>    print(first_variable + second_variable)
<strong># Calling the function with 1 and 3 as arguments
</strong><strong>sum_operation(1, 3) # The output of this line is 4
</strong></code></pre>

**NOTE**

_Calling_ a function means executing what it’s supposed to do. In other words, calling a function is simply using it. The timeline of a function is getting defined and then getting called.

Let’s see how to import a function from a library and use its functions:

<pre><code><strong># Importing the library    
</strong>import math
<strong># Using the natural logarithm function
</strong>math.log(10)
<strong># Using the exponential function (e)
</strong>math.exp(3)
<strong># Using the factorial function
</strong>math.factorial(50)
</code></pre>

As a side note, the _factorial_ operation is a mathematical operation that is used to calculate the product of all positive integers from 1 up to a certain number (which is the argument requested in `math.factorial()`).

Libraries may not be as easy as one plus one. Sometimes, external libraries require installation first before they can be imported to the Python interpreter. Installation can be done through the prompt using the following syntax:

```
pip install library_name
```

Recall [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03) where the MIC was discussed. To calculate the MIC, you can use the following code (after having defined the sine and cosine waves):

<pre><code><strong># Importing the library
</strong>from minepy import MINE
<strong># Calculating the MIC
</strong>mine = MINE(alpha = 0.6, c = 15)
mine.compute_score(sine, cosine)
MIC = mine.mic()
print('Correlation | MIC: ', round(MIC, 3))
</code></pre>

Importing the library directly will likely lead to an error as it has not been `pip` installed. Therefore, you must install it first using the following syntax at the prompt (not in the Python interpreter):

```
pip install minepy
```

**NOTE**

You may need to update Microsoft Visual C++ (at least version 14.0 or greater) to avoid any errors in trying to run `minepy`library.

It is also important to read the documentation that comes with libraries in order to use them correctly. _Documentation_ helps in knowing the aim of the functions and what arguments go inside. Furthermore, it tells you what type of arguments the function can accept (for example, strings or numerics). Let’s go back to functions now (notice how both are intertwined and discussing one may result in discussing the other).

Functions can have a `return` statement which allows the result to be stored in a variable so that it can be used in other parts of the code. Let’s take two simple examples and then discuss them step-by-step:

<pre><code><strong># Defining a function to sum two variables and return the result
</strong>def sum_operation(first_variable, second_variable):
<strong>    # The summing operation is stored in a variable called final_sum
</strong>    final_sum = first_variable + second_variable
<strong>    # The result is returned
</strong>    return final_sum
<strong># Create a new variable that holds the result of the function    
</strong>summed_value = sum_operation(1, 2)
<strong># Use the new variable in a new mathematical operation
</strong>double_summed_value = summed_value * 2
</code></pre>

The previous code defines the `sum_operation` function with two arguments, then stores the operation in a variable called `final_sum` before returning it so it can be stored externally. Afterwards, a new variable called `summed_value` is defined as the output of the function. Finally, another variable is created under the name of `double_summed_value` and is the result of `summed_value` multiplied by 2. This is an example of how to use results from functions as variables in external operations. Now, let’s consider another example (while keeping in mind the previously defined `sum_operation` function):

<pre><code><strong># Defining a function to square the result gotten from sum_operation()
</strong>def square_summed_value(first_variable, second_variable):
<strong>    # Calling the nested sum_operation function and storing its result
</strong>    final_sum = sum_operation(first_variable, second_variable) 
<strong>    # Creating a variable that stores the square of final_sum
</strong>    squared_sum = final_sum ** 2
<strong>    # The result is returned    
</strong>    return squared_sum
<strong># Create a new variable that holds the result of the function   
</strong>squared_summed_value = square_summed_value(1, 2)
</code></pre>

The preceding code snippet defines a function called `square_summed_value` which takes on two arguments. Furthermore, it uses a nested function inside, which in this case is `sum_operation`. The result of the nested function is once again stored in a variable called `final_sum` , which is used as an input in finding the `squared_sum variable`. The variable is found as `final_sum` to the power of two. This was an example of how to create functions out of other functions inside of them (in other words, nested functions).

Let’s end the section with common libraries in Python and machine learning (other than `numpy` and `pandas`):

<pre><code><strong>matplotlib # For plotting and visualizing data
</strong><strong>sklearn    # For machine learning models
</strong><strong>scipy      # For scientific computing and optimization
</strong><strong>keras      # For neural networks
</strong><strong>math       # For using mathematical tools such as square roots
</strong><strong>random     # For generating random variables
</strong><strong>requests   # For making HTTP requests used in web scraping
</strong></code></pre>

## Exception Handling and Errors

Quite often you will run into errors due to issues with the code during execution. In other words, errors occur when the code is executed and the interpreter finds an obstacle that prevents it from continuing further. The most basic error is _SyntaxError,_ which occurs when there are misspelled words or missing elements that make the code unintelligible:

<pre><code><strong># Will not output a SyntaxError if executed
</strong>my_range = range(1, 10)
<strong># Will output a SyntaxError is executed
</strong>my_range = range(1, 10
</code></pre>

As you can see from the previous code, there is a missing parenthesis at the end of the second code line, which is not understood by the interpreter. This type of error is likely to be your most common one. Another common error is _NameError_ which occurs when failing to define a variable before executing a code that contains it. Consider the following example:

```
x + y
```

The previous code will give you a _NameError_ because the interpreter does not know the value of `x` and `y` since they were not defined.

The _ModuleNotFoundError_ occurs when the interpreter cannot find the library or module you are trying to import. This generally occurs when it is installed in the bad directory or when it is not properly installed. Common fixes for this issue include:

* Verifying if the module’s name has been written correctly.
* Verifying if the module has been correctly `pip` installed.
* Verifying if the module is installed in the correct location.

Another type of common error is _TypeError,_ and it occurs when you apply a certain operation on an incompatible element such as summing an integer with a string. The following operation raises a _TypeError_:

<pre><code><strong># Defining variable x
</strong>x = 1
<strong># Defining variable y
</strong>y = 'Hello
<strong># Summing the two variables which will raise a TypeError
</strong>x + y
</code></pre>

In time series analysis, you will likely to encounter these four errors:

* _IndexError_: This is raised when referring to an index that is out of range regarding the current array or data frame. Imagine having an array of 300 values (rows). If you want to loop through them and at each loop, you want to input the number 1 in the next cell (time step + 1), you are likely to encounter an _IndexError_ as in the last loop there is no next cell, and the interpreter will raise this error.
* _ValueError_: This is raised when you try to call a function with an invalid argument. An example of this would to be try to pass an integer element as a string when calling a function.
* _KeyError_: This occurs when trying to access an element in a data frame that does not exist. For example, if you have three columns in the data frame and you refer to one that does not exist (maybe due to a syntax issue), you are likely to run into a _KeyError_.
* _ZeroDivisionError_: This error is intuitive and occurs when trying to divide a number by zero.

There are other types of errors that you may encounter. It is important to understand what they refer to so that you are able to fix them.

_Exceptions_ on the other hand may be not fatal to the code in the sense that they only show a warning but don’t necessarily terminate the code. Therefore, exceptions occur during the execution (as opposed to errors which occur because the interpreter is unable to execute).

**NOTE**

Understanding the error will help you fix it and get the code running again.

To ignore certain exceptions (and errors), the `try`  and `except` keywords are used. This is useful when you are certain that handling the exception will not alter the output of the code. Let’s take an example of creating a function that divides the first column of a time series by the next value of the second column. The first step is to define the time series as a data frame or as an array (or any other data collection structure):

<pre><code><strong># Importing the required library to create an array
</strong>import numpy as np
<strong># Creating a two-column list with 8 rows
</strong>my_time_series = [(1, 3), 
                  (1, 4), 
                  (1, 4), 
                  (1, 6), 
                  (1, 4), 
                  (0, 2), 
                  (1, 1), 
                  (0, 6)]
<strong># Transforming the list into an array
</strong>my_time_series = np.array(my_time_series)
</code></pre>

Now, let’s write the division function that will take any value in the first column and divide it by the next value in the second column:

<pre><code><strong># Defining the function
</strong>def division(first_column, second_column):
<strong>    # Looping through the length of the created array
</strong>    for i in range(len(my_time_series)):
<strong>        # Division operation and storing it in the variable x
</strong>        x = my_time_series[i, first_column] / 
            my_time_series[i + 1, second_column]
<strong>        # Outputting the result
</strong>        print(x)
<strong># Calling the function
</strong>division(0, 1)
</code></pre>

Running the two previous code blocks will give an _IndexError_ because in the last loop, the function cannot find the next value of the second column because it does not exist:

```
IndexError: index 8 is out of bounds for axis 0 with size 8
```

Fixing this through `try` and `except` will ignore the last calculation that is causing the problem and will return the expected results:

<pre><code><strong># Defining the function
</strong>def division(first_column, second_column): 
<strong>    # Looping through the length of the created array    
</strong>    for i in range(len(my_time_series)): 
<strong>        # First part of the exception handling
</strong>        try:
<strong>            # Division operation and storing it in the variable x
</strong>            x = my_time_series[i, first_column] / 
                my_time_series[i + 1, second_column] 
<strong>            # Outputting the result            
</strong>            print(x)       
<strong>        # Exception handling of a specific error     
</strong>        except IndexError:
<strong>            # Ignoring (passing) the error
</strong>            pass
<strong># Calling the function
</strong>division(0, 1)
</code></pre>

The output is as follows:

```
0.25
0.25
0.16
0.25
0.50
0.00
0.16
```

## Data Structures in Numpy and Pandas

You now understand what a library is and, therefore, you know that these two are the go-to libraries to manipulate, handle, and import data in Python. This section shows the differences between the two and their key functions that are definitely a great addition to your data analysis. But first, let’s define these two libraries:

_numpyNumPy_ (short for Numerical Python) is a Python library that allows working with multi-dimensional arrays and matrices. NumPy provides a powerful  interface for performing various operations on arrays and matrices._pandasPandas_ (short for Panel Data) is a Python library that allows working with data frames (a type of tabular data). Pandas provides two main data structures: series and data frames. A _series_ is a one-dimensional array-like object that can hold any data type. A _data frame_ is a two-dimensional table-like structure that consists of rows and columns (similar to a spreadsheet).

Both libraries are very useful in analyzing time series data. Arrays hold only numerical type data and therefore do not really hold date type data as opposed to data frames. This may be one of the advantages of using `pandas` over `numpy` but both have the strengths and relative weaknesses. In the end, it is a matter of choice. This book will prioritize using `numpy` due to the simplicity and due to the fact that the machine learning models seen in the next chapter use `sklearn` library which is applied on arrays.

**NOTE**

Switching between `numpy` and `pandas` requires converting the time series type. It is a relatively easy task but can sometimes cause loss of certain types of data (for example, date data).

Let’s import both libraries before starting to see some of their potential:

```
import numpy as np
import pandas as pd
```

The following code creates two time series with two columns and three rows. The first time series is called `my_data_frame` and is created using the function `pd.DataFrame` of `pandas`. The second time series is called `my_array` and is created using the function `np.array` of `numpy`:

<pre><code><strong># Creating a data frame
</strong>my_data_frame = pd.DataFrame({'first_column' : [1, 2, 3], 
                              'second_column' : [4, 5, 6]})
<strong># Creating an array
</strong>my_array = np.array([[1, 4], [2, 5], [3, 6]])
</code></pre>

As can be seen from [Figure 6-2](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#figure-6-2), data frames have real indexes and can have column names. Arrays can only hold one type of data:

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0602.png" alt="" height="264" width="600"><figcaption></figcaption></figure>

**Figure 6-2. On the left, a data frame (pandas) and on the right, an array (numpy)**

To switch between the two types of data, you will be using the same two functions used in the previous code block:

<pre><code><strong># To transform my_data_frame into my_new_array
</strong>my_new_array = np.array(my_data_frame)
<strong># To transform my_array into my_new_data_frame
</strong>my_new_data_frame = pd.DataFrame(my_array)
</code></pre>

Let’s now take a look at useful functions that will come in handy when dealing with models. Slicing, concatenating, and other tools are things that you must master in order to smoothly navigate through the data analysis part. Consider the following arrays:

```
first_array  = np.array([ 1,  2,  3,  5,   8,  13])
second_array = np.array([21, 34, 55, 89, 144, 233])
```

_Concatenation_ is the act of fusing two datasets together either through rows (axis = 0) or through columns (axis = 1). Let’s do both of them:

<pre><code><strong># Reshaping the arrays so they become dimensionally compatible
</strong>first_array  = np.reshape(first_array, (-1, 1))
second_array = np.reshape(second_array, (-1, 1))
<strong># Concatenating both arrays by columns
</strong>combined_array = np.concatenate((first_array, second_array), axis = 1)
<strong># Concatenating both arrays by rows
</strong>combined_array = np.concatenate((first_array, second_array), axis = 0)
</code></pre>

Now, let’s do the same thing for data frames. Consider the following data frames:

```
first_data_frame  = pd.DataFrame({'first_column'  : [ 1,  2,  3], 
                                  'second_column' : [ 4,  5,  6]})
second_data_frame = pd.DataFrame({'first_column'  : [ 7,  8,  9], 
                                  'second_column' : [10, 11, 12]})
```

Concatenation is useful when you want to combine data into one structure. This is how it can be done with data frames (notice how it’s simply a change of syntax and function source):

<pre><code><strong># Concatenating both data frames by columns
</strong>combined_data_frame = pd.concat([first_data_frame, second_data_frame], 
                                axis = 1)
<strong># Concatenating both data frames by rows
</strong>combined_data_frame = pd.concat([first_data_frame, second_data_frame], 
                                axis = 0)
</code></pre>

Remember that with time series, _rows_ (horizontal cells) represent one time step (for example, hourly) with all the data inside, while _columns_ represent the different types of data (for example, open price and close price of a financial instrument). Now let’s see slicing techniques for arrays:

<pre><code><strong># Defining a one-dimensional array
</strong>my_array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
<strong># Referring to the first value of the array
</strong><strong>my_array[0] # Outputs 1
</strong><strong># Referring to the last value of the array
</strong><strong>my_array[-1] # Outputs 1​0
</strong><strong># Referring to the sixth value of the array
</strong><strong>my_array[6] # Outputs 7
</strong><strong># Referring to the first three values of the array
</strong><strong>my_array[0:3] # Outputs array([1, 2, 3])
</strong><strong>my_array[:3]  # Outputs array([1, 2, 3])
</strong><strong># Referring to the last three values of the array
</strong><strong>my_array[-3:] # Outputs array([8, 9, 10])
</strong><strong># Referring to all the values as of the second value
</strong><strong>my_array[1:] # Outputs array([2, 3, 4, 5, 6, 7, 8, 9, 10])
</strong><strong># Defining a multi-dimensional array
</strong>my_array = np.array([[ 1,  2,  3,  4,  5], 
                     [ 6,  7,  8,  9, 10], 
                     [11, 12, 13, 14, 15]])
<strong># Referring to the first value and second column of the array
</strong><strong>my_array[0, 1] # Outputs 2
</strong><strong># Referring to the last value and last column of the array
</strong><strong>my_array[-1, -1] # Outputs 15
</strong><strong># Referring to the third value and second to last column of the array
</strong><strong>my_array[2, -2] # Outputs 14
</strong><strong># Referring to the first three and fourth column values of the array
</strong><strong>my_array[:, 2:4] # Outputs array([[3, 4], [8, 9], [13, 14]])
</strong><strong># Referring to the last two values and fifth column of the array
</strong><strong>my_array[-2:, 4] # Outputs array([10, 15])
</strong><strong># Referring to all the values and all the columns up until the second row
</strong><strong>my_array[:2, ] # Outputs array([[ 1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
</strong><strong># Referring to the last row with all the columns
</strong><strong>my_array[-1:, :] # Outputs array([[11, 12, 13, 14, 15]])
</strong></code></pre>

**NOTE**

It is important to know that Python indexing starts at zero. This means that to refer to the first element in a data structure, you refer to its index as index = 0. On another note, it is also worth noting that in ranges, the last element is excluded, which means that the first three elements in a data structure are referred to as `[0, 3]` , which will give the elements indexed at 0, 1, and 2.

Let’s see the same thing for data frames so that this section becomes a sort of a mini encyclopedia whenever you want to manipulate data structures:

<pre><code><strong># Defining a one-dimensional data frame
</strong>my_df= pd.DataFrame({'first_column': [1, 2, 3, 4, 5, 
                                      6, 7, 8, 9, 10]})
<strong># Referring to the first value of the data frame
</strong><strong>my_df.iloc[0]['first_column'] # Outputs 1
</strong><strong># Referring to the last value of the data frame
</strong><strong>my_df.iloc[-1]['first_column'] # Outputs 10
</strong><strong># Referring to the sixth value of the data frame
</strong><strong>my_df.iloc[6]['first_column'] # Outputs 7
</strong><strong># Referring to the first three values of the data frame
</strong><strong>my_df.iloc[0:3]['first_column'] # Outputs ([1, 2, 3])
</strong><strong># Referring to the last three values of the data frame
</strong><strong>my_df.iloc[-3:]['first_column'] # Outputs ([8, 9, 10])
</strong><strong># Referring to all the values as of the second value
</strong><strong>my_df.iloc[1:]['first_column'] # Outputs ([2, 3, 4, 5, 6, 7, 8, 9, 10])
</strong><strong># Defining a multi-dimensional data frame
</strong>my_df  = pd.DataFrame({'first_column'  : [ 1,  6,  11], 
                       'second_column' : [ 2,  7,  12],
                       'third_column'  : [ 3,  8,  13],
                       'fourth_column' : [ 4,  9,  14],
                       'fifth_column'  : [ 5,  10, 15]})
<strong># Referring to the first value and second column of the data frame
</strong><strong>my_df.iloc[0]['second_column'] # Outputs 2
</strong><strong># Referring to the last value and last column of the data frame
</strong><strong>my_df.iloc[-1]['fifth_column'] # Outputs 15
</strong><strong># Referring to the third value and second to last column of the data frame
</strong><strong>my_df.iloc[2]['fourth_column']​ # Outputs 14
</strong><strong># Referring to the first three and fourth column values of the data frame
</strong>my_df.iloc[:][['third_column', 'fourth_column']]
<strong># Referring to the last two values and fifth column of the data frame
</strong><strong>my_df.iloc[-2:]['fifth_column']​ # Outputs ([10, 15])
</strong><strong># Referring to all the values and all the columns up until the second row
</strong><strong>my_df.iloc[:2,] # Outputs ([[ 1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
</strong><strong># Referring to the last row with all the columns
</strong><strong>my_df.iloc[-1:,]  # Outputs ([[11, 12, 13, 14, 15]])
</strong></code></pre>

**NOTE**

Try going back to the earlier chapters to execute the code given there. You should have a more solid understanding by now.

## Importing Financial Time Series in Python

This section presents a key part in deploying machine and deep learning algorithms. It deals with the historical OHLC data that is needed to run the models and evaluate their performance.

The first step is to prepare the environment and everything else necessary for the success of the algorithms. For this, you need two programs:

* A Python interpreter that you use to write and execute code. You have already completed this step.
* Charting and financial software that you use as a database. This part is covered in this section.

Throughout many parts in the book, I use MetaTrader 5, a benchmark charting program used by many traders around the globe. Follow these steps:

1. Download Spyder and familiarize yourself with how it works.
2. Download the MetaTrader 5 software.
3. Use Spyder to import historical prices from MetaTrader 5.

From the [official website](https://www.metatrader5.com/en), download and install MetaTrader 5. You need to create a demo account, which is simply a virtual account with imaginary money. The word _demo_ does not refer to a limited duration of use but to the fact that it is not using real money.

To open an account, select File > Open an Account, choose MetaQuotes Software Corp, and then click Next. Then, choose the first option to open a demo account; this will let you trade virtual money. Finally, enter some basic information such as name, email, and account type. You will not receive a verification request or any type of confirmation as the demo should launch directly, allowing you to see the charts.

[Figure 6-3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#figure-6-3) shows the platform’s interface. By default, MetaTrader 5 does not show all the markets it covers, so you need to make them accessible for import and visualization if necessary. Click View, click Market Watch, and then right-click any of the symbols shown in the new tab and choose Show All. This way you can see the extended list with more markets.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0603.png" alt="" height="461" width="600"><figcaption></figcaption></figure>

**Figure 6-3. MetaTrader’s 5 interface**

Before proceeding to the coding part, you need to install the MetaTrader 5 Python integration library so you can use it later in Spyder. This is easy and requires one step. Open the Anaconda prompt and type:

```
pip install MetaTrader5
```

Installation is the bridge that allows you to use Python modules and functions designed for MetaTrader 5 in the interpreter.

The following code block uses the `import` built-in statement, which calls for internal (self-created) or external (created by third parties) libraries. You’ll recall that a library is a store of functions, and thus, you need to import the libraries that are pertinent to what you want to do. For demonstration purposes, import the following modules, packages, and libraries:

<pre><code><strong>import datetime # Gives tools for manipulating dates and time
</strong><strong>import pytz # Offers cross-platform time zone calculations
</strong><strong>import MetaTrader5 as mt5 # Importing the software's library
</strong>import pandas as pd
import numpy as np 
</code></pre>

The next step is to create the universe of the time frames that you will be able to import. Even though I will be showing you how to analyze and back-test hourly data, you can define a wider universe, as shown in the following code snippet:

<pre><code><strong>frame_M15 = mt5.TIMEFRAME_M15      # 15-minute time
</strong><strong>frameframe_M30 = mt5.TIMEFRAME_M30 # 30-minute time frame
</strong><strong>frame_H1 = mt5.TIMEFRAME_H1        # Hourly time frame
</strong><strong>frame_H4 = mt5.TIMEFRAME_H4        # 4-hour time frame
</strong><strong>frame_D1 = mt5.TIMEFRAME_D1        # Daily time frame
</strong><strong>frame_W1 = mt5.TIMEFRAME_W1        # Weekly time frame
</strong><strong>frame_M1 = mt5.TIMEFRAME_MN1       # Monthly time frame
</strong></code></pre>

**NOTE**

The full code is found in the GitHub repository under the name _master\_function.py._

A _time frame_ is the frequency with which you record the prices. With hourly data, you will record the last price printed every hour. This means that in a day, you can have up to 24 hourly prices. This allows you to see the intraday evolution of the price. The aim is to record the totality of the OHLC data within a specific period.

The following code defines the current time, which is used so that the algorithm has a reference point when importing the data. Basically, you are creating a variable that stores the current time and date:

```
now = datetime.datetime.now()
```

Let’s now proceed to defining the universe of the financial instruments you want to back-test. In this book, the back-tests will be done exclusively on the FX market. So, let’s create a variable that stores some key currency pairs:

```
assets = ['EURUSD', 'USDCHF', 'GBPUSD', 'USDCAD']
```

Now that you have your time and asset variables ready, all you need is to create the structure of the importing algorithm. The `get_quotes()` function does this:

```
def get_quotes(time_frame, year = 2005, month = 1, day = 1, 
               asset = "EURUSD"):
    if not mt5.initialize():   
        print("initialize() failed, error code =", mt5.last_error())
        quit()
    timezone = pytz.timezone("Europe/Paris")
    time_from = datetime.datetime(year, month, day, tzinfo = timezone)   
    time_to = datetime.datetime.now(timezone) + datetime.timedelta(days=1)
    rates = mt5.copy_rates_range(asset, time_frame, time_from, time_to)
    rates_frame = pd.DataFrame(rates)
    return rates_frame
```

Notice that in the `get_quotes()` function, you use the `pytz` and `pandas` libraries. The function starts by defining the _Olson_ time zone, which you can set yourself. Here is a brief, nonexhaustive list of what you can enter depending on your time zone:

```
America/New_York
Europe/London
Europe/Paris
Asia/Tokyo
Australia/Sydney
```

Afterward, I define two variables called `time_from` and `time_to`:

* The `time_from` variable contains the datetime referring to the beginning of the import date (e.g., 01-01-2020).
* The `time_to` variable contains the datetime referring to the end of the import date which uses the `now` variable to represent the current time and date.

The next step is to create a variable that imports the financial data using the time periods you have specified. This is done through the `rates` variable using the `mt5.copy_rates_range()` function. Finally, using `pandas`, transform the data into a data frame. The final function required for the importing process is the `mass_import()` function. It lets you choose the time frame using the variable and then uses the `get_quotes()` function to import the data and format it to an array. The following code snippet defines the `mass_import()` function:

```
def mass_import(asset, time_frame):               
    if time_frame == 'H1':
        data = get_quotes(frame_H1, 2013, 1, 1, asset = assets[asset])
        data = data.iloc[:, 1:5].values
        data = data.round(decimals = 5)           
    return data 
```

The `mass_import()` function automatically converts the data frame into an array, so you do not have to worry about conversion when using the automatic import.

**NOTE**

You may need to adjust the year argument higher in order to get the data in case you have an empty array. For instance, if you get an empty array using the `mass_import()` function, try putting a more recent year in the `get_quotes()` function (“2014” instead of “2013”).

To import the historical hourly EURUSD data since beginning of 2014 to date, you may type the following (assuming `get_quotes()`, `now`, the frames, and the libraries are already defined):

<pre><code><strong># Defining the universe of currency pairs
</strong>assets = ['EURUSD', 'USDCHF', 'GBPUSD', 'USDCAD']
<strong># Re-defining the mass_import function to switch to a default 2014
</strong>def mass_import(asset, time_frame):                
    if time_frame == 'H1':
        data = get_quotes(frame_H1, 2014, 1, 1, asset = assets[asset])
        data = data.iloc[:, 1:5].values
        data = data.round(decimals = 5)  
<strong># Calling the mass_import function and storing it into a variable
</strong>eurusd_data = mass_import(0, 'H1')
</code></pre>

**NOTE**

Notice how the `return` statement is used in the `mass_import` function in order to store the historical data in chosen variables.

Even though there is a macOS version of MetaTrader 5, the Python library only works on Windows. It requires a Windows emulator on a macOS. For macOS oe Linux users, you may want to try the manual import method (or the alternative way proposed in [Chapter 7](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch07.html#ch07) that uses a library called `pandas-datareader`).

Automatic import is a huge time saver but even Windows users may run into frustrating errors. For this, I will show you the manual import way which you can use as a fix. In the GitHub link[2](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#id250) for this book, you will find a folder called _Historical Data_. Inside the folder there is a selection of historical financial time series in Excel format, which you can download.

The manual way is to have an Excel file with OHLC data that you have downloaded from a third party (such as the Excel files provided in the GitHub repository). In this case, you can use the `pandas` library to import it and transform it into an array.

Let’s take an example of _Daily\_GBPUSD\_Historical\_Data.xlsx._ Download the file from the repository (found in Historical Data) and store it on your desktop. You now have to make sure that the Spyder’s directory is in the same place as the file (so, in the desktop). In layperson’s terms, Spyder must search the desktop for the Excel file. To choose the right directory, click the folder button next to the arrow, as shown in [Figure 6-4](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#figure-6-4).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0604.png" alt="" height="33" width="600"><figcaption></figcaption></figure>

**Figure 6-4. Directory tab**

You should get a separate window where you can choose the desktop location and then validate the choice. Having done this, the tab should look like [Figure 6-5](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#figure-6-5).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0605.png" alt="" height="32" width="600"><figcaption></figcaption></figure>

**Figure 6-5. Directory tab**

You use the `read_excel()` function (built-in in `pandas` and accessible after importing it) to get the values inside the Excel file. Follow this syntax:

<pre><code><strong># Importing the excel file into the Python interpreter
</strong>my_data = pd.read_excel('Daily_GBPUSD_Historical_Data.xlsx.xlsx')
</code></pre>

You should have a data frame called _Daily\_GBPUSD\_Historical\_Data.xlsx_ with five different columns representing open, high, low, and close prices. You generally have to enter the library’s name before using a function that belongs to it; this is why `read_excel()` is preceded by `pd`.

**NOTE**

I recommend using the automatic way for Windows users and the manual way for macOS users due to compatibility issues.

## Summary

Python, a major star among coding languages, enjoys widespread adoption by the developer community. Mastering it is key to unlocking huge potential in the data science world.

The next chapter discusses machine learning and different prediction algorithms. The main aim is to be able to code the algorithms and run a back-test over financial data. You will see that once you start understanding the process, it becomes a matter of removing an algorithm and plugging another (in case they have the same assumptions). The warm-up chapters are over, and it’s time to start coding.

[1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#id249-marker) Imaginary numbers are a type of complex number that represent the square root of a negative number.

[2](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch06.html#id250-marker) Link: https://github.com/sofienkaabar/deep-learning-for-finance
