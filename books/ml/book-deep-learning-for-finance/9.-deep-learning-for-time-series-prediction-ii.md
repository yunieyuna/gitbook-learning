# 9. Deep Learning for Time Series Prediction II

## Chapter 9. Deep Learning for Time Series Prediction II

This chapter presents a few techniques and methods to complement the forecasting task of machine and deep learning algorithms. It is composed of different topics that each discuss a way to improve and optimize the process. Naturally, up until now, you should have a sound understanding of the basics of machine and deep learning models, and you know how to code a basic algorithm that predicts the returns of a financial time series (or any stationary time series). This chapter bridges the gap between the basic knowledge and the advanced knowledge required to elevate the algorithms to a functional level.

## Fractional Differentiation

In his book, _Advances in Financial Machine Learning_, Marco Lopez de Prado (2009), described a technique to transform non-stationary data into stationary data. This is referred to as fractional differentiation.

_Fractional differentiation_ is a mathematical technique used to transform a time series into a stationary series while preserving some of its memory. It extends the concept of _differencing_ (or taking the returns), which is commonly used to remove trends and make time series stationary.

In traditional differencing, the data sequence is differenced by a whole number, typically 1, which involves subtracting the previous value from the current value. This helps eliminate trends and makes the series stationary. However, in some cases, the series may exhibit long-term dependencies or memory effects that are not effectively captured by traditional differencing. These dependencies may help in forecasting the time series, and if they are completely eliminated, that may hinder the ability of the algorithm to perform well. These dependencies are referred to as _memory_.

Fractional differentiation addresses this limitation by allowing the differencing parameter to be a fractional value. The fractional differencing operator effectively applies a weighted sum of lagged values to each observation in the series, with the weights determined by the fractional differencing parameter. This allows for capturing long-term dependencies or memory effects in the series. Fractional differentiation is particularly useful in financial time series analysis, where data often exhibit long memory or persistent behavior. This can be implemented in Python. First, `pip install` the required library from the prompt:

```
pip install fracdiff
```

Next, import the required libraries:

```
from fracdiff.sklearn import Fracdiff
import pandas_datareader as pdr
import numpy as np
import matplotlib.pyplot as plt
```

Let’s use the classic example that De Prado used in his book, the S\&P 500, to prove that fractional differentiation transforms a non-stationary time series into a stationary one with visible preserved memory.

The following code applies fractional differentiation and compares it to traditional differencing:

<pre><code><strong># Set the start and end dates for the data
</strong>start_date = '1990-01-01'
end_date   = '2023-06-01'
<strong># Fetch S&#x26;P 500 price data
</strong>data = np.array((pdr.get_data_fred('SP500', start = start_date, 
                                   end = end_date)).dropna())
<strong># Calculate the fractional differentiation
</strong>window = 100
f = Fracdiff(0.48, mode = 'valid', window = window)
frac_data = f.fit_transform(data)
<strong># Calculate a simple differencing function for comparison
</strong>diff_data = np.reshape(np.diff(data[:, 0]), (-1, 1))
<strong># Harmonizing time indices
</strong>data = data[window - 1:, ]
diff_data = diff_data[window - 2:, ]
</code></pre>

[Figure 9-1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-1) shows the three types of transformations. You can notice the trending nature in the first panel with the non-transformed S\&P 500 data. You can also notice that in the second panel, this trend is less visible but still there. This is what fractional differentiation aims to do. By keeping a hint of the market’s memory while rendering it stationary, this technique can help improve some forecasting algorithms. The third panel shows normal differencing of the price data.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0901.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-1. Fractional differentiation on S\&P 500 (order = 0.48)**

[Figure 9-1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-1) was generated using this code:

```
fig, axes = plt.subplots(nrows = 3, ncols = 1)
axes[0].plot(data[5:,], label = 'S&P 500', color = 'blue', linewidth = 1)
axes[1].plot(frac_data[5:,], label = 
             'Fractionally Differentiated S&P 500 (0.48)', 
             ​color = 'orange', linewidth = 1)
axes[2].plot(diff_data[5:,], label = 
             'Differenced S&P 500', color = 'green', linewidth = 1)
axes[0].legend()
axes[1].legend()
axes[2].legend()
axes[0].grid()
axes[1].grid()
axes[2].grid()   
axes[1].axhline(y = 0, color = 'black', linestyle = 'dashed') 
axes[2].axhline(y = 0, color = 'black', linestyle = 'dashed')  
```

Let’s make sure that the fractionally differentiated data is indeed stationary by applying the ADF test (you used it in [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03)):

```
from statsmodels.tsa.stattools import adfuller
print('p-value: %f' % adfuller(data)[1])
print('p-value: %f' % adfuller(frac_data)[1])
print('p-value: %f' % adfuller(diff_data)[1])
```

The output of the previous code block is as follows (assuming a 5% significance level):

<pre><code><strong># The original S&#x26;P 500 dataset is non-stationary
</strong>p-value: 0.842099 
<strong># The fractionally differentiated S&#x26;P 500 dataset is stationary
</strong>p-value: 0.038829
<strong># The normally differenced S&#x26;P 500 dataset is stationary
</strong>p-value: 0.000000
</code></pre>

As the results show, the data is indeed stationary. Let’s look at another example. The following code imports the daily values of EURUSD:

```
data = np.array((pdr.get_data_fred('DEXUSEU', start = start_date, 
                                   end = end_date)).dropna())
```

[Figure 9-2](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-2) compares EURUSD with fractional differentiation (0.20) applied onto it with the regular differencing in the last panel.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0902.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-2. Fractional differentiation on EURUSD (order = 0.20)**

The results of the ADF test are as follows:

<pre><code><strong># The original EURUSD dataset is non-stationary
</strong>p-value: 0.397494
<strong># The fractionally differentiated EURUSD  dataset is stationary
</strong>p-value: 0.043214
<strong># The normally differenced EURUSD  dataset is stationary
</strong>p-value: 0.000000 
</code></pre>

As a comparison, [Figure 9-3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-3) compares the same dataset with fractional differentiation (0.30) applied onto it with the regular differencing in the last panel.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0903.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-3. Fractional differentiation on EURUSD (order = 0.30)**

**NOTE**

Approaching an order of 1.00 intuitively makes the fractional differentiation approach a normal integer differencing. Similarly, approaching an order of 0.00 makes the fractional differentiation approach the untransformed data series.

[Figure 9-3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-3) shows a more stationary EURUSD series in the second panel than the one in the second panel of [Figure 9-2](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-2), and this because the order of fractional differentiation is increased. This is why the ADF test result for the fractional differentiation of order = 0.30 is 0.002, which is much lower than the ADF test result when the order = 0.20 (which is at 0.043).

In summary, fractional differentiation is a valuable tool for time series prediction as it captures long-term dependencies, handles non-stationarity, adapts to various dynamics, and preserves integral properties. Its ability to capture complex patterns and improve forecasting accuracy makes it a good fit for modeling and predicting a wide range of real-world time series data.

## Forecasting Threshold

The _forecasting threshold_ is the minimum required percentage prediction to validate the signal. This means that the forecasting threshold technique is a filter that removes the low conviction predictions.

Objectively, low conviction predictions are the ones that are below a certain percentage. A hypothetical example is shown in [Table 9-1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#table-9-1). The threshold is ±1%.

| Time | Forecast | Status    |
| ---- | -------- | --------- |
| 1    | 0.09%    | Dismissed |
| 2    | -0.60%   | Dismissed |
| 3    | -1.50%   | Taken     |
| 4    | 1.00%    | Taken     |
| 5    | 2.33%    | Taken     |

At time 1, the trading signal is bullish with an expectation of a 0.09% rise in the hypothetical financial instrument. As this prediction is below the threshold of 1.00%, the trade is not taken. At time 2, the same intuition is applied as the bearish signal is below the threshold. The rest of the signals are taken since they are equal to or greater than the threshold (magnitude-wise). The aim of this section is to develop an MLP model and keep only the predictions that respect a certain threshold.

As usual, start by importing the required libraries:

```
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from master_function import data_preprocessing, mass_import
from master_function import plot_train_test_values, forecasting_threshold
```

Next, set the hyperparameters and import the data using `mass_import()`:

```
num_lags = 500
train_test_split = 0.80 
num_neurons_in_hidden_layers = 256 
num_epochs = 100 
batch_size = 10
threshold = 0.0015
```

Import and preprocess the data, then design the MLP architecture:

<pre><code><strong># Fetch the historical price data
</strong>data = np.diff(mass_import(0, 'D1')[:, 3])
<strong># Creating the training and test sets
</strong>x_train, y_train, x_test, y_test = data_preprocessing(data, num_lags, 
                                                      train_test_split)
<strong># Designing the architecture of the model
</strong>model = Sequential()
<strong># First hidden layer
</strong>model.add(Dense(num_neurons_in_hidden_layers, input_dim = num_lags, 
                activation = 'relu'))  
<strong># Second hidden layer
</strong>model.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))
<strong># Output layer
</strong>model.add(Dense(1))
<strong># Compiling
</strong>model.compile(loss = 'mean_squared_error', optimizer = 'adam')
</code></pre>

Fit and predict the data and retain the predictions that satisfy the threshold you have defined in the hyperparameters. This is done using the function `forecasting_threshold()`:

<pre><code><strong># Fitting
</strong>model.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)
<strong># Predicting
</strong>y_predicted = model.predict(x_test)
<strong># Threshold function
</strong>y_predicted = forecasting_threshold(y_predicted, threshold)
<strong># Plotting
</strong>plot_train_test_values(100, 50, y_train, y_test, y_predicted)
</code></pre>

[Figure 9-4](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-4) shows the comparison chart between the real values and the predicted values. Flat observations on the predictions indicate the absence of signals due to them being lower than the required threshold; in this case it is 0.0015.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0904.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-4. Training data followed by test data (dashed line) and the predicted data (thin line). The vertical dashed line represents the start of the test period**

The threshold can be found through many ways, notably:

* _The fixed numerical threshold_: As you saw in the previous example, this technique assumes a fixed arbitrary number to be used as a threshold.
* _The volatility-based threshold_: In this technique, you use a volatility indicator such as a rolling standard deviation of prices to set a variable threshold at each time step. This technique has the benefit of using up-to-date volatility information.
* _The statistical threshold_: In this technique, you look at the real values from the training set (not the test set), and select a certain quantile (for example the 75% quantile) as a minimum threshold to validate the signals.

To sum up, using the forecasting threshold may help select the trades with the highest conviction and can also help minimize transaction costs since the algorithms assume trading all the time, which is not recommended. This assumes adding a new state to the algorithm, which gives a total of three:

* _Bullish signal_: The algorithm predicts a higher value.
* _Bearish signal_: The algorithm predicts a lower value.
* _Neutral signal_: The algorithm does not have any directional conviction.

## Continuous Retraining

_Retraining_ refers to the act of training the algorithm every time new data comes in. This means that when dealing with a daily time series, the retraining is done every day while incorporating the latest daily inputs.

The continuous retraining technique deserves to be tested, and that is the aim of the section. The architecture of the algorithm will follow this framework:

1. Train the data on the training test.
2. For each prediction made, re-run the algorithm and include the new real inputs in the training set.

**NOTE**

One big limitation of the continuous retraining technique is the speed of the algorithm, as it has to retrain at every time step. If you have 1000 instances of test data where every training requires a few minutes, then the back-testing process becomes drastically slow. This is especially an issue with deep learning algorithms such as LSTM which may take a long time to train.

The main reason for applying continuous retraining is because of _concept drift_, the change in the data’s inner dynamics and structures that may invalidate the function found in the training phase. Basically, financial time series do not exhibit static relationships, and over time they change. Therefore, continuous retraining aims to update the models by always using the latest data to train.

**NOTE**

Continuous retraining does not need to be done at every time step. You can set _n_ periods for the retraining. For example, if you select 10, then the model retrains after each 10 new values.

To simplify things, this section shows the code for the continuous retraining (every day) using a linear regression model on the weekly EURUSD values at every time step. You can do the same thing with other models, you just have to change the lines of code where the model is imported and designed. First, import the required libraries:

```
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression
from master_function import data_preprocessing, mass_import
from master_function import plot_train_test_values, 
from master_function import calculate_accuracy, model_bias
from sklearn.metrics import mean_squared_error
```

Import the data and set the hyperparameters of the algorithm:

<pre><code><strong># Importing the time series
</strong>data = np.diff(mass_import(0, 'D1')[:, 3])
<strong># Setting the hyperparameters
</strong>num_lags = 15
train_test_split = 0.80 
<strong># Creating the training and test sets
</strong>x_train, y_train, x_test, y_test = data_preprocessing(data, num_lags, 
                                                      train_test_split)
<strong># Fitting the model
</strong>model = LinearRegression()
model.fit(x_train, y_train)
<strong># Predicting in-sample
</strong>y_predicted_train = np.reshape(model.predict(x_train), (-1, 1))
</code></pre>

Create the continuous retraining loop as follows:

<pre><code><strong># Store the new forecasts
</strong>y_predicted = []
<strong># Reshape x_test to forecast one period
</strong>latest_values = np.transpose(np.reshape(x_test[0], (-1, 1)))
<strong># Isolate the real values for comparison
</strong>y_test_store = y_test
y_train_store = y_train
for i in range(len(y_test)):
    try: 
<strong>        # Predict over the first x_test data
</strong>        predicted_value = model.predict(latest_values)
<strong>        # Store the prediction in an array
</strong>        y_predicted = np.append(y_predicted, predicted_value)
<strong>        # Adding the first test values to the last training values
</strong>        x_train = np.concatenate((x_train, latest_values), axis = 0)
        y_train = np.append(y_train, y_test[0])
<strong>        # Removing the first test values from the test arrays
</strong>        y_test = y_test[1:]
        x_test = x_test[1:, ]
<strong>        # Retraining
</strong>        model.fit(x_train, y_train)
<strong>        # Selecting the first values of the test set
</strong>        latest_values = np.transpose(np.reshape(x_test[0], (-1, 1)))
    except IndexError:
        pass
</code></pre>

Plot the predicted values as shown in [Figure 9-5](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-5):

```
plot_train_test_values(100, 50, y_train, y_test_store, y_predicted)
```

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0905.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-5. Training data followed by test data (dashed line) and the predicted data (thin line). The vertical dashed line represents the start of the test period**

As a simple comparison, the same back-test has been done on the model with no retraining. The latter has got 48.55% test set accuracy compared to 48.92% test set accuracy for the same model with retraining.

Continuous retraining is not a guarantee for better results, but it makes sense to update the model every once in a while due to changing market dynamics. The frequency at which you should update the model may be subjective.

## Time Series Cross Validation

_Cross validation_ is a technique used in machine learning to assess the performance of a model. It involves splitting the available data into subsets for training and evaluation. In the case of time series data, where the order of observations is important (due to the sequential nature), a traditional _k_-fold cross validation approach may not be suitable. Instead, time series cross validation techniques are used, such as the _rolling window_ or _expanding window_ methods.

**NOTE**

In traditional _k-fold cross validation_, the data is randomly split into _k_ equally sized folds. Each fold is used as a validation set, while the remaining _k-1_ folds are combined for training the model. The process is repeated _k_ times, with each fold serving as the validation set once. Finally, the performance metrics are averaged across the _k_ iterations to assess the model’s performance.

Unlike traditional _k_-fold cross validation, time series cross validation methods respect the temporal order of data points. Two commonly used techniques for time series cross-validation are the rolling window and expanding window methods:

* _Rolling window cross validation_: In rolling window cross validation, a fixed-size training window is moved iteratively over the time series data. At each step, the model is trained on the observations within the window and evaluated on the subsequent window. This process is repeated until the end of the data is reached. The window size can be defined based on a specific time duration or a fixed number of observations. [Figure 9-6](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-6) shows an illustration of the rolling window cross validation.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0906.png" alt="" height="273" width="600"><figcaption></figcaption></figure>

**Figure 9-6. Rolling window cross validation**

* _Expanding window cross validation_: In expanding window cross validation, the training set starts with a small initial window and expands over time, incorporating additional data points at each step. The model is trained on the available data up to a specific point and evaluated on the subsequent time period. Similar to the rolling window approach, this process is repeated until the end of the data is reached. [Figure 9-7](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-7) shows an illustration of the expanding window cross validation.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0907.png" alt="" height="279" width="600"><figcaption></figcaption></figure>

**Figure 9-7. Expanding window cross validation**

During each iteration of time series cross validation, the model’s performance is measured using appropriate evaluation metrics. The performance results obtained from each iteration can be aggregated and summarized to assess the overall model performance on the time series data.

## Multiple Period Forecasting

_Multiple period forecasting_ (MPF) refers to a forecasting technique that aims to forecast more than just the next period. It aims to generate a path with _n_ periods as defined by the user. There are two ways to approach MPF:

* The _recursive model_ uses the prediction as an input for the next prediction. As you may have already guessed, the recursive model may quickly get off track due to the exponentially rising error term from predicting while using predictions as inputs.&#x20;
* The _direct model_ trains the model from the beginning into outputting multiple forecasts in their respective time periods. This model is likely to be more robust than the recursive model.

Let’s start with the recursive model. Mathematically speaking, its most basic form can be represented in the following way:

�����������=��(�����������-1,...,�����������-�)

Exceptionally, this section will use weather data and an economic indicator to apply the deep learning algorithm.

The first part in predictive analysis is to get to know the data, so let’s see what the algorithm will aim to forecast. The first time series is the average daily temperatures in Basel, Switzerland since 2005. [Figure 9-8](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-8) shows the time series.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0908.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-8. A sample from the dataset showing the cyclical nature of temperature**

The second time series the Institute for Supply Management’s Purchasing Managers’ Index (ISM PMI). It is a widely recognized economic indicator in the United States. It provides insight into the health of the manufacturing sector and the overall economy. The index is based on a monthly survey of purchasing managers from various industries, including manufacturing, and assesses key factors such as new orders, production, employment, supplier deliveries, and inventories.

The index is reported as a percentage, with a value above 50 indicating expansion in the manufacturing sector, while a value below 50 suggests contraction. A higher PMI typically indicates positive economic growth, while a lower PMI may signal economic slowdown or recessionary conditions. The ISM PMI is closely monitored by policymakers, investors, and businesses as it can offer valuable insights into economic trends and potential shifts in the business cycle. [Figure 9-9](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-9) shows the ISM PMI historical observations.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0909.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-9. A sample from the imported dataset showing the mean-reverting nature of the ISM PMI**

The aim of the forecast is to test the algorithm’s ability to push through the noise and model the original mean-reverting nature of the ISM PMI. Let’s start with the recursive model.

The framework for the recursive model is as follows:

1. Train the data on the training set using the usual 80/20 split.
2. Forecast the first observation using the inputs needed from the test set.
3. Forecast the second observation using the last prediction in step two and the required data from the test set while dropping the first one.
4. Repeat step 3 until reaching the desired number of predictions. At some point, a prediction is made by solely looking at previous predictions.

**NOTE**

Up until now, you have been evaluating accuracy using `calculate_accuracy()` which works when you are predicting positive or negative values (such as the change in the price of EURUSD). When dealing with multiple period forecasting of values that do not hover around zero, it is better to calculate the directional accuracy which is basically the same calculation but does not hover around zero. For this, the function `calculate_directional_accuracy()` is used. Remember, the functions can be found in `master_function.py` in the GitHub repository.

Let’s start with the first the average temperature in Basel. Import the dataset using the following code (make sure to download the historical observations data from the GitHub repository):

```
from keras.models import Sequential
from keras.layers import Dense
import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from master_function import data_preprocessing, plot_train_test_values, 
from master_function import recursive_mpf
from master_function import calculate_directional_accuracy
from sklearn.metrics import mean_squared_error
```

Next, preprocess the data:

<pre><code><strong># Import the data
</strong>data = np.reshape(np.array(pd.read_excel('Temperature_Basel.xlsx').dropna()
                  ), (-1))
<strong># Setting the hyperparameters
</strong>num_lags = 500
train_test_split = 0.8
num_neurons_in_hidden_layers = 100
num_epochs = 200
batch_size = 12
<strong># Creating the training and test sets
</strong>x_train, y_train, x_test, y_test = data_preprocessing(data, num_lags, 
                                                      train_test_split)
</code></pre>

Design the architecture of the MLP with multiple hidden layers. Then, fit and predict on a recursive basis:

<pre><code><strong># Designing the architecture of the model
</strong>model = Sequential()
<strong># First hidden layer
</strong>model.add(Dense(num_neurons_in_hidden_layers, input_dim = num_lags, 
          activation = 'relu'))  
<strong># Second hidden layer
</strong>model.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  
<strong># Third hidden layer
</strong>model.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  
<strong># Fourth hidden layer
</strong>model.add(Dense(num_neurons_in_hidden_layers, activation = 'relu')) 
<strong># Output layer
</strong>model.add(Dense(1))
<strong># Compiling
</strong>model.compile(loss = 'mean_squared_error', optimizer = 'adam')
<strong># Fitting the model
</strong>model.fit(x_train, np.reshape(y_train, (-1, 1)), epochs = num_epochs, 
          batch_size = batch_size)
<strong># Predicting in-sample
</strong>y_predicted_train = np.reshape(model.predict(x_train), (-1, 1))
<strong># Predicting in the test set on a recursive basis
</strong>x_test, y_predicted = recursive_mpf(x_test, y_test, num_lags, 
                                    model, architecture = 'MLP')
</code></pre>

The `recursive_mpf()` function takes the following arguments:

* The test set features that will continuously be updated. They are represented by the variable `x_test`.
* The test set dependent variables. They are represented by the variable `y_test`.
* The number of lags. This variable is represented by `num_lags`.
* The fitted model as defined by the variable `model`.
* The type of architecture as represented by the argument `architecture`. It can either be `MLP` for two-dimensional arrays or `LSTM` for three-dimensional arrays.

[Figure 9-10](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-10) shows the predictions versus the real values (dashed line). Notice how the deep neural network recreates well the seasonal characteristics of the time series (albeit with some imperfections) and projects it well into the future with no required knowledge along the way.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0910.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-10. Multiple period forecasts of the model versus the real values in a dashed line**

**NOTE**

Many machine and deep learning algorithms are able to model this relationship well. This example used MLPs, but this does not undermine other models, even simple ones such as linear regression. A good task for you would be to try applying the same example using a model of your choice (such as LSTM) and comparing the results. If you are using an LSTM model, make sure to set `architecture = 'LSTM'`.

Now, apply the same process on the second time series. You only need to change the name of the imported file and the hyperparameters (as you see fit):

```
data = np.reshape(np.array(pd.read_excel('ISM_PMI.xlsx').dropna()), (-1))
```

[Figure 9-11](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-11) shows the predictions (dashed line) versus the real values.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0911.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-11. Multiple period forecasts of the model versus the real values in a dashed line**

The trained model is not too complex so as to avoid overfitting. However, it does manage to time turning points quite well during the first projections. Naturally, over time, this ability slowly fades away. Tweaking the hyperparameters is the key to achieving good directional accuracy. You can start with the following hyperparameters:

```
num_lags = 200
train_test_split = 0.8
num_neurons_in_hidden_layers = 500
num_epochs = 400
batch_size = 100
```

The second MPF technique trains the model from the beginning into outputting multiple forecasts in their respective time periods. Mathematically, it can be represented as follows:

�����������=��(����������-1,...,������-�)�����������+1=��(����������-1,...,������-�)�����������+2=��(����������-1,...,������-�)

The framework for the recursive model is as follows:

1. Create a function that relates the desired number of inputs to the desired number of outputs. This means that the last layer of the neural network will contain a number of outputs equal to the number of forecasting periods you want to project into the future.
2. Train the model to predict multiple outputs at every time step based on the inputs from the same time step.

Let’s continue with the ISM PMI. As usual, import the required libraries:

```
from keras.models import Sequential
from keras.layers import Dense
import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from master_function import direct_mpf
from master_function import calculate_directional_accuracy
from sklearn.metrics import mean_squared_error
```

Import and preprocess the data while setting the hyperparameters:

<pre><code><strong># Import the data
</strong>data = np.reshape(np.array(pd.read_excel('ISM_PMI.xlsx').dropna()), (-1))
<strong># Setting the hyperparameters
</strong>num_lags = 10
train_test_split = 0.80
num_neurons_in_hidden_layers = 200
num_epochs = 200
batch_size = 10
<strong>forecast_horizon = 18 # This means eighteen months
</strong>x_train, y_train, x_test, y_test = direct_mpf(data, num_lags, 
                                              train_test_split, 
                                              forecast_horizon)
</code></pre>

The `direct_mpf()` function takes the following arguments:

* The dataset represented by the variable `data`.
* The number of lags represented by the variable `num_lags`.
* The split represented by the variable `train_test_split`.
* The number of observations to project represented by the variable `forecast_horizon`.

Prepare the arrays, design the architecture, and predict the data for a horizon of 18 months (since the ISM PMI is a monthly indicator):

<pre><code><strong># Designing the architecture of the model
</strong>model = Sequential()
<strong># First hidden layer
</strong>model.add(Dense(num_neurons_in_hidden_layers, input_dim = num_lags, 
                activation = 'relu'))  
<strong># Second hidden layer
</strong>model.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  
<strong># Output layer
</strong>model.add(Dense(forecast_horizon))
<strong># Compiling
</strong>model.compile(loss = 'mean_squared_error', optimizer = 'adam')
<strong># Fitting (training) the model
</strong>model.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)
<strong># Make predictions
</strong>y_predicted = model.predict(x_test)
<strong># Plotting
</strong>plt.plot(y_predicted[-1], label = 'Predicted data', color = 'red', 
         linewidth = 1)
plt.plot(y_test[-1], label = 'Test data', color = 'black', 
         linestyle = 'dashed', linewidth = 2)
plt.grid()
plt.legend()
</code></pre>

[Figure 9-12](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-12) shows the predictions (dashed line) versus the real values.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0912.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-12. Multiple period forecasts of the model versus the real values in a dashed line with some optimization**

The interpretation of the model at the time of the forecast was for a consecutive drop in the ISM PMI for 18 months. The model seems to have done a good job at predicting this direction. Note that you may get different results due to the random initialization of the algorithm which may impact its convergence to a minimum loss function. You can use `random_state` to get the same results every time (you have seen this in [Chapter 7](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch07.html#ch07))

**NOTE**

The ISM PMI has a positive correlation with the US GDP and a slight positive correlation with the S\&P 500. To be more precise, bottoms in the ISM PMI have coincided with equity markets bottoms.

Out of curiosity, let’s try running the model on very simple and basic hyperparameters:

```
num_lags = 1
train_test_split = 0.80
num_neurons_in_hidden_layers = 2
num_epochs = 10
batch_size = 1
forecast_horizon = 18
```

Obviously, with one lag, the model will only take into account the previous value to learn how to predict the future. The hidden layers will only contain two neurons each and will run for only ten epochs using a batch size of 1. Naturally, you would not expect satisfying results by using these hyperparameters. [Figure 9-13](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-13) compares the predicted values to the real values. Notice the huge discrepancy as the model does not pick on the magnitude nor the direction.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0913.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-13. Multiple period forecasts of the model versus the real values in a dashed line using basic hyperparameters**

This is why hyperparameter optimization is important and a certain degree of complexity is needed. After all, these time series are not simple and carry a significant amount of noise in them.

Finally, let’s have a look at the results of running the following hyperparameters on Basel’s temperature data as you have seen in the beginning of this section:

```
num_lags = 500
train_test_split = 0.80
num_neurons_in_hidden_layers = 128
num_epochs = 50
batch_size = 12
forecast_horizon = 500
```

[Figure 9-14](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-14) compares the predicted values to the real values using the temperature time series. The number of predicted observations is 500.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0914.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-14. Multiple period forecasts of the model versus the real values in a dashed line**

Evidently, using such different prediction techniques depends on your preferences and needs. It is worth mentioning that there is also another MPF technique referred to as the _multiple output model_, which is a one-shot forecast of a number of values. This means that the model is trained over the training set with the aim of producing an instant pre-defined number of outputs (predictions). Obviously, this model may be computaionally expensive and would require a sizable amount of data.

## Applying Regularization to MLPs

[Chapter 8](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch08.html#ch08) discussed two regularization concepts regarding deep learning:

* Dropout as a regularization technique that randomly deactivates neurons during training to prevent overfitting.
* Early stopping as a method to prevent overfitting by monitoring the model’s performance and stopping training when performance starts to degrade.

Another regularization technique worth discussing is _batch normalization_, a technique used in deep learning to improve the training and generalization of neural networks. It normalizes the inputs of each layer within a mini-batch during training, which helps in stabilizing and accelerating the learning process.

The main idea behind batch normalization is to ensure that the inputs to a layer have zero mean and unit variance. This normalization is applied independently to each feature (or neuron) within the layer. The process can be summarized in the following steps:

1. For each feature in a mini-batch, calculate the mean and variance across all the samples in the batch.
2. Subtract the mean and divide by the standard deviation (the square root of the variance) for each feature.
3. After normalization, the features are then scaled and shifted by learnable parameters. These parameters allow the model to learn the optimal scale and shift for each normalized feature.

This section presents a simple forecasting task using LSTMs with the addition of the three regularization techniques. The time series is S\&P 500’s 20-day rolling autocorrelation data. Import the required libraries:

```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
import pandas_datareader as pdr
from master_function import data_preprocessing, plot_train_test_values
from master_function import calculate_directional_accuracy
from sklearn.metrics import mean_squared_error
```

Import and preprocess the data:

<pre><code><strong># Set the start and end dates for the data
</strong>start_date = '1990-01-01'
end_date   = '2023-06-01'
<strong># Fetch S&#x26;P 500 price data
</strong>data = np.array((pdr.get_data_fred('SP500', start = start_date, 
                                   end = end_date)).dropna())
</code></pre>

Calculate the 20-day autocorrelation of the close prices:

```
rolling_autocorr = pd.DataFrame(data).rolling(window = 
                                              20).apply(lambda x: 
                                              x.autocorr(lag=1)).dropna()
rolling_autocorr = np.reshape(np.array(rolling_autocorr), (-1))
```

**NOTE**

In Python, a `lambda` function, also known as an anonymous function, is a small, unnamed function that can have any number of arguments but can only have one expression. These functions are often used for creating simple, inline functions without needing to define a full function using the `def` keyword. Here’s a simple example to illustrate how `lambda` works:

<pre><code><strong># Create an anonymous function to divide two variables
</strong>divide = lambda x, y: x / y
<strong># Call the function
</strong>result = divide(10, 2)
</code></pre>

The output will be the float 5.0 stored in `result`.

The `apply()` function is a method that is available in `pandas`. It is primarily used to apply a given function along an axis of a dataFrame.

Before continuing, try plotting the S\&P 500 price data versus its 20-day autocorrelation that you just calculated. Use this code to generate [Figure 9-15](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-15):

```
fig, axes = plt.subplots(nrows = 2, ncols = 1)
axes[0].plot(data[-350:,], label = 'S&P 500', linewidth = 1.5)
axes[1].plot(rolling_autocorr[-350:,], label = '20-Day Autocorrelation', 
             color = 'orange', linewidth = 1.5)
axes[0].legend()
axes[1].legend()
axes[0].grid()
axes[1].grid()
axes[1].axhline(y = 0.95, color = 'black', linestyle = 'dashed')
```

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0915.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-15. The S\&P 500 versus its 20-day price autocorrelation (lag = 1)**

What you should retain from the chart and from the intuition of autocorrelation is that whenever it approaches 1.00, the current trend may break, thus leading to a market correction. This is not a perfect assumption, but you can follow these basic rules to interpret the rolling autocorrelation observations:

* A trending market (bullish or bearish) will have its autocorrelation approach 1.00 sooner or later. When this happens, it may signal a pause in the underlying trend and in rarer occasions, a full reversal.
* A sideways (ranging) market will have a low autocorrelation. If the autocorrelation approaches historical lows, then it may mean that the market is ready to trend.&#x20;

Let’s now continue building the algorithm. The next step is to set the hyperparameters and prepare the arrays:

<pre><code>num_lags = 500 
train_test_split = 0.80 
num_neurons_in_hidden_layers = 128 
num_epochs = 100 
batch_size = 20
<strong># Creating the training and test sets
</strong>x_train, y_train, x_test, y_test = data_preprocessing(rolling_autocorr, 
                                                      num_lags, 
                                                      train_test_split)
</code></pre>

Transform the input arrays into three-dimensional structures so that they are processed into the LSTM architecture with no issues:

```
x_train = x_train.reshape((-1, num_lags, 1))
x_test = x_test.reshape((-1, num_lags, 1))
```

Design the LSTM architecture and add the dropout layer and batch normalization. Add the early stopping implementation while setting `restore_best_weights` to `True` so as to keep the best parameters for the prediction over the test data:

<pre><code><strong># Create the LSTM model
</strong>model = Sequential()
model.add(LSTM(units = num_neurons_in_hidden_layers, input_shape = 
               (num_lags, 1)))
<strong># Adding batch normalization and a dropout of 10%
</strong>model.add(BatchNormalization())
model.add(Dropout(0.1)) 
<strong># Adding the output layer
</strong>model.add(Dense(units = 1))
<strong># Compile the model
</strong>model.compile(loss = 'mean_squared_error', optimizer = 'adam')
<strong># Early stopping implementation
</strong>early_stopping = EarlyStopping(monitor = 'loss', patience = 15, 
 restore_best_weights = True)
<strong># Train the model
</strong>model.fit(x_train, y_train, epochs = num_epochs, 
          batch_size = batch_size, callbacks = [early_stopping])
</code></pre>

Predict and plot the results:

<pre><code><strong># Predicting in-sample
</strong>y_predicted_train = np.reshape(model.predict(x_train), (-1, 1))
<strong># Predicting out-of-sample
</strong>y_predicted = np.reshape(model.predict(x_test), (-1, 1))
<strong># Plotting
</strong>plot_train_test_values(300, 50, y_train, y_test, y_predicted)
</code></pre>

[Figure 9-16](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch09.html#figure-9-16) shows the predictions versus the real values (dashed line). The model has stopped the training before reaching 100 epochs due to the callback from the early stopping mechanism.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0916.png" alt="" height="450" width="600"><figcaption></figcaption></figure>

**Figure 9-16. Training data followed by test data (dashed line) and the predicted data (thin line). The vertical dashed line represents the start of the test period**

The results are as follows:

```
Accuracy Train =  70.37 %
Accuracy Test =  68.12 %
RMSE Train =  0.0658945761
RMSE Test =  0.0585669847
Correlation In-Sample Predicted/Train =  0.945
Correlation Out-of-Sample Predicted/Test =  0.936
```

It’s important to note that using indicators such as the rolling autocorrelation, should be done with caution. They provide insights into historical patterns, but they don’t guarantee future performance. Additionally, the effectiveness of rolling autocorrelation as a technical indicator depends on the nature of the data and the context in which it’s being used. You can try applying the MPF method on the autocorrelation data.

Other regularization techniques that exist include the following:

* _L1 and L2 regularization_: Also known as weight decay, L1 and L2 regularization add a penalty term to the loss function based on the magnitude of the weights. _L1 regularization_ adds the absolute values of the weights to the loss, encouraging sparsity in the model. _L2 regularization_ adds the squared values of the weights, which discourages large weight values and tends to distribute the influence of features more evenly.
* _DropConnect_: Similar to dropout but applied to connections rather than neurons. This technique randomly drops connections between layers during training.
* _Weight constraints_: Limiting the magnitude of weight values can prevent the model from learning complex patterns from noise and helps regularize the model.
* _Adversarial training_: Training the model using adversarial examples can improve its robustness by making it more resistant to small perturbations in the input data.

Using these regularization techniques doesn’t guarantee a better result than using the model without them. However, deep learning best practices encourage such techniques to avoid more serious problems like overfitting.

**NOTE**

When manually uploading an excel file (using `pandas` for example) that contains historical data, make sure that it has a shape of `(n, )` and not a shape of `(n, 1)`. This is to make sure that when you use the `data_preprocessing()` function, the four training/test arrays will be created with the proper dimensions.

To transform a `(n, 1)` array to `(n, )`, use the following syntax:

```
data = np.reshape(data, (-1))
```

To transform a `(n, )` array to `(n, 1)`, use the following syntax:

```
data = np.reshape(data, (-1, 1))
```

## Summary

This chapter presented a few ways that may improve the different machine and deep learning algorithms. I like to refer to such ways as _satellites_ since they hover around the main component, that is, neural networks. Optimizations and enhancements are crucial to the success of the analysis. For example, some markets may benefit from the forecasting threshold technique and fractional differentiation. Trial and error is key into understanding your data, and as you commence [Chapter 10](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch10.html#ch10) and learn about reinforcement learning, you will see that trial and error is not just a human task. It can also be a computer task.
