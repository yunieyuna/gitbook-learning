# 2. Essential Probabilistic Methods for Deep Learning

## Chapter 2. Essential Probabilistic Methods for Deep Learning

The rise and accessibility of technology have made it possible for everyone to deploy machine learning and deep learning algorithms for data analysis and optimization. But unfortunately, this means that a large number of users do not understand the basics and underlyings of the different learning models. This makes machine learning nothing short of a black box to them, which is a recipe for disaster.

Fundamental concepts in probability, statistics, and math are essential for understanding and mastering data as well as the creation of models that seek to interpret and forecast it if possible. This chapter presents the basics of probablity that are either directly or indirectly related to the algorithms. Note that you are unlikely to use these probability concepts in your everyday life but it’s important to know where some algorithms draw their assumptions from.

## A Primer on Probability

_Probability_ is all about describing random variables and random events. The world is filled with randomness, and the best way to find your way through chaos is to try to explain it using probabilistic methods. Granted, the phrase _explain chaos_ may be an oxymoron, as chaos cannot really be explained, but we humans cannot relinquish control over uncertain events. This is why we have developed tools to make sense out of the scary world.

You may wonder what is the use of understanding the basics of probability when trying to develop machine learning algorithms for financial trading. This is a reasonable question, and you must know that the foundations of a discipline do not necessarily resemble it.

For example, to become a pilot, you have to have to study aerodynamics first, which is filled with technical concepts that do not resemble the final skill acquired at graduation. This is similar to what is being done in this chapter; by studying probabilistic essentials, you give your brain a proper warm-up for what’s to come after.

Knowing the utility of what you are learning should give you a motivation boost. Here are some key probability topics that are important for machine learning:

Probability distribution functionsThe possibility of seeing various outcomes of a random variable is described by a _probability distribution_. For many machine learning techniques, it is essential to comprehend the features and attributes of typical probability distributions. Probability distribution functions also describe different types of time series data, which in turn helps in choosing the right algorithm. For simplicity and coherence, this topic is discussed in [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03).Hypothesis testing_Hypothesis testing_ is used to establish whether a population-based assertion is more likely to be true or incorrect based on a sample of data. Stationarity tests use hypothesis testing and are discussed in [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03).Decision trees_Decision trees_ are a type of machine learning algorithm that borrows from probabilistic concepts such as conditional probability, a concept covered in this chapter. For more detail, decision trees are covered in [Chapter 7](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch07.html#ch07).Information theory_Information theory_ is the complex study of how information is quantified, stored, and transmitted. It is incorporated into numerous machine learning techniques, including decision trees.​ It is also used in a type of non-linear correlation measure called the maximal information coefficient discussed in [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03).

### Introduction to Probabilistic Concepts

The most basic piece of probabilistic information is a _random variable,_ which is an uncertain number or outcome. Random variables are used to model events that are considered uncertain, such as the future return of a currency pair.

A random variable is either discrete or continuous. A _discrete random variable_ has a finite set of values, while a _continuous random variable_ has values within a certain interval. Consider the following examples to clarify things:

* An example of a discrete random variable would be the result of rolling a die. They are limited by the following set {1, 2, 3, 4, 5, 6}.
* An example of a continuous random variable would be the daily price returns of EURUSD (The exchange rate of 1 Euro expressed in US Dollars).

Random variables are described by _probability distributions,_ which are functions that give the probability of every possible value of these random variables. Generally, a histogram is used to show the probability. Histogram plotting is discussed in [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03).

At any moment, the probability that a certain event unfolds is between 0 and 1. This means that probability is assigned to random variables on a scale between 0 and 1 such that a probability of 0 represents zero chance of occurence and a probability of 1 represents a certainty of occurence.

You can also think of this in percentage terms, which range from 0% to 100%. Values within the two numbers are valid, which means that you can have a 0.5133 (51.33%) probability of a certain event occurring. Consider rolling a die that has six sides. What is the probability of getting 3 knowing that the die is not manipulated in any way?

As the die has six sides, there are six equal probabilities for every outcome, which means that for any outcome, the probability is found as follows:

�(�)=16=0.167

With _P(x)_ designating the probability of event _x_. This gives the answer to the question:

�(3)=16=0.167

When a die is rolled, there can only be one result. It cannot give 3 and 4 simultaneously, since one side has to dominate the other. This is the concept of _mutual exclusivity_. Mutually exclusive events (such as getting a 3 or getting a 4 in a die roll) eventually sum up to 1. Take a look at the following example:

�(1)=16=0.167

�(2)=16=0.167

�(3)=16=0.167

�(4)=16=0.167

�(5)=16=0.167

�(6)=16=0.167

Summing all these mutually exclusive events gives 1, which means that the sum of the possible probabilities in a six-sided die is as follows:

�(1)+�(2)+�(3)+�(4)+�(5)+�(6)=1

**NOTE**

Stating that a random variable has a 0.8 probability of occurring is the same as stating that the same variable has a 0.2 probability of not occurring.

Probability measures can be conditional or unconditional. A _conditional probability_ is when the occurrence of an event impacts the probability that another events occurs. For example, the probability of a sovereign interest rate hike given positive employment data is an example of a conditional probability. The probability of event A given the occurrence of event B is denoted by the following mathematical notation: _P(A|B)_

In contrast, _unconditional probability_ is not dependent on other events. Taking the example of the conditional probability, you can formulate an unconditional probability calculation which measures the probability of an interest rate hike regardless of other economic events.

Probabilities have specific addition and multiplication rules with their own interpretations. Let’s take a look at the formulas before seeing an example. The _joint probability_ of the realization of two events is the probability that they will both occur. It is calculated using the following formula:

�(��)=�(�|�)×�(�)

What that formula says is that the probability of occurence for both A and B is the probability that A occurs given B occurs multiplied by the probability that B occurs. Therefore, the right side of the equation multiplies a conditional probability by an unconditional probability.

The _addition rule_ is used to determine the probability that at least one of the two outcomes will occur. This works in two ways: where one deals with mutually exclusive events, and the other deals with events that are non mutually exclusive:

If the events are not mutually exclusive, then to add avoid double counting, the formula is:

�(����)=�(�)+�(�)-�(��)

If the events are mutually exclusive, then the formula is simplified to the following:

�(��)=0

�(����)=�(�)+�(�)-0

�(����)=�(�)+�(�)

Notice how in mutually exclusive events, it’s either A or B that can be realized, and therefore the probability that both of them will occur is zero. To understand why you need to subtract the joint probability of A and B, take a look at [Figure 2-1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch02.html#figure-2-1).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098148386/files/assets/dlff_0201.png" alt="" height="400" width="600"><figcaption></figcaption></figure>

**Figure 2-1. The addition rule of probability**

Notice how the probability of either A or B occurring while they are mutually exclusive must not include their joint probability. Let’s now look at the concept of independent events.

_Independent events_ are not tied together (for example, rolling the die twice). The joint probability is calculated as follows:

�(��)=�(�)×�(�)

Independent events therefore refer to instances where the occurrence of one has absolutely zero impact on the occurrence of the others. Now, let’s see an example to validate these concepts. Consider a simple coin toss. The probability of getting heads does not depend on what you have gotten in the previous coin toss. Therefore the probability of getting heads is always 0.50 (50%). To take things further, what is the probability of getting only heads after five coin tosses?

As the probability of each event is independent from the previous or the next one, the formula is as follows:

�(�)=0.50×0.50×0.50×0.50×0.50=0.03125=3.125%

The _expected value_ of a random variable is the weighted average of the different outcomes. Therefore, the expected value is really another way of referring to the mean. Mathematically, the expected value is as follows:

�(�)=∑�=1�(�(��)��)

Take a look at [Table 2-1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch02.html#table-2-1) and try to calculate the expected value of the next employment numbers in a certain month of the year.

| Non-farm payrolls | Probability |
| ----------------- | ----------- |
| 300,000           | 0.1         |
| 400,000           | 0.3         |
| 500,000           | 0.5         |
| 600,000           | 0.1         |

_Non-farm payrolls_ refer to a monthly report issued by the US Department of Labor that gives information on the total number of paid employees added in the nation, excluding those employed in the agriculture sector, as well as those employed by the government and non-profit organizations.

From [Table 2-1](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch02.html#table-2-1), economists assume there is a 50% probability that there will be a 500,000 increase in the total number of paid employees and a 30% probability that there will be a 400,000 increase in the total number of paid employees. The expected value is therefore:

�(�)=(300,000×0.1)+(400,000×0.3)+(500,000×0.5)+(600,000×0.1)=460,000

Therefore, the number that represents the economists’ consensus is 460,000, as it is the closest weighted value to most forecasts. It is the value that represents the dataset.

**NOTE**

The main takeaways from this section are as follows:

* Probability describes random variables and random events. It is a value between 0 and 1.
* Probabilities of events may be grouped together to form more complex scenarios.
* The expected outcome is the weighted average of every probability in the designated universe.

### Sampling and Hypothesis Testing

When populations are large, representative samples are taken so that they become the main describers of data. Take the United States. Its democratic system means that the people hold the right to decide their own fate, but it’s not possible to go to every person and ask them about their detailed opinions on every topic out there. This is why elections are held and representatives are elected so that they act in the people’s name.

_Sampling_ refers to the act of selecting samples of data within a larger population and and making conclusions about the statistical properties of the population. There are a few different methods of sampling. The most known ones are the following:

Simple random samplingWith simple random sampling, each element in the population has an equal chance of being selected for the sample. This can be a random number generated on a labeled population where each individual has the same probability of being selected.Stratified samplingWith stratified sampling, the population is divided into groups based on some characteristic, and then a simple random sample is taken from each group in proportion to its size.Cluster samplingWith cluster sampling, the population is divided into clusters, and a random sample of clusters is selected. Then, all elements within the selected clusters are included in the sample.Systematic samplingWith systematic sampling, an element is selected by choosing every _nth_ individual from the population, where _n_ is a fixed number. This means that it is not random but pre-specified in advance.

A rule of thumb is that the more data you acquire, the better the metrics reflect the population. Sampling is extremely important in the world of machine learning as quite often, you are taking samples of data to represent the true population. For example, when performing a back-test on a trading strategy, you will be required to split the whole dataset into a _training sample_ and a _testing sample_ where the first is the sample of data on which the algorithm understands its structure (also known as the _in-sample set_), and the second is the sample of data on which the algorithm tests its predictive power (also known as the _out-of-sample set_).

Similarly, another example of using sampling is _cross validation_, a technique that divides a dataset into two or more subgroups. The model is trained using one subset, and its results are tested using the other subsets. For various subsets of the data, this procedure is repeated numerous times, and then the model’s average performance is determined.

These terms are discussed in more depth in the coming chapters. For now you should understand that the concept of sampling is very important in machine learning.

Sampling is not perfect and errors may be possible just as any other estimation method. _Sampling error_ refers to the difference between the statistic of the sample and the statistic of the population (if it’s known). A _statistic_ is a metric that describes the analyzed dataset (an example of this would be the mean, a statistic you will see in greater detail in [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03)). Now, what is the minimum sample size you should have to be able to make inferences about the population? The rule of thumb is to have a minimum of 30 observations and the more the merrier. This brings the discussion to the _central limit theorem_ which states that random samples drawn from a population will approach a normal distribution (a probability distribution that is symmetric and bell-shaped) as the sample gets larger.

The central limit theorem makes it simple to apply inferences and conclusions as hypothesis testing goes well with a normal distribution. Before proceeding to hypothesis testing, let’s look at _confidence intervals_, ranges of values where the population parameter is expected to be. Confidence intervals are generally constructed by adding or subtracting a factor from the point estimate. For example, given a sample mean x̄, a confidence interval can be constructed as follows:

�¯±(�����������������×�������������)

Let’s try to understand the calculation step by step. The sample mean is an estimate of the population and is calculated because it is not possible to calculate the population means, therefore, by performing a random sample, the assumption is that the sample mean should be equal to the population mean. However, in real life, things may differ, and this why you should construct a confidence interval using probabilistic methods.

**NOTE**

The _significance level_ is the threshold of the confidence interval. For example, a confidence interval of 95% means that with 95% confidence, the estimate should lie within a certain range. The remaining 5% probability that it does not, is called a significance level (generally marked with the alpha symbol α).

A _reliability factor_ is a statistical measure that depends on the distribution of the estimate and the probability that it falls within the confidence interval. For the sake of simplicity, let’s assume that the variance of the population is normal and the population is normally distributed. For a significance level of 5% (thus, a confidence interval of 95%), the reliability factor is 1.96 in this case (the way you get this number is less relevant to the discussion).

The _standard error_ is the standard deviation of the sample. _Standard deviation_ is discussed in greater depth in [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03); for now, just know that it represents the degree of fluctuations of the different values around the mean. Standard error is found using the following formula:

�=��

����ℎ����������������������������

����ℎ��������������ℎ�����������������

It is also worth knowing that for a 1% significance level, the reliability factor is 2.575, and for a 10% significance level, the reliability factor is 1.645. Let’s take a practical example to make sense out all of this math.

Consider a population of 100 financial instruments (bonds, currency pairs, stocks, structured products, etc.). The mean annual return of these instruments is 1.4%. Assuming a population standard deviation of 4.34%, what is the confidence interval at 1% significance level (99% confidence interval) of the mean?

The answer is just plugging the values in the formula as follows:

1.4%±2.575×4.34%100=1.4%±1.11%

This means that the confidence interval is between (0.29%, 2.51%).

**NOTE**

If the sample size is small and / or the population standard deviation is unknown, a t-distribution may be a better choice than a normal distribution.

The _t-distribution_ is a type of probability distribution used to model the distribution of a sample mean when the sample size is small and / or when the population standard deviation is unknown. It resembles the normal distribution in shape, but with heavier tails, which represents the uncertainty associated with smaller sample sizes.

The next stop is hypothesis testing, a key probabilistic technique of getting conclusions on samples of data. This part is extremely important as it’s used in a lot of statistical analyses and models.

In statistics, _hypothesis testing_ is a technique for drawing conclusions about a population from a small sample of data. It entails developing two competing hypotheses, the _null hypothesis_ and the _alternative hypothesis_, about a population parameter, and then figuring out which is more likely to be accurate using sample data.

For example, a financial analyst is evaluating two portfolios from a risk perspective. They formulate two hypotheses:

* The null hypothesis states that there is no significant difference in the volatility of the two portfolios.
* The alternative hypothesis states that there is a significant difference in the volatility of the two portfolios.

The hypothesis is then tested using statistical analysis to determine if the difference in volatility is statistically significant or due to pure chance.

Following the definition of the null and alternative hypotheses, a test statistic is computed using the sample data. To assess the result’s significance, the test statistic is then compared to a critical value drawn from a standard distribution. The null hypothesis is rejected and the alternative hypothesis is accepted if the test statistic is inside the crucial zone. The null hypothesis is not rejected and the conclusion that there is insufficient evidence to support the alternative hypothesis is reached if the test statistic does not fall inside the crucial zone.

This is all fancy talk to say that hypothesis testing is basically creating two opposing scenarios, running a probability check, and then deciding which scenario is more likely true. Hypothesis testing can take two forms:

* _One-tailed test_: An example of this would be to test if the return on certain financial instruments is greater than zero.
* _Two-tailed test_: An example of this would be to test if the the return on certain financial instruments is different from zero (meaning that it can be either greater or smaller than zero). Hypothesis tests are generally two-tailed.

The null hypothesis is the one that you want to reject and therefore is tested in the hopes of getting rejected and accepting the alternative scenario. A two-tailed test takes the following general form:

�0:�=�0

��:�≠�0

As the alternative scenario allows for values above and below zero (which is the stated level in the null hypothesis), there should be two critical values. Therefore, the rule of a two-tailed test is to reject the null hypothesis if the test statistic is greater than the upper critical value or if the test statistic is lower than the lower critical value. For instance, for a normally distributed data, the test statistic is compared with the critical values (at 5% significance level) at +1.96 and -1.96. The null hypothesis is rejected if the test statistic falls outside the range between +1.96 and -1.96.

The process of hypothesis testing entails the calculation of the test statistic. It is calculated by comparing the point estimate of the population parameter with the hypothesized value of the null hypothesis. Both are then scaled by the standard error of the sample. The mathematical representation is as follows:

�������������=���������������-ℎ����ℎ������������������������

An important consideration in hypothesis testing is that the sample may not be representative, which leads to errors in describing the population. This gives rise to two types of errors:

* _Type I error_: This error occurs when rejecting the null hypothesis even though it is true.
* _Type II error_: This error occurs when failing to reject the null hypothesis even though it is false.

Intuitively, the significance level is the probability of making a type I error. Remember that if α = 5%, then there is a 5% chance of rejecting a true null hypothesis by mistake. An example would make things clearer.

Consider an analyst doing research on the annual returns of a long-short portfolio over a period of 20 years. The mean annual return was 1% with a standard deviation of 2%. The analyst’s opinion is that the annual mean return is not equal to zero and they want to constuct a 95% confidence interval for this and then construct a hypothesis test:

1. State the variables. The size of the sample is 20, the standard deviation is 2% and the mean is 1%. &#x20;
2. Calculate the standard error, which in this case is 0.44% as per the formula.
3. Define the critical values for the 95% confidence interval, which are +1.96 and -1.96. &#x20;
4. The confidence interval is therefore (0.13%, 1.86%).
5. Specify the null hypothesis, which is, according to the analyst’s opinion, a two-tailed test. The null hypothesis is that the annual return equals zero. You should reject it if the test statistic is less than -1.96 or greater than +1.96.
6. Using the formula to find the test statistic gives 2.27. Therefore, the null hypothesis is rejected.

One more important metric to discuss: the p-value. The _p-value_ is the probability of seeing a test statistic more extreme than the one seen in the statistical test given that the null hypothesis is true. Comparing a p-value to a significance level—typically 0.05—allows you to understand it. The result is deemed statistically significant, and the null hypothesis is rejected in favor of the alternative hypothesis if the p-value is less than or equal to the significance level.

If the p-value is less than the significance level of 5%, it means that there is a 5% chance to see a test statistic as extreme as the current one if the null hypothesis is true. Another way of defining the p-value is to consider it as the smallest significance level for which the null hypothesis can be rejected.

**NOTE**

The main takeaways from this section are as follows:

* Sampling refers to the collection of data within a population in the aim of making conclusions about the statistical properties of the aforementioned population.
* Hypothesis testing is a technique for drawing conclusions about a population from a small sample of data.

### A Primer on Information Theory

_Information theory_ is a complex abstract mathematical field that is closely related to probability. It is the study of how information is quantified, stored, and transmitted. There are three conditions of occurrence when it comes to an event:

* _Uncertainty_: If the event has not occurred yet.
* _Surprise_: If the event has just occurred.
* _Information_: If the event has occurred in the past.

One of the key concepts in information theory is _entropy_, the level of uncertainty or randomness in a message or information source. It describes the degree to which an event or message is unexpected. In contrast, _information gain_ measures the reduction in entropy (surprise) when receiving new information.

Basically, information theory describes the surprise of events. When an event has a low probability of occurrence, it has more surprise and hence, more information to provide. Similarly, when an event has a high probability of occurrence, it has less surprise and therefore, less information. What you should retain from this is that the amount of information learned from an unlikely event is greater than the amount of information learned from a likely event.

Before starting to dig a little deeper in information theory, it is important to understand what a _logarithm_ is and for that matter what an _exponent_ is. A general exponential function takes a certain constant or a variable to a certain power:

�(�)=��

In other words, the _exponent of a number_ is the number of times you will multiply it by itself:

43=4×4×4=64

In contrast, a logarithm is the opposite of an exponent, and its aim is to find the exponent (knowing 4 and 64 from the previous example and finding 3):

log4(64)=3

A logarithm, therefore, is the answer to how many of one number to multiply to get another number. Since they are literally inverse functions, you can use them together to simplify or even solve for _x_. Take the following example:

log4(�)=3

The objective here is to find x given the logarithmic function. The first step is simply to use the exponential function on one side as you want it to cancel out the logarithm on the right (inverse functions cancel each other out). This gives us the following result:

4���4(�)=43

�=43

�=64

Logarithms can have different bases. However, the most used logarithm has a base of 10. In computer science, base 2 logarithms represent bits (binary digits). Therefore, information is represented as bits. The formula of information gain is as follows:

�(��)=-���2(�(��))

Let’s assume two variables _x_ and _y_ where _x_ has a probability of 1 (100% and therefore, certain) and _y_ has a probability of 0.5 (50% and therefore, mostly random), what would be the information in these two cases? The answer is as follows:

�(�)=-���2(�(1))=0

�(�)=-���2(�(0.5))=1

So the certain event gives zero information and the one that has a fifty-fifty chance of realizing has an information of 1. What about the very unlikely event _z_ that has a probability of 0.05 (5%)?

�(�)=-���2(�(0.05))=4.32

A negative relationship between probability and information is therefore one of the principles of information theory. Entropy and information are related concepts, but they have different meanings and applications.

_Entropy_ is a metric used to assess how chaotic or random a system is. Entropy describes how uncertain or unpredictable a signal is. The degree of disorder or unpredictability in the system or communication increases as entropy increases.

_Information_ is the decrease in entropy or uncertainty that happens as a result of receiving a signal. A signal’s ability to lessen the receiver’s uncertainty or entropy increases with its informational content.

**NOTE**

Entropy is maximized whenever all the events are equally likely.

Entropy is calculated using the following formula:

�(��)=∑�=1�(-���2(�(��)).(�(��)))

Therefore, it is the average of the sum of logarithms times their respective probabilities.

Now, let’s discuss the final concept of the section, _information gain_.  The reduction in entropy caused by changing a dataset is calculated via information gain.

Information gain is one of the key concepts you will see in [Chapter 7](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch07.html#ch07) with decision trees, and therefore you may want to refer to this section after understanding what decision trees are.

You mainly calculate information gain by comparing the entropy of a dataset before and after a transformation. Recall that entropy is maximized when all the outcomes of a random event have the same probability. This can also be presented as a distribution where a symmetrical distribution (such as the normal distribution) has high entropy and a skewed distribution has low entropy.

**NOTE**

Minimizing entropy is related to maximizing information gain.

Before closing this introductory section on information theory, let’s look at the concept of _mutual information_. This measure is calculated between two variables, hence the name _mutual_, and it measures the reduction in uncertainty of a variable given another variable. The formula for mutual information is as follows:

��(�,�)=�(�)-�(�|�)

��(�,�)���ℎ�������������������������

�(�)���ℎ�����������

�(�|�)���ℎ����������������������������

Mutual information therefore measures the dependence between the variables. The greater the mutual information, the bigger the relationship between the variables (a value of zero represents independent variables). Keep this concept in mind as you will see it in [Chapter 3](https://learning.oreilly.com/library/view/deep-learning-for/9781098148386/ch03.html#ch03) in the section that deals with correlations. This is because mutual information can also be a measure of non-linear correlation between the variables.

**NOTE**

Let’s do a summary of what you need to retain in information theory to have a basic knowledge of what’s to come:

* Information theory uses concepts from probability to calculate information and entropy that are used in machine learning models and other calculations (such as correlation).
* Information is the decrease in entropy or uncertainty that happens as a result of receiving a signal. Entropy is a metric used to assess how chaotic or random a system is.
* Mutual information is a measure of dependence between two random variables. It can also be used to calculate the correlation between the two.
* Tools from information theory are used in some machine learning models such as decision trees.

### Summary

Probability presents a basic framework before continuing towards more advanced topics. This chapter skimmed over the concepts that you may encounter when dealing with machine and deep learning models. It is important to understand how probability is calculated and how hypothesis testing is performed (even though, in reality algorithms will do this for you).

The next chapter is extremely important and presents the required statistical knowledge you need, not just for machine learning but also for financial trading and even complex data analysis.
