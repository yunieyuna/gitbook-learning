# 9. Supervised and Unsupervised Learning

As we discussed in the last few chapters, supervised and unsupervised learning are two primary approaches to machine learning. At its core, machine learning is about teaching computers to learn from data. There are many different types of machine learning, but two of the most common are supervised learning and unsupervised learning.

Supervised learning involves training a model using _**labeled data**_, which consists of input-output pairs. The model learns the underlying patterns and relationships between the inputs and outputs, enabling it to make predictions on unseen data. Common applications of supervised learning include image recognition, sentiment analysis, and fraud detection. For example, a supervised learning algorithm could be trained to classify images of animals into one of a set of predefined categories, such as cat, dog, bird, etc.

> _Definition of labeled data: Also known as annotated data, it refers to datasets where each instance is associated with a specific label or outcome. Labeled data is often more time-consuming and expensive to obtain than unlabeled data because it typically involves human expertise to manually classify each instance in the dataset. For instance, going to a large pet pictures dataset and label them either as “cat” or “dog” or “other.”_

Unsupervised learning, on the other hand, deals with unlabeled data, where the model learns to identify patterns, structures, and relationships within the data without prior knowledge of the desired output. It is often used for tasks such as clustering, dimensionality reduction, and anomaly detection. For example, an unsupervised learning algorithm could be used to find groups of similar customers.

The significance of these techniques lies in their ability to solve complex problems, automate tasks, and generate insights that can drive business growth. They form the foundation of AI applications, making it essential for executives to understand their differences and potential use cases.

Understanding supervised and unsupervised learning from a first principles perspective involves breaking down these techniques into their fundamental components and examining the underlying principles that govern their behavior. This approach enables business executives to

1.  1\.

    **Make informed decisions**: A First Principles understanding allows executives to identify suitable machine learning techniques for specific business problems, ensuring the selection of appropriate algorithms and models that align with their objectives.

    &#x20;
2.  2\.

    **Foster innovation**: By grasping the core principles behind these learning techniques, executives can think beyond existing solutions and encourage innovative approaches to problem-solving.

    &#x20;
3.  3\.

    **Enhance collaboration**: A solid understanding of supervised and unsupervised learning enables executives to communicate effectively with data scientists and engineers, facilitating cross-functional collaboration.

    &#x20;

There are many ways that you can use supervised and unsupervised learning to grow your company. Here are a few examples:

* **Customer segmentation**: You can use unsupervised learning to segment your customers into groups with similar characteristics. This can help you to target your marketing campaigns more effectively.
* **Fraud detection**: You can use supervised learning to detect fraudulent transactions. This can protect your company from financial losses.
* **Product recommendations**: You can use collaborative filtering to recommend products to your customers based on their past purchases. This can help you to increase sales.
* **Risk assessment**: You can use supervised learning to assess the risk of default on loans. Or to assess the overall customer risk. This can help you to make better business decisions.
* **Spam filtering**: You can use supervised learning to filter out spam emails. This can improve the user experience for your customers.

These are just a few examples of how you can use supervised and unsupervised learning to grow your company. With a little creativity, you can find many other ways to use these powerful tools.

Both supervised and unsupervised learning are powerful tools that can be used to solve a wide variety of problems. In this chapter, we will take a closer look at both types of learning and discuss their applications. We will also introduce semi-supervised learning and reinforcement learning, two other important types of machine learning.

### Supervised Learning

Supervised learning is a foundational concept in artificial intelligence (AI) and machine learning (ML). It is a form of learning where an algorithm is trained on a dataset containing both input features and the corresponding correct output labels. In essence, the algorithm learns the mapping between the inputs and outputs from the training data, allowing it to make predictions on new, unseen data points. Supervised learning is best understood from a First Principles perspective as a process of generalizing patterns in data to construct an underlying function that relates the inputs to the outputs. It is also called a “Discriminate model,” as the model learns to discriminate between groups seen in the labeled dataset. We will see how these models differ from “generative modeling,” foundation of the latest large language models.

From a First Principles perspective, _**supervised learning can be seen as an optimization problem**_. The goal is to find the optimal model parameters that minimize the difference between the model’s predictions and the actual output labels in the training dataset. This difference is often quantified using a loss function, which measures the discrepancy between the predictions and ground truth labels. By iteratively adjusting the model’s parameters, the learning algorithm seeks to minimize the loss function, resulting in a model that can make accurate predictions on new data points.

The following are the core components of supervised learning from a First Principles perspective:

1.  i.

    **Labeled training data**: Supervised learning relies on a dataset with input-output pairs, where each input feature vector is associated with a corresponding output label. This labeled data is used to teach the algorithm the underlying relationships between the inputs and outputs, allowing it to generalize these patterns to make predictions on new, unseen data.

    &#x20;
2.  ii.

    **Model training**: During the training phase, the algorithm uses the labeled training data to learn the mapping between the input features and the output labels. This is accomplished by adjusting the model’s parameters to minimize the loss function, which measures the difference between the model’s predictions and the actual output labels.

    &#x20;
3.  iii.

    **Model evaluation**: After training, the model’s performance is assessed on a separate dataset, typically called the validation or test set. This dataset is not used during training and serves to evaluate the model’s ability to generalize to new, unseen data points. Common evaluation metrics include accuracy, precision, recall, and F1-score for classification tasks, and mean squared error (MSE) or root mean squared error (RMSE) for regression tasks. We will explore these in later chapters.

    &#x20;
4.  iv.

    **Model** **optimization**: The process of model training often involves hyperparameter tuning and regularization techniques to optimize the model’s performance on the validation or test set. Hyperparameters are adjustable settings that influence the learning process, such as the learning rate, the number of layers in a neural network, or the maximum depth of a decision tree. Regularization techniques, like L1 and L2 regularization, help prevent overfitting by adding a penalty term to the loss function, discouraging overly complex models.

    &#x20;

There are many popular supervised learning algorithms and their applications. We will explore later how to decide the best one depending on several factors:

1.  i.

    **Linear regression**: A simple algorithm for modeling the relationship between a dependent variable and one or more independent variables. Linear regression is often used for forecasting, trend analysis, and determining the impact of various factors on an outcome.

    &#x20;
2.  ii.

    **Logistic regression**: A classification algorithm used for predicting the probability of an instance belonging to a specific class. Common applications include spam detection, medical diagnosis, and credit risk assessment.

    &#x20;
3.  iii.

    **Support vector machines (SVM)**: SVMs are a powerful classification and regression technique that seeks to find the optimal decision boundary (or hyperplane) separating the classes. SVMs are used in various fields, such as image recognition, text categorization, and bioinformatics.

    &#x20;
4.  iv.

    **Decision trees**: A hierarchical, tree-like structure used for decision-making and prediction. Decision trees can be used for both classification and regression tasks and are the basis for more complex algorithms like random forests.

    &#x20;
5.  v.

    **Random forests**: An ensemble learning method that combines multiple decision trees to improve prediction accuracy and reduce overfitting. Random forests are used in a variety of applications, including customer segmentation, fraud detection, and feature selection.

    &#x20;
6.  vi.

    **Neural networks**: A family of algorithms inspired by the structure and function of the human brain, consisting of interconnected layers of artificial neurons. Neural networks are particularly well-suited for complex tasks such as image and speech recognition, natural language processing, and game playing. Given the importance of this algorithm and recent developments, we will further explore them in Chapter [10](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml).

    &#x20;

As we saw, the data availability is extremely important. In enterprise environments, the most common data type is tabular data, in my experience, the best algorithm in overall terms for that data is _**extreme gradient boosting machines (XGB).**_ There are also plenty of industry reviews that achieve the same conclusion.[1](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn1)

Tip&#x20;

XGBoost is a powerful machine learning algorithm that can be used for a variety of supervised learning tasks. It is often _**the most all-round model for most tabular**_ datasets.

Indeed, the XGBoost algorithm has gained immense popularity due to its speed and performance. It is based on the principle of boosting weak learners using the gradient descent architecture. However, like any model, it is not a magic bullet, and its effectiveness can depend on the specific characteristics of your data and also business objectives. Therefore, although XGBoost tends to be an all-rounder and performs well on many tabular datasets, it is always a good idea to experiment with different models and select the one that best fits your specific problem.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484296691/files/images/605840_1_En_9_Chapter/605840_1_En_9_Fig1_HTML.jpg" alt="" height="849" width="1004"><figcaption><p>Figure 9-1 </p></figcaption></figure>

Figure [9-1](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fig1) shows the confusion matrix for the XGBoost model applied to predicting who will survive in the Titanic. You will be able to create this model yourself using any code-generation tools (such as Copilot, ChatGPT, or Bard). I have created a few prompts at the end of the chapter.

Here are some of the benefits of using XGBoost:

* **Speed**: XGBoost is one of the fastest machine learning algorithms available. This is due to its use of a tree-based structure, which allows it to make predictions very quickly.
* **Accuracy**: XGBoost is known for its high accuracy. It has been shown to outperform other machine learning algorithms on a variety of datasets.
* **Flexibility**: XGBoost is a very flexible algorithm. It can be used for a variety of supervised learning tasks, and it can be extended to handle missing data and categorical features.
* **Explainability**: XGBoost is more explainable than other models such neural networks or re-enforcement learning. Applying techniques such as SHAP (SHapley Additive exPlanations) can make the models very explainable.

Here are some additional tips for using XGBoost:

* **Use cross-validation to evaluate your model**: Cross-validation is a technique that can be used to evaluate the performance of a machine learning model on unseen data. It is important to use cross-validation when tuning the hyperparameters of your XGBoost model.
* **Regularize your model**: Regularization is a technique that can be used to prevent overfitting. It is important to regularize your XGBoost model, especially if you are using a large number of features.
* **Experiment with different hyperparameters**: The hyperparameters of XGBoost can have a significant impact on the performance of your model. It is important to experiment with different hyperparameters to find the best combination for your dataset.

There are a few real-world examples and case studies of supervised learning:

1.  i.

    **Medical diagnosis**: Supervised learning algorithms like logistic regression and support vector machines are used to predict the likelihood of a patient having a specific disease based on a set of input features, such as age, blood pressure, and medical history.

    &#x20;
2.  ii.

    **Credit scoring**: Banks and financial institutions use supervised learning algorithms, such as decision trees and neural networks, to assess the creditworthiness of loan applicants based on factors like income, employment history, and credit history.

    &#x20;
3.  iii.

    **Fraud detection**: In the financial sector, supervised learning techniques like random forests and neural networks are employed to detect fraudulent transactions and suspicious activities by analyzing patterns in transaction data.

    &#x20;
4.  iv.

    **Natural language processing**: Supervised learning algorithms play a crucial role in various NLP tasks, such as sentiment analysis, where algorithms like logistic regression and neural networks are used to classify text data as positive, negative, or neutral.

    &#x20;
5.  v.

    **Product recommendations**: Supervised learning algorithms are used to recommend products to customers. For example, Amazon uses supervised learning algorithms to recommend products to its customers based on their past purchases.

    &#x20;
6.  vi.

    **Spam filtering**: Supervised learning algorithms are used to filter out spam emails. For example, Gmail uses supervised learning algorithms to filter out spam emails from its users’ inboxes.

    &#x20;

It is very important to understand supervised learning from a first principles perspective, for business executives to gain a deeper appreciation of the underlying concepts and techniques that drive AI and ML applications. While the team should have data scientists which will go into the technical details, everyone in the team should understand the basic concepts to ensure the right technique is applied to the right business problem, with the right metrics. This knowledge can be invaluable for decision-making, especially when it comes to selecting the right ML algorithm for a specific problem or optimizing an existing AI system.

### Unsupervised learning

Unsupervised learning is a type of machine learning where algorithms learn from data without any prior knowledge of the desired outcomes or labeled training data. In contrast to supervised learning, which relies on labeled data to make predictions or classifications, unsupervised learning identifies patterns and structures within the data itself. This self-guided learning process enables the model to uncover hidden patterns, groupings, and associations within the data, which can lead to new insights and more efficient data processing.

The core components from a First Principles perspective of unsupervised learning:

1.  i.

    **Unlabeled data**: The primary input for unsupervised learning algorithms is raw, unlabeled data. Unlike supervised learning, there is no pre-defined target variable, which allows the model to explore the data without any predetermined assumptions or guidance.

    &#x20;
2.  ii.

    **Pattern recognition and clustering**: One of the main goals of unsupervised learning is to identify patterns or structures within the data. Clustering is a common technique used to group similar data points based on their inherent characteristics, which can help reveal hidden relationships and associations.

    &#x20;
3.  iii.

    **Dimensionality reduction**: High-dimensional data can be challenging to analyze and visualize due to the sheer number of variables. Unsupervised learning algorithms can perform dimensionality reduction, which reduces the number of variables while retaining the essential information, making it easier to analyze and visualize the data.

    &#x20;
4.  iv.

    **Feature extraction**: Unsupervised learning can also be used to extract relevant features from the data. This process involves transforming the raw data into a more meaningful and informative representation, which can be used as input for other machine learning models or for further analysis.

    &#x20;

There are several popular unsupervised learning algorithms and their applications:

1.  i.

    **K-means clustering**: A widely used clustering algorithm that partitions the data into K distinct clusters based on their similarities. K-means is often employed for market segmentation, anomaly detection, and image segmentation.

    &#x20;
2.  ii.

    **Hierarchical clustering**: This clustering algorithm creates a tree-like structure of nested clusters, which can be visualized as a dendrogram. Hierarchical clustering is commonly used in gene expression analysis, document clustering, and social network analysis.

    &#x20;
3.  iii.

    **Principal component analysis (PCA)**: A dimensionality reduction technique that transforms the data by projecting it onto a lower-dimensional space while preserving as much of the variance in the data as possible. PCA is often used for data visualization, noise reduction, and feature extraction in various domains, including finance, biology, and image processing.

    &#x20;
4.  iv.

    **Independent component analysis (ICA)**: Another dimensionality reduction technique that separates the data into statistically independent components. ICA is commonly used in blind source separation problems, such as separating mixed audio signals or recovering original images from mixed signals.

    &#x20;
5.  v.

    **t-distributed stochastic neighbor embedding (t-SNE)**: A nonlinear dimensionality reduction technique designed for visualizing high-dimensional data in a low-dimensional space. t-SNE is particularly useful for visualizing complex datasets, such as gene expression data or text documents.

    &#x20;

As with all ML models, the choice of which unsupervised learning algorithm to use depends on the specific task at hand.

Tip&#x20;

The most popular ML algorithm for unsupervised learning is _**K-means**_ clustering. K-means clustering is a good choice for simple tasks such as data segmentation. Hierarchical clustering is a good choice for more complex tasks such as creating a dendrogram (a diagram representing a tree).

K-means clustering is a method used to automatically partition a dataset into K groups or clusters. The algorithm works by iteratively assigning each data point to one of the K groups based on feature similarity, which is often calculated using distance metrics such as Euclidean or Manhattan distance.

The goal is to minimize the within-cluster distances (i.e., data points in the same cluster should be as similar as possible) and maximize the between-cluster distances (i.e., data points in different clusters should be as different as possible)

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484296691/files/images/605840_1_En_9_Chapter/605840_1_En_9_Fig2_HTML.jpg" alt="" height="899" width="1299"><figcaption><p>Figure 9-2 </p></figcaption></figure>

Figure [9-2](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fig2) shows K-means model applied to the Titanic dataset. You will be able to create this model yourself using any code-generation tools (such as Copilot, ChatGPT, or Bard). I have created a few prompts at the end of the chapter. The number of clusters, 3, was arbitrarily chosen for this example. In a real-world scenario, you would likely want to use a method like the Elbow Method to determine the optimal number of clusters.

The resulting plot shows three groups of passengers distinguished by age and fare. This might suggest some underlying patterns in the data, such as different clusters representing different passenger classes, age groups, etc.

Below are some real-world examples and case studies of unsupervised learning:

1.  i.

    **Customer segmentation**: Retailers and e-commerce businesses use clustering algorithms, such as K-means and hierarchical clustering, to segment their customer base into distinct groups based on purchasing behavior, demographics, and preferences. This segmentation enables companies to tailor their marketing strategies and product offerings to better serve each customer segment.

    &#x20;
2.  ii.

    **Anomaly detection**: Unsupervised learning techniques, such as clustering and autoencoders, can be used to identify unusual or suspicious patterns in data such as detecting fraudulent transactions in financial services or identifying outliers in sensor data from industrial equipment. By flagging these anomalies, companies can take preventive action, reducing the risk of loss or damage.

    &#x20;
3.  iii.

    **Text mining and document clustering**: Unsupervised learning algorithms, like hierarchical clustering and t-SNE, can be applied to large collections of text documents to automatically organize and categorize them based on their content. This capability is useful for content management systems, search engines, and news aggregation platforms, where grouping similar documents can enhance user experience and facilitate information retrieval.

    &#x20;
4.  iv.

    **Image segmentation and object recognition**: Unsupervised learning methods, such as K-means and autoencoders, are used to segment images into distinct regions or objects, enabling more effective analysis and understanding of the visual content. This technique is widely used in computer vision applications, including medical imaging, satellite imagery analysis, and autonomous vehicle navigation.

    &#x20;
5.  v.

    **Genomic data analysis**: The high dimensionality and complexity of genomic data make unsupervised learning techniques, like PCA and t-SNE, valuable tools for visualizing and exploring gene expression patterns. This analysis can help researchers identify biologically meaningful relationships and subgroups within the data, which can inform the development of new therapies and diagnostics.

    &#x20;

Unsupervised learning offers a powerful and flexible approach to discovering hidden patterns, structures, and associations within data. Unsupervised learning algorithms can uncover valuable insights and generate more efficient representations of the data, when analyzing raw, unlabeled data without any predefined assumptions or guidance. From customer segmentation to image recognition, the applications of unsupervised learning span a wide range of industries and domains, making it a crucial component of any data-driven organization’s AI toolkit.

### Semi-supervised Learning

Semi-supervised learning is a machine learning paradigm that combines aspects of both supervised and unsupervised learning. While supervised learning relies on labeled data and unsupervised learning on unlabeled data, semi-supervised learning utilizes a mixture of labeled and unlabeled data to train models. The primary motivation behind semi-supervised learning is that labeled data can be scarce, expensive, or time-consuming to obtain, while unlabeled data is often more readily available. Semi-supervised learning seeks to improve model performance and generalization while reducing the cost and effort associated with data labeling, when incorporating both types of data.

The following are the core components of semi-supervised learning from a First Principles perspective:

1.  i.

    **Combination of** **labeled and unlabeled data**: Semi-supervised learning algorithms work with a mixture of labeled and unlabeled data. The labeled data provides guidance for the learning process, while the unlabeled data helps capture the underlying structure and distribution of the data, which can lead to better model generalization.

    &#x20;
2.  ii.

    **Model** **training and optimization** **using both types of data**: In semi-supervised learning, the model is trained and optimized using both labeled and unlabeled data. The training process typically involves an iterative process where the model is first trained on the labeled data, then refined using the unlabeled data, either through clustering or other unsupervised techniques.

    &#x20;

There are some popular semi-supervised learning algorithms and their applications:

1.  i.

    **Label propagation**: Label propagation is a graph-based semi-supervised learning algorithm that uses the relationships between data points to propagate labels from labeled to unlabeled data. By constructing a graph with data points as nodes and similarities between points as edges, label propagation iteratively updates the labels of the unlabeled nodes based on their neighbors’ labels until convergence. This algorithm is commonly used in applications such as image and text classification, where the underlying structure of the data can be represented as a graph.

    &#x20;
2.  ii.

    **Label spreading**: Label spreading is like label propagation but introduces a regularization term to control the smoothness of the label assignments across the graph. This regularization helps prevent overfitting and makes the algorithm more robust to noise. Like label propagation, label spreading is applicable to various classification tasks where the data can be represented as a graph, such as social network analysis and bioinformatics.

    &#x20;
3.  iii.

    **Self-training**: Self-training is a semi-supervised learning technique that leverages the model’s confidence in its predictions to iteratively label and retrain on the unlabeled data. The algorithm starts by training a model on the labeled data and then uses the model to predict labels for the unlabeled data. High-confidence predictions are then added to the labeled dataset, and the model is retrained. This process is repeated until no more high-confidence predictions can be made or a predetermined stopping criterion is met. Self-training is applicable to a wide range of classification problems, including text classification, image recognition, and speech recognition.

    &#x20;

There are some real-world examples and case studies of semi-supervised learning:

1.  i.

    **Sentiment analysis**: In sentiment analysis, semi-supervised learning can be used to classify the sentiment of text data, such as product reviews or social media posts. Labeled data, which includes a small set of texts with known sentiment labels, is combined with a large amount of unlabeled data to improve classification performance. Label propagation or self-training techniques can be applied to iteratively refining the model, ultimately yielding more accurate sentiment predictions.

    &#x20;
2.  ii.

    **Image classification**: Semi-supervised learning is also valuable in image classification tasks, where acquiring labeled data can be time-consuming and expensive. In these scenarios, a small set of labeled images can be combined with a larger set of unlabeled images to enhance the classification model. Techniques such as self-training can be employed to iteratively refine the model, ultimately leading to better classification accuracy and generalization to new images. A notable example of this approach is the use of semi-supervised learning in medical image analysis, where expert annotation is often limited and costly. By leveraging a small amount of labeled data and a larger pool of unlabeled data, researchers can develop more accurate and robust models for tasks like tumor segmentation and organ identification.

    &#x20;
3.  iii.

    **Fraud detection**: In the financial industry, semi-supervised learning can be employed to detect fraudulent transactions or other anomalous activities. In this context, labeled data may consist of a small number of known fraud cases, while unlabeled data represents most transactions. Using techniques like label propagation or self-training, semi-supervised learning can help identify patterns indicative of fraud and improve the overall accuracy of fraud detection systems.

    &#x20;
4.  iv.

    **Bioinformatics**: In the field of bioinformatics, semi-supervised learning has been applied to tasks such as gene function prediction and protein interaction prediction. In these cases, labeled data might include a small number of experimentally validated gene functions or protein interactions, while unlabeled data represents the broader set of genes or proteins whose functions or interactions are unknown. By leveraging both types of data, researchers can develop models that more accurately predict gene functions and protein interactions, thus facilitating a deeper understanding of biological processes and potential drug targets.

    &#x20;

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484296691/files/images/605840_1_En_9_Chapter/605840_1_En_9_Fig3_HTML.jpg" alt="" height="835" width="1004"><figcaption><p>Figure 9-3 </p></figcaption></figure>

Figure [9-3](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fig3) shows the confusion matrix for the semi-supervised model applied to predicting who will survive in the Titanic. You will be able to create this model yourself using any code-generation tools (such as Copilot, ChatGPT, or Bard). I have created a few prompts at the end of the chapter.

In this code, I simulated a semi-supervised learning situation where only a small portion of the data (30% in this case) is labeled. We mark the unlabeled instances with -1 as per the requirement of the LabelSpreading algorithm.

The LabelSpreading model is then trained on both labeled and unlabeled data. After training, the model is used to predict labels for all data.

Finally, we evaluate the performance of the model only on the originally labeled data. We also display a confusion matrix for these predictions. Not surprisingly, in this case, the performance of this model is worse than using all the labeled data, but this technique can improve the performance in other cases where we have little labeled data and loads of unlabeled data.

Please note that in a real-world scenario, you would typically have a separate labeled test set for evaluation which was not used during training or semi-supervised label estimation.

Here are some examples of semi-supervised learning in action:

* **Google Photos**: Google Photos[2](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn2) uses semi-supervised learning to classify images. The algorithm is trained on a small set of labeled images, and then it is used to label unlabeled images. This allows Google Photos to classify images even if they are not labeled.
* **Amazon Recommendations**: Amazon[3](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn3) uses semi-supervised learning to recommend products to customers. The algorithm is trained on a small set of labeled data, which includes customer purchases and ratings. The algorithm then uses this data to predict which products other customers are likely to purchase.
* **Spotify Music Recommendations**: Spotify uses semi-supervised learning to recommend music to users. The algorithm is trained on a small set of labeled data, which includes user listening history and ratings. The algorithm then uses this data to predict which songs other users are likely to enjoy.

Semi-supervised learning is a powerful machine learning paradigm that combines the strengths of both supervised and unsupervised learning techniques. With applications ranging from sentiment analysis and image classification to fraud detection and bioinformatics, semi-supervised learning is a valuable tool for businesses and researchers looking to grow their company with AI using a first principles point of view.

### Reinforcement Learning

Reinforcement learning (RL) is a type of machine learning that focuses on training agents to make decisions by interacting with an environment. Unlike supervised and unsupervised learning, which relies on labeled or unlabeled data, reinforcement learning (RL) is based on trial and error, learning from the feedback received in the form of rewards or penalties. The primary goal of reinforcement learning is to maximize cumulative rewards over time, leading to the discovery of optimal strategies or policies for decision-making.

From a first principles perspective, reinforcement learning can be thought of as a problem-solving framework that enables agents to learn the best course of action under different circumstances. It is particularly well suited for problems where the optimal solution is not apparent or easily derived from available data, and where agents must continuously adapt their behavior to changing conditions.

Tip&#x20;

Reinforcement learning is a powerful machine learning technique that can be used to train agents to learn how to behave in complex environments. However, reinforcement learning can be very inefficient to learn, requiring loads of data and compute time. Furthermore, RL algorithms are often more complex to implement and harder to debug than other types of machine learning algorithms. As such, unless your task specifically requires the kind of decision-making capabilities that RL provides, it might be more efficient to explore other machine learning techniques first

While RL can be a very powerful alternative in some situations, there are many in the data science community who rightly point out a few challenges with this modeling approach. For start, RL has a very inefficient way to learn, and the models require an enormous amount of computation and data. Another challenge to RL is that the rewards mechanisms are an ideation and not really seen in nature – for example, think about nature, there is not a real-time reward but rather long term in the shape of natural selection. Finally, for heavily regulated industries, RL algorithms outputs can be difficult to explain in human logic, and they can produce “surprising” outputs. For these reasons, the reader should be careful when to use this technique. In any case, it is a very powerful tool, and hence we spend some time going through it. For instance, ChatGPT and many other large language models use a class of RL, called RLHF Reinforcement Learning From Human Feedback[4](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn4). Reinforcement Learning from Human Feedback (RLHF) uses feedback and rewards from human interaction. Instead of purely relying on pre-existing labeled data, RLHF utilizes a cycle of human feedback to inform the reinforcement signal in the learning process. The model begins with initial training using a dataset, often generated by human experts demonstrating the task. After the initial training, the model’s performance is evaluated by humans who provide reward signals or comparative feedback on different actions or decisions taken by the model. This feedback is then used to update the model’s understanding of its task and improve future decisions. This cycle repeats, allowing the model to continually learn and improve from human feedback. RLHF is particularly useful in situations where it’s hard to specify the correct behavior in every situation but easier for a human to evaluate the behavior after the fact.

The following are the core components of reinforcement learning:

1.  i.

    **Agents, environments, states, actions, and rewards**: In reinforcement learning, an agent interacts with an environment, which is described by a set of states. At each time step, the agent takes an action, which leads to a change in the environment’s state and generates a reward or penalty. The agent’s goal is to learn a policy that maps states to actions, enabling it to maximize cumulative rewards over time.

    &#x20;
2.  ii.

    **Exploration and exploitation**: A key challenge in reinforcement learning is balancing exploration and exploitation. Exploration refers to the agent’s attempts to discover new actions and state transitions, potentially leading to higher rewards. Exploitation, on the other hand, involves choosing actions that the agent already knows will yield high rewards. Striking the right balance between exploration and exploitation is critical for learning optimal policies.

    &#x20;
3.  iii.

    **Policy learning**: The primary objective of reinforcement learning is to learn an optimal policy, which is a function that maps states to actions. Policies can be represented in various ways, such as lookup tables or parameterized functions. The learning process typically involves updating the policy based on the observed rewards and state transitions, with the goal of maximizing cumulative rewards over time.

    &#x20;

There are some common reinforcement learning algorithms and their applications:

1.  i.

    **Q-learning**: Q-learning is a widely used, model-free reinforcement learning algorithm. In Q-learning, agents maintain a Q-table that represents the expected cumulative rewards for each state-action pair. The Q-table is updated iteratively based on observed rewards and state transitions, eventually converging to the optimal Q-values. Agents can then use these Q-values to choose the best action in each state. Q-learning has been applied in various domains, such as robotics, game playing, and resource allocation.

    &#x20;
2.  ii.

    **Deep Q-Networks (DQN)**: DQN is an extension of Q-learning that combines deep neural networks with reinforcement learning. Instead of maintaining a Q-table, DQN uses a neural network to approximate the Q-values for state-action pairs. This allows DQN to handle large-scale problems with high-dimensional state spaces, making it applicable to complex tasks like Atari games and robotic control.

    &#x20;
3.  iii.

    **Policy gradients**: Policy gradient methods are another class of reinforcement learning algorithms that directly optimize the policy function. These methods compute gradients of the expected cumulative rewards with respect to the policy parameters and update the policy accordingly. Policy gradient methods can be used with both discrete and continuous action spaces and have been applied to tasks like robotic manipulation, locomotion, and natural language processing.

    &#x20;
4.  iv.

    **Actor-Critic methods**: Actor-Critic methods are a hybrid of value-based and policy-based reinforcement learning algorithms. In this framework, an agent consists of two components: an actor, which represents the policy, and a critic, which estimates the value function. The actor and critic work together to optimize the policy, with the critic providing guidance to the actor based on its value estimates. Actor-Critic methods have been used in a wide range of applications, including autonomous vehicle control, recommendation systems, and financial trading.

    &#x20;

Below are some real-world examples and case studies of reinforcement learning:

1.  i.

    **AlphaGo**: One of the most famous examples of reinforcement learning is AlphaGo[5](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn5), a computer program developed by DeepMind to play the ancient board game of Go. AlphaGo utilized a combination of deep neural networks and reinforcement learning to defeat the world champion Go player, Lee Sedol, in a historic match in 2016. This achievement marked a significant milestone in AI research, as Go was considered a challenging problem due to its vast state space and complex strategies.

    &#x20;
2.  ii.

    **Robotics**: Reinforcement learning has been extensively applied in the field of robotics for tasks like robotic manipulation, navigation, and locomotion. For example, OpenAI’s robotic hand, Dactyl[6](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn6), used reinforcement learning to teach itself how to manipulate objects with human-like dexterity. Another example is Boston Dynamics’ quadruped robot, Spot[7](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn7), which has been trained using reinforcement learning techniques to navigate various terrains and carry out tasks autonomously.

    &#x20;
3.  iii.

    **Autonomous vehicles**: Reinforcement learning is playing a crucial role in the development of autonomous vehicles. Companies like Waymo[8](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn8) and Tesla are leveraging reinforcement learning algorithms to train their self-driving cars to make optimal decisions in complex and dynamic environments, such as urban traffic scenarios.

    &#x20;
4.  iv.

    **Personalized recommendations**: Reinforcement learning has been employed in recommendation systems to personalize content for users. For instance, Netflix[9](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn9) uses reinforcement learning techniques to optimize its recommendation engine, which suggests movies and TV shows based on users’ viewing history and preferences. Similarly, online advertising platforms use reinforcement learning to optimize ad placements and maximize user engagement.

    &#x20;
5.  v.

    **Finance**: In the finance domain, reinforcement learning has been used to optimize trading strategies, portfolio management, and risk assessment. For example, hedge funds and trading firms leverage reinforcement learning algorithms to develop trading models that can adapt to changing market conditions and maximize returns.

    &#x20;

As we have seen, reinforcement learning is a powerful framework for decision-making and problem-solving, particularly in situations where the optimal solution is not immediately apparent or easily derived from available data. Reinforcement learning is a rapidly evolving field, and staying informed of the latest advancements and case studies will be essential for companies seeking to leverage AI and remain competitive in the future.

### Choosing the Right Learning Technique

Selecting the appropriate learning technique is a critical step in developing effective AI-driven solutions for your organization. This section aims to guide business executives in choosing the right learning technique based on various factors, including data availability, problem complexity, and computational resources.

We saw in Chapter [8](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_8\_Chapter.xhtml) the First Principles approach to approach a generic ML problem. Here, there are several factors to consider when selecting a learning technique for the algorithms discussed on this chapter:

1.  i.

    **Availability of labeled data**: One of the most significant factors that influence the choice of learning technique is the availability of labeled data. In supervised learning, labeled data is essential for training and evaluating models. If your organization has access to a substantial amount of labeled data, supervised learning techniques can be highly effective in building predictive models. On the other hand, unsupervised learning techniques are more suitable when dealing with unlabeled data, as they focus on finding patterns and structures within the data without the need for explicit labels. In cases where you have limited labeled data and a large amount of unlabeled data, semi-supervised learning can be a practical choice, as it combines the strengths of both supervised and unsupervised learning.

    &#x20;
2.  ii.

    **Problem complexity and required model interpretability**: The complexity of the problem at hand and the desired level of model interpretability should also be considered when selecting a learning technique. Simpler models, such as linear regression and decision trees, can be easily interpreted and are suitable for relatively straightforward problems. However, these models may not capture complex patterns in data as effectively as more advanced techniques, like neural networks. As we saw, RL, while highly powerful and versatile, can be challenging to interpret, which might be a concern in industries where explainability is crucial, such as healthcare or finance. In contrast, RL is well-suited for problems involving decision-making in dynamic environments, like robotics or autonomous vehicles, where the optimal solution is not immediately apparent.

    &#x20;
3.  iii.

    **Computational resources and scalability**: The availability of computational resources and the need for scalability should also be considered when choosing a learning technique. Some algorithms, like deep learning models, require substantial computational power and can be resource-intensive during training. Depending on your organization’s resources, it may be necessary to consider more computationally efficient algorithms or leverage cloud-based services to scale your AI solutions. Additionally, it’s essential to consider the time it takes to train, validate, and deploy models, as well as the ease of updating them as new data becomes available.

    &#x20;

To make well-informed decisions regarding the selection of learning techniques, it is crucial to balance first principles thinking with practical considerations. At the same time, it is essential to recognize the practical constraints that may impact the choice of learning techniques, such as data availability, computational resources, and the specific requirements of your organization. Here are a few suggestions to help strike the right balance:

1.  i.

    **Assess your organization’s needs and goals**: Before selecting a learning technique, clearly define the objectives of your AI initiative and the specific problems you aim to address. This will provide a solid foundation for identifying the most suitable learning techniques and aligning them with your organization’s goals.

    &#x20;
2.  ii.

    **Evaluate your data**: Thoroughly assess the quality, quantity, and type of data available for your AI project. Understanding the characteristics of your data will enable you to choose the most appropriate learning techniques and ensure the success of your AI initiatives.

    &#x20;
3.  iii.

    **Experiment with different techniques**: Don’t be afraid to try out different learning techniques to find the best fit for your problem. Experimenting with various algorithms will help you gain valuable insights into their performance and suitability for your specific use case. Keep in mind that there might not be a one-size-fits-all solution, and sometimes combining multiple techniques or using ensemble methods can lead to better results.

    &#x20;
4.  iv.

    **Consult with experts**: Collaborate with data scientists, machine learning engineers, and other experts in the field to gain insights into the most suitable learning techniques for your organization. Their expertise and experience can provide valuable guidance and help you avoid common pitfalls in the AI implementation process.

    &#x20;
5.  v.

    **Leverage existing resources and platforms**: Many open-source tools, libraries, and platforms are available to help you implement various learning techniques. By leveraging these resources, you can save time and effort, and benefit from the expertise of the broader AI community.

    &#x20;
6.  vi.

    **Continuously monitor and evaluate performance**: After selecting and implementing a learning technique, it is crucial to continuously monitor and evaluate its performance. This will enable you to identify areas for improvement, fine-tune your models, and ensure that your AI initiatives continue to deliver value to your organization.

    &#x20;
7.  vii.

    **Keep up with the latest developments**: The field of AI and machine learning is constantly evolving, with new algorithms and techniques being developed regularly. Staying informed about the latest research and advancements can help you make better decisions and stay ahead of the competition.

    &#x20;

In summary, choosing the right learning technique is a critical aspect of implementing successful AI-driven solutions for your organization.

PROMPT EXERCISES

We will use Bard/ChatGPT to create code that can be exported and run to Google’s Colab. All the scripts produced first time running code with ChatGPT at the time of writing. However, please note that due to continuous API updates, you will very likely get different answers or even might need to do a bit of debugging.

**Exercise 1: Supervised Learning – XGBoost**

Prompt for Bard/ChatGPT:\<Begin Prompt>Please write Python code to load the Titanic dataset from https://raw.github.com/datasciencedojo/datasets/master/titanic.csv , preprocess the data (handle missing values, convert categorical variables into numerical ones), split it into training and testing sets, and then train a XGBoost model using sklearn. After training the model, make predictions on the test set, and calculate the accuracy, precision, recall, and F1-score of the predictions. Display a few graphs to show performance.\</End Prompt>**Exercise 2: UnSupervised Learning – K-means Clustering**\<Begin Prompt>Please write Python code to load the Titanic dataset from https://raw.github.com/datasciencedojo/datasets/master/titanic.csv , preprocess the data (handle missing values, convert categorical variables into numerical ones), split it into training and testing sets, and then train a K-means model. demonstrate how to apply K-means clustering. Use the 'Age' and 'Fare' columns for clustering. Visualize the resulting clusters and explain the output.\</End Prompt>**Exercise 3: Semi-supervised Learning**\<Begin Prompt>Please write Python code to load the Titanic dataset from https://raw.github.com/datasciencedojo/datasets/titanic.csv , preprocess the data (handle missing values, convert categorical variables into numerical ones), split it into training and testing sets, and then use a semi-supervised model. Produce the confusion matrix and overall model results.\</End Prompt>

These exercises should give readers a hands-on understanding of some of the most common supervised and unsupervised learning algorithms. They also serve as a good starting point for further exploration and experimentation. Please note that the results are a very basic pipeline. In a real-world scenario, you would want to do a more detailed exploratory data analysis, feature engineering, hyperparameter tuning, handle class imbalance, etc. And most importantly, you would interpret the results and see if they make sense, iterating on your model as necessary.

### Conclusion and Chapter Summary/Key Takeaways

In this chapter, we have provided a detailed understanding of the differences between supervised and unsupervised learning, along with their applications from a First Principles perspective. We have also briefly introduced semi-supervised learning and reinforcement learning, highlighting their core components and applications.

When implementing AI solutions, it is essential to follow best practices to maximize the benefits and avoid common pitfalls. Here, we present three key takeaway points and some do’s and don’ts for each.

1.  1.**Takeaway 1: The importance of quality data and relevant model selection:**

    1.  a.**Availability of labeled data:**

        1.  i.

            Do: Invest in creating high-quality labeled datasets for supervised learning tasks.

            &#x20;
        2.  ii.

            Don’t: Rely solely on automated labeling methods without manual verification, as this may introduce errors and affect model performance.

            &#x20;

        &#x20;
    2.  b.**Problem complexity and required model interpretability:**

        1.  i.

            Do: Consider simpler models if interpretability is a priority, and ensure stakeholders can understand the model’s decision-making process.

            &#x20;
        2.  ii.

            Don’t: Use overly complex models without justifying their necessity, as they may be difficult to interpret and maintain.

            &#x20;

        &#x20;
    3.  c.**Computational resources and scalability:**

        1.  i.

            Do: Assess the computational resources required for your chosen learning technique and plan accordingly.

            &#x20;
        2.  ii.

            Don’t: Ignore scalability concerns when selecting a learning technique, as this may lead to increased costs and inefficiencies in the long run.

            &#x20;

        &#x20;

    &#x20;
2.  2.**Takeaway 2: Apply First Principles thinking and encourage stakeholder collaboration:**

    1.  a.**First Principles thinking:**

        1.  i.

            Do: Approach AI problems from a First Principles perspective, focusing on the underlying principles and core components of each learning technique.

            &#x20;
        2.  ii.

            Don’t: Blindly apply popular algorithms without understanding their underlying assumptions and limitations.

            &#x20;

        &#x20;
    2.  b.**Collaboration with experts:**

        1.  i.

            Do: Consult with data scientists, machine learning engineers, and other experts to gain insights into the most suitable learning techniques for your organization’s needs.

            &#x20;
        2.  ii.

            Don’t: Make AI-related decisions without involving the relevant stakeholders and experts, as this may lead to suboptimal solutions and missed opportunities.

            &#x20;

        &#x20;

    &#x20;
3.  3.**Takeaway 3: Regular evaluation, ethical considerations, and a culture of innovation:**

    1.  a.**Regular evaluation and optimization:**

        1.  i.

            Do: Continuously evaluate and optimize your models to ensure they remain accurate and relevant as new data becomes available.

            &#x20;
        2.  ii.

            Don’t: Neglect model maintenance and assume that a one-time training process is sufficient for long-term success.

            &#x20;

        &#x20;
    2.  b.**Ethical considerations:**

        1.  i.

            Do: Consider the ethical implications of your AI solutions, such as potential biases, privacy concerns, and fairness.

            &#x20;
        2.  ii.

            Don’t: Implement AI solutions without considering the potential negative impacts on stakeholders, including customers, employees, and society at large.

            &#x20;

        &#x20;
    3.  c.**Experimentation and innovation:**

        1.  i.

            Do: Encourage a culture of experimentation and innovation, allowing your organization to explore new AI and machine learning techniques.

            &#x20;
        2.  ii.

            Don’t: Stick to a single learning technique or become overly reliant on past successes, as this may stifle growth and limit your organization’s ability to adapt to new challenges.

            &#x20;

        &#x20;

    &#x20;

As we have seen throughout the chapter, understanding supervised and unsupervised learning, along with their core components, is essential for business executives looking to drive growth and innovation through AI adoption. As you continue to explore and apply these learning techniques to solve real-world problems, we encourage you to seek out additional resources – as included at the end of the book – and maintain an open dialogue with experts in the field.

Footnotes[1](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn1\_source)

[https://arxiv.org/ftp/arxiv/papers/2204/2204.12868.pdf](https://arxiv.org/ftp/arxiv/papers/2204/2204.12868.pdf)

&#x20;[2](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn2\_source)

[https://ai.googleblog.com/2021/07/from-vision-to-language-semi-supervised.html](https://ai.googleblog.com/2021/07/from-vision-to-language-semi-supervised.html)

&#x20;[3](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn3\_source)

[www.amazon.science/publications/a-semi-supervised-multi-task-learning-approach-to-classify-customer-contact-intents](http://www.amazon.science/publications/a-semi-supervised-multi-task-learning-approach-to-classify-customer-contact-intents)

&#x20;[4](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn4\_source)

[https://huggingface.co/blog/rlhf](https://huggingface.co/blog/rlhf)

&#x20;[5](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn5\_source)

[www.deepmind.com/research/highlighted-research/alphago](http://www.deepmind.com/research/highlighted-research/alphago)

&#x20;[6](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn6\_source)

[https://openai.com/research/learning-dexterity](https://openai.com/research/learning-dexterity)

&#x20;[7](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn7\_source)

[www.bostondynamics.com/products/spot](http://www.bostondynamics.com/products/spot)

&#x20;[8](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn8\_source)

[https://waymo.com/](https://waymo.com/)

&#x20;[9](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml#Fn9\_source)

[https://research.netflix.com/research-area/machine-learning](https://research.netflix.com/research-area/machine-learning)
