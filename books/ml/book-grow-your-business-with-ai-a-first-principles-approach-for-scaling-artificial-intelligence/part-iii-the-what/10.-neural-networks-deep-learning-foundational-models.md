# 10. Neural Networks, Deep Learning, Foundational Models

One of the key driving forces behind AI advancements is the development of neural networks, deep learning, and foundational models. These techniques have the potential to revolutionize many industries and solve some of the world’s most pressing problems.

Neural networks are computational models inspired by the structure and function of the human brain. They consist of interconnected nodes, or neurons, that are organized into layers. Neurons can be activated or inhibited by other neurons, and they can learn to perform complex tasks by adjusting the strength of their connections. These layers include input, hidden, and output layers, with each neuron performing specific computations to process and transmit information. Neural networks have been widely adopted in various industries, providing solutions to complex problems in fields like computer vision, natural language processing, and speech recognition.

Deep learning is an extension of neural networks that involves training deep neural networks with multiple hidden layers. This added depth allows for the extraction and identification of more complex features and patterns in data, leading to improved performance and more accurate predictions. Deep learning has been at the forefront of recent AI breakthroughs, enabling the development of advanced systems capable of understanding and interpreting human language, recognizing objects in images, and even playing complex games at a superhuman level.

Foundational models, sometimes referred to as pre-trained models, are large-scale neural networks that have been pre-trained on massive amounts of data. These models are designed to capture general patterns and structures in data, allowing them to be fine-tuned for specific tasks with relatively small amounts of labeled data. Popular foundational models include BERT, GPT, and T5, which have revolutionized natural language understanding and generation tasks, making them invaluable tools for businesses looking to leverage AI in their operations.

Understanding neural networks, deep learning, and foundational models from a First Principles perspective is crucial for businesses that wish to harness the power of AI. By breaking down these complex techniques into their core components, business executives can better appreciate the underlying mechanisms that drive AI advancements and make more informed decisions when implementing AI solutions.

The impact of neural networks and deep learning on AI advancements cannot be overstated. These techniques have enabled machines to learn from data in ways that were once thought to be the exclusive domain of human intelligence. As a result, businesses that effectively leverage these techniques can gain a competitive edge, automating processes, improving decision-making, and unlocking new opportunities for growth.

In this chapter, we will delve deeper into the intricacies of neural networks, deep learning, and foundational models, exploring their core components and providing real-world examples of their applications. Additionally, we will discuss generative AI, a powerful technique that utilizes deep learning to generate data such as images, text, and audio. By gaining a strong foundation in these advanced AI techniques, business executives can drive innovation, improve efficiency, and unlock the full potential of AI for their organizations.

Neural networks, deep learning, and foundational models are still in their early stages of development, but they have the potential to change the world. These techniques are already being used in a variety of applications, including

* **Natural language processing (NLP)**: Neural networks are being used to improve the accuracy of NLP tasks, such as machine translation, text summarization, and question answering.
* **Computer vision (CV)**: Neural networks are being used to improve the accuracy of CV tasks, such as image classification, object detection, and facial recognition.
* **Speech recognition (SR)**: Neural networks are being used to improve the accuracy of SR tasks, such as transcribing audio and video recordings.
* **Medicine**: Neural networks are being used to develop new drugs, diagnose diseases, and personalize treatments.
* **Finance**: Neural networks are being used to predict market trends, manage risk, and make investment decisions.
* **Manufacturing**: Neural networks are being used to improve the efficiency of manufacturing processes, optimize product design, and automate quality control.

The potential applications of neural networks, deep learning, and foundational models are endless. As these techniques continue to develop, they will have a profound impact on the way we live and work.

### Neural Networks

Neural networks form the backbone of modern artificial intelligence, inspired by the structure and function of the human brain. In this section, we will define neural networks from a First Principles perspective and discuss their core components. We will also explore popular neural network architectures and their applications, providing real-world examples and case studies to illustrate their potential for growing your company.

Neural networks were first developed in the 1950s, but they did not become widely used until the 1990s, when advances in computing power made it possible to train large neural networks. In recent years, neural networks have been used to achieve state-of-the-art results on a wide variety of tasks, including image classification, object detection, speech recognition, and natural language processing.

A neural network is a computational model designed to process information and make decisions by mimicking the human brain’s interconnected structure. They are made up of many simple units, called neurons, that are connected to each other. Neurons can be activated or inhibited by other neurons, and they can learn to perform complex tasks by adjusting the strength of their connections. It is important to highlight that human neurons, as depicted in Figure [10-1](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fig1), are quite complicated and that the exact mechanism for the whole brain is still unknown. In particular, human neurons do not perform backpropagation as many artificial neural networks do.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484296691/files/images/605840_1_En_10_Chapter/605840_1_En_10_Fig1_HTML.jpg" alt="" height="773" width="1063"><figcaption><p>Figure 10-1 </p></figcaption></figure>

It consists of interconnected nodes, or artificial neurons, organized into layers. These layers include input, hidden, and output layers, each responsible for specific computations that transmit information through the network. By adjusting the connections between these neurons, a neural network can “learn” to recognize patterns and make predictions.

As mentioned before, we still do not fully know how the brain organizes all the neuron activity at higher levels. For the curious reader, I recommend an interesting book[1](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn1) – _A Thousand Brains_ – which present a proposed full working model for the brain, even when many of the hypotheses are still being researched.

Core components of neural networks from First Principles approach:

1.  1\.

    **Neurons and activation functions**: Neurons are the fundamental units of a neural network. Each neuron receives input from other neurons or external data, processes it, and produces an output. Activation functions determine the output of a neuron based on its input, introducing non-linearity into the network and enabling it to learn complex patterns.

    &#x20;
2.  2\.

    **Layers**: Neural networks are organized into layers – input, hidden, and output layers. The input layer receives the raw data, while the output layer produces the final predictions. Hidden layers, which lie between the input and output layers, perform intermediate computations.

    &#x20;
3.  3\.

    **Weights and biases**: Connections between neurons in adjacent layers have associated weights and biases. Weights determine the strength of the connection, while biases are additional constants that help adjust the neuron’s output. These parameters are adjusted during the training process to minimize the network’s error.

    &#x20;
4.  4\.

    **Forward and backward propagation**: During forward propagation, data flows through the network, and the neurons compute their outputs. Once the output is obtained, the network’s error is calculated. Backward propagation, or backpropagation, is the process of updating the weights and biases by minimizing the error using gradient descent or other optimization algorithms.

    &#x20;
5.  5\.

    **Loss functions and optimization algorithms**: Loss functions quantify the error between the network’s predictions and the true labels. Optimization algorithms, such as gradient descent or more advanced techniques like Adam, adjust the weights and biases to minimize the loss function.

    &#x20;
6.  6\.

    **Learning** **rate, batch sizes, and epochs**: The learning rate determines the step size during optimization, affecting the speed and stability of the training process. Batch sizes refer to the number of data points used in each update step, balancing computational efficiency and convergence speed. An epoch is a complete iteration through the entire dataset during training.

    &#x20;

Popular neural network architectures and their applications:

1.  1\.

    **Feedforward neural networks (FNN)**: FNNs are the simplest type of neural network (Figure [10-2](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fig2)), where information flows in a single direction from the input layer to the output layer without looping back. They are widely used for tasks such as regression, classification, and function approximation.

    &#x20;
2.  2\.

    **Convolutional neural networks (CNN)**: CNNs are designed for processing grid-like data, such as images or speech signals. They use convolutional layers to scan the input for local patterns, enabling them to learn translation-invariant features. CNNs have revolutionized computer vision tasks, such as image classification, object detection, and semantic segmentation.

    &#x20;
3.  3\.

    **Recurrent neural networks (RNN)**: RNNs are designed to handle sequences of data, such as time series or text. They possess connections that loop back on themselves, allowing them to maintain a “memory” of previous inputs. RNNs are used in tasks like language modeling, speech recognition, and time series prediction.

    &#x20;
4.  4\.

    **Long short-term memory (LSTM)** **networks**: LSTMs are a variant of RNNs designed to overcome the vanishing gradient problem, which hampers learning long-range dependencies in sequences. LSTMs use special gating mechanisms to control the flow of information, enabling them to learn longer sequences. They have been employed in machine translation, sentiment analysis, and video frame prediction.

    &#x20;

Real-world examples and case studies of neural networks:

1.  1\.

    **Image classification**: CNNs have been applied to various image classification tasks, such as distinguishing between different breeds of dogs or identifying cancer cells in medical images. For example, Google’s Inception[2](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn2) model achieved top performance on the ImageNet Large Scale Visual Recognition Challenge, showcasing the power of neural networks in image classification.

    &#x20;
2.  2\.

    **Natural language processing**: Neural networks, specifically RNNs and LSTMs, have made significant strides in natural language processing tasks. For instance, OpenAI’s GPT-3, a transformer-based neural network, has demonstrated impressive language understanding and generation capabilities, enabling applications like sentiment analysis, machine translation, and text summarization.

    &#x20;
3.  3\.

    **Autonomous vehicles**: Neural networks are essential components in the development of autonomous vehicles, as they process and interpret data from sensors to make decisions in real-time. Tesla’s Autopilot system, for example, employs CNNs to process visual data from cameras and make driving decisions based on learned patterns.

    &#x20;
4.  4\.

    **Financial forecasting**: Neural networks, including RNNs and LSTMs, have been used to predict stock prices and market trends based on historical data. By analyzing patterns in financial data, these networks can provide valuable insights for investment decisions and risk management.

    &#x20;
5.  5\.

    **Customer** **churn prediction**: Companies can use neural networks to analyze customer behavior and identify patterns that suggest a customer may leave for a competitor. By predicting customer churn, businesses can take proactive measures to retain valuable customers and improve overall customer satisfaction.

    &#x20;

Neural networks are a rapidly evolving field, and new applications are being discovered all the time. As neural networks continue to develop, they are likely to have a profound impact on many different industries.

### Deep Learning

Deep learning is a subfield of machine learning that focuses on the development of deep neural networks, which are artificial neural networks containing multiple hidden layers. These networks are designed to learn hierarchical representations of data, enabling the discovery of complex patterns and structures. Deep learning has played a significant role in advancing the state of the art in various fields such as image and speech recognition, natural language processing, and game playing.

Deep learning differs from traditional neural networks by having a deeper architecture, meaning _**it contains more layers of neurons**_. This depth allows deep learning models to learn increasingly abstract features from the input data, providing a more nuanced understanding of the data’s underlying structure. In essence, deep learning models can learn more complex functions and representations, making them highly effective at solving a wide range of challenging tasks.

In recent years, deep learning has become increasingly popular, due to the availability of large datasets and the development of powerful computing hardware.

Core components of deep learning:

1.  1\.

    **Deep neural networks** **with multiple hidden layers**: The primary component of deep learning is deep neural networks, which consist of multiple hidden layers between the input and output layers. Each hidden layer learns to extract progressively higher-level features from the input data, allowing the model to recognize complex patterns and relationships.

    &#x20;
2.  2\.

    **Advanced** **optimization techniques**: Deep learning models typically rely on advanced optimization algorithms, such as Adam or RMSprop, to update the model’s weights and biases during training. These algorithms help overcome the challenges associated with training deep networks, such as vanishing gradients and slow convergence.

    &#x20;
3.  3\.

    **Techniques for handling overfitting and regularization**: Deep learning models are prone to overfitting due to their large number of parameters. To counteract overfitting, several regularization techniques are employed, such as dropout, weight decay, and early stopping. These techniques help improve the model’s generalization capabilities and prevent it from memorizing the training data.

    &#x20;

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484296691/files/images/605840_1_En_10_Chapter/605840_1_En_10_Fig2_HTML.jpg" alt="" height="592" width="1065"><figcaption><p>Figure 10-2 </p></figcaption></figure>

Popular deep learning architectures and their applications:

1.  1\.

    **Deep CNNs**: Deep convolutional neural networks (CNNs) are designed for processing grid-like data, such as images and videos. These networks use convolutional layers to scan the input data for local patterns, enabling the model to learn spatial hierarchies of features. Deep CNNs have been used for various computer vision tasks, including image classification, object detection, and segmentation.

    &#x20;
2.  2\.

    **Deep RNNs**: Deep recurrent neural networks (RNNs) are designed for processing sequential data, such as time series and natural language. RNNs maintain an internal state that can capture information from previous time steps, allowing them to model temporal dependencies. Deep RNNs, including LSTMs and GRUs, have been used in applications like speech recognition, sentiment analysis, and machine translation.

    &#x20;
3.  3\.

    **Transformer models**: Transformer models are a type of deep learning architecture designed for processing sequence data, with a focus on parallelization and long-range dependencies. Transformers use self-attention mechanisms to weigh the importance of different input elements, allowing them to effectively model complex relationships in the data. Transformer models have been employed in various natural language processing tasks, such as language modeling, question-answering, and text summarization.

    &#x20;

Real-world examples and case studies of deep learning:

1.  1\.

    **Image recognition**: Deep CNNs have revolutionized image recognition, achieving human-level performance on tasks like object recognition and face detection. For example, Meta’s DeepFace[3](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn3) system uses a deep CNN to recognize faces in photos with an accuracy rate of over 97%, surpassing the capabilities of many traditional computer vision methods.

    &#x20;
2.  2\.

    **Speech recognition**: Deep learning models, particularly RNNs and LSTMs, have made significant advancements in speech recognition. Open source’s DeepSpeech[4](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn4), a deep RNN-based speech recognition system, has demonstrated remarkable performance in converting spoken language into written text, enabling applications like voice assistants and transcription services.

    &#x20;
3.  3\.

    **Machine translation**: Deep learning models, including RNNs, LSTMs, and transformer-based models, have significantly improved machine translation capabilities. For instance, Google Translate has evolved from using statistical machine translation methods to employing deep learning techniques, resulting in more accurate translations that capture the nuances of the source language.

    &#x20;
4.  4\.

    **Game playing**: Deep learning has been utilized in developing AI systems that can play complex games at a superhuman level. AlphaGo[5](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn5), a deep learning-based system developed by DeepMind, famously defeated the world champion Go player in 2016, showcasing the ability of deep learning models to learn complex strategies and make decisions in high-dimensional spaces.

    &#x20;
5.  5\.

    **Autonomous vehicles**: Deep learning models, particularly deep CNNs, play a crucial role in enabling autonomous vehicles to perceive and understand their environment. Companies like Tesla and Waymo utilize deep learning techniques to process sensor data, identify objects, and make driving decisions, paving the way for self-driving cars to become a reality.

    &#x20;

Deep learning is a powerful technique, but it also has some challenges. Some of the challenges of deep learning include

* **Data requirements**: Deep learning algorithms require large amounts of data to train. This data can be expensive and time-consuming to collect.
* **Computational requirements**: Deep learning algorithms can be computationally expensive to train.
* **Interpretability**: Deep learning algorithms are often difficult to interpret. It can be difficult to understand how the algorithm makes its decisions.

Deep learning is a powerful subfield of machine learning that focuses on the development of deep neural networks with multiple hidden layers. These networks have demonstrated remarkable success in solving complex problems across various domains, including image and speech recognition, natural language processing, and game playing.

### Generative AI

Most of the models we discussed in Chapter [9](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_9\_Chapter.xhtml) and in this one so far belong to the class of “Discriminate” models. The discriminate models learn the relationship between the features of the data points and the labels. They are typically trained on a dataset of labeled data and are used to classify or predict typically. There is another model class called “Generative” models. These ones understand the distribution of data and how likely a given example is. They generate new data that is similar to the data it was trained on, and it can be used to predict the next word in a sequence.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484296691/files/images/605840_1_En_10_Chapter/605840_1_En_10_Fig3_HTML.jpg" alt="" height="834" width="1713"><figcaption><p>Figure 10-3 </p></figcaption></figure>

Figure [10-3](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fig3) has a visual representation of how the two classes of models work. On the left-hand side, a discriminative model will learn how to separate the green and blue dots. It could be used to predict what color a new point will be. Generative models are useful for creating new data that resembles the original training set, while discriminative models excel in tasks like image or speech classification. Rather than merely partitioning the data into distinct categories, discriminative models learn where these separations occur. On the other hand, generative models comprehend how the data is placed within the overall space.

These methodologies greatly differ from each other, making them uniquely appropriate for specific tasks. In tasks involving classification, discriminative models often outperform generative models in terms of accuracy. However, for complex learning tasks that necessitate the expression of intricate dependencies, the versatility of generative models comes into play.

Generative AI is still under development, but it has the potential to revolutionize the way we interact with computers. Generative AI could be used to create new forms of entertainment, to generate new products and services, and to improve the accuracy of artificial intelligence systems.

Generative AI works by learning from existing data. The AI system is trained on a dataset of images, text, or audio. Once the AI system has been trained, it can be used to generate new data that is like the data it was trained on.

Core components of generative AI from First Principles perspective:

1.  1\.

    **Generative models**: The foundation of generative AI lies in the development of generative models. These models learn the probability distribution of the input data and use this information to generate new data points that resemble the training data. Unlike discriminative models, which focus on identifying the boundaries between different classes of data, generative models aim to create new data points that follow the same underlying patterns as the original data.

    &#x20;
2.  2\.

    **Techniques for generating data**: Several techniques have been developed for generating data using generative AI algorithms. These techniques can be broadly categorized into three main types: generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based generative models.

    &#x20;

There are many different generative AI algorithms, but some of the most popular algorithms include

1.  1.**Generative adversarial networks (GANs**): GANs are a class of generative models that consist of two neural networks: a generator and a discriminator. The generator creates new data points, while the discriminator evaluates the authenticity of the generated data. The two networks are trained together in a process known as adversarial training, where the generator tries to create data that is indistinguishable from the real data, and the discriminator tries to correctly identify whether the input data is real or generated. GANs have been successfully applied in various domains, such as

    1.  a.

        **Image synthesis**: GANs can generate realistic images, enabling applications like creating artwork or virtual environments. For example, NVIDIA’s StyleGAN can generate high-resolution, photorealistic images of human faces, objects, and scenes.

        &#x20;
    2.  b.

        **Data augmentation**: GANs can be used to generate additional training data, helping to improve the performance of machine learning models when the available dataset is limited.

        &#x20;
    3.  c.

        **Image-to-image translation**: GANs can convert images from one domain to another, such as transforming satellite images into maps, or converting black and white photos into color.

        &#x20;

    &#x20;
2.  2.**Variational autoencoders (VAEs)**: VAEs are another class of generative models that learn to encode input data into a lower-dimensional latent space and then decode it back into the original form. The VAE model is trained by optimizing the reconstruction loss (i.e., the difference between the input data and the reconstructed data) and a regularization term that encourages the latent space to have a specific distribution, typically a Gaussian distribution. Applications of VAEs include

    1.  a.

        **Image generation**: VAEs can generate new images by sampling points from the latent space and decoding them back into the image space.

        &#x20;
    2.  b.

        **Anomaly detection**: VAEs can be used to identify unusual data points in a dataset by measuring the reconstruction error for each data point. Higher reconstruction errors indicate that the data point is an outlier.

        &#x20;
    3.  c.

        **Dimensionality reduction**: VAEs can be employed for unsupervised dimensionality reduction, allowing for the visualization and analysis of high-dimensional data.

        &#x20;

    &#x20;
3.  3.**Transformer-based generative models** (e.g., GPT-4): Some transformer models, such as the Generative Pre-trained Transformer (GPT) series, have been developed to generate coherent and contextually relevant text. These models can be fine-tuned for various natural language processing tasks, such as text summarization, translation, or question-answering. The most recent iteration, GPT-4, is one of the largest and most powerful language models currently available, demonstrating impressive capabilities in generating human-like text. Applications of transformer-based generative models include

    1.  a.

        **Content generation**: These models can be used to create articles, blog posts, or social media content, assisting in content marketing and SEO efforts.

        &#x20;
    2.  b.

        **Text summarization**: Transformer-based generative models can automatically generate summaries of long documents, saving time and effort for employees who review large amounts of information.

        &#x20;
    3.  c.

        **Natural language interfaces**: GPT-like models can be used to build conversational agents or chatbots, enabling businesses to provide better customer service or automate routine tasks.

        &#x20;

    &#x20;

Real-world examples and case studies of generative AI:

1.  1\.

    **Art and design**: Generative AI has been employed to create unique and visually appealing artwork. For instance, the AI-generated painting _Portrait of Edmond Belamy_[6](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn6) sold for **$432,500** at an auction in 2018, showcasing the potential of AI-generated art in the creative industry. Furthermore, generative AI can be used in graphic design and advertising, enabling companies to develop visually striking marketing materials with minimal human effort.

    &#x20;
2.  2\.

    **Music generation**: Generative AI algorithms, such as OpenAI’s MuseNet[7](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn7), can create original music compositions in various styles and genres. This technology can be applied in the entertainment industry, as well as in generating background music for videos and games.

    &#x20;
3.  3\.

    **Drug discovery**: Generative AI models have been used to accelerate the process of drug discovery by generating novel molecular structures with desired properties. For example, Insilico Medicine, a biotechnology company, used GANs[8](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn8) to generate a set of promising drug candidates for a specific target protein in just 46 days, significantly faster than traditional drug discovery methods.

    &#x20;
4.  4\.

    **Customer service**: Businesses can use transformer-based generative models to develop AI-powered chatbots that can understand and respond to customer queries more effectively. These chatbots can handle a wide range of customer service tasks, reducing response times and freeing up human agents to focus on more complex issues.

    &#x20;
5.  5\.

    **Video game development**: Generative AI can be applied in game development to create realistic and dynamic game environments, characters, and objects. For instance, Promethean AI[9](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn9), a platform for game developers, leverages GANs to generate 3D models and textures, simplifying the content creation process and reducing the time and resources needed for game development.

    &#x20;

Generative AI is a powerful technique, but it also has some challenges. Some of the challenges of generative AI include

1.  1\.

    **Data requirements**: Generative AI systems require large amounts of data to train. This data can be expensive and time-consuming to collect.

    &#x20;
2.  2\.

    **Interpretability**: Generative AI systems are often difficult to interpret. It can be difficult to understand how the system generates its output.

    &#x20;
3.  3\.

    **Bias**: Generative AI systems can be biased. This means that the system may generate output that is biased toward certain groups of people or toward certain viewpoints.

    &#x20;

Generative AI is a rapidly evolving field, and new applications are being discovered all the time. As generative AI continues to develop, it is likely to have a profound impact on many different industries.

Generative AI offers a wide range of applications and opportunities for businesses to innovate, improve efficiency, and drive growth. As the field of generative AI continues to evolve, further advancements in algorithms and applications are expected, providing even more possibilities for businesses to capitalize on this cutting-edge technology.

### Foundational Models

In this subsection, we will discuss foundational models, their core components, popular foundational models, and their applications. We will also explore real-world examples and case studies to demonstrate the impact of these models on businesses and AI applications.

Foundational models are a class of machine learning models that have been pre-trained on massive amounts of data to learn the underlying structure and patterns within the data. These models can be fine-tuned for specific tasks using a relatively small amount of labeled data, enabling them to generalize well and achieve state-of-the-art performance across various domains. The primary advantage of foundational models is their ability to leverage pre-existing knowledge, which reduces the need for extensive training data and computational resources.

Core components of foundational models:

1.  1\.

    **Pre-trained language models**: Foundational models are often pre-trained on large corpora of text, such as web pages, books, and articles, allowing them to learn the underlying structure of language, including grammar, syntax, and semantics. This pre-training phase enables the models to capture a rich understanding of the language and generate meaningful representations of text.

    &#x20;
2.  2\.

    **Transfer learning and finetuning**: Transfer learning is the process of leveraging the pre-trained knowledge of a foundational model and adapting it to a specific task using a smaller labeled dataset. Finetuning involves updating the model’s weights and biases using the task-specific dataset to tailor the model’s performance to the desired task. This process significantly reduces the amount of data and computational resources required to achieve high performance in various applications.

    &#x20;

The following are popular foundational models and their applications:

1.  1\.

    **BERT (Bidirectional Encoder Representations from Transformers**): BERT[10](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn10) is a transformer-based model developed by Google that has been pre-trained on a vast amount of text data. It is designed for bidirectional context understanding, enabling it to capture complex relationships between words and their meanings. BERT has been applied to various natural language processing (NLP) tasks, such as sentiment analysis, named entity recognition, and question-answering systems, achieving state-of-the-art performance in these domains.

    &#x20;
2.  2\.

    **GPT (Generative Pre-trained Transformer**): GPT, developed by OpenAI, is another transformer-based model that has been pre-trained on a large corpus of text data. GPT is primarily designed for language generation tasks, allowing it to create coherent and contextually relevant text. GPT has been applied to numerous NLP tasks, including text summarization, translation, and content generation. The latest iteration, GPT-4, has demonstrated human-like text generation capabilities, making it a powerful tool for various applications.

    &#x20;
3.  3\.

    **T5 (Text-to-Text Transfer Transformer)**: T5, developed by Google Research, is a transformer-based model that frames all NLP tasks as a text-to-text problem. This unified approach allows T5 to perform tasks such as translation, summarization, question-answering, and text classification by converting input text to target text. T5 has achieved state-of-the-art performance on numerous benchmarks, showcasing its versatility and power in handling diverse NLP tasks.

    &#x20;
4.  4\.

    **LaMDA**: LaMDA is a foundational model developed by Google AI. LaMDA is able to generate text, translate languages, and answer questions.

    &#x20;
5.  5\.

    **Meena**: Meena is a foundational model developed by Google[11](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn11) AI. Meena can generate text, translate languages, and answer questions.

    &#x20;

Real-world examples and case studies of foundational models:

1.  1\.

    **Sentiment analysis**: Businesses can leverage foundational models like BERT and GPT to analyze customer feedback, product reviews, and social media posts to identify sentiment trends, enabling them to make data-driven decisions about product improvements, customer service, and marketing strategies. For example, an e-commerce company can use BERT to automatically classify product reviews as positive, negative, or neutral, helping them identify areas for improvement and better understand customer needs.

    &#x20;
2.  2\.

    **Customer support chatbots**: Foundational models can be used to create intelligent chatbots that understand natural language queries and provide accurate, contextually relevant responses. For instance, a telecom provider can use GPT-4 to build a chatbot that can handle customer queries about billing, troubleshooting, and service-related issues, providing instant support and reducing human intervention.

    &#x20;
3.  3\.

    **Content generation**: Businesses can leverage foundational models like GPT-4 to generate high-quality content for their websites, blogs, and marketing materials. For example, a marketing agency can use GPT-4 to create engaging blog posts, social media content, and email campaigns, saving time and resources while maintaining a consistent brand voice.

    &#x20;
4.  4\.

    **Text summarization**: Foundational models like T5 can be employed to automatically generate summaries of lengthy documents, such as research papers, news articles, and legal contracts. This can help businesses save time and resources by enabling them to quickly understand the key points of complex documents. For instance, a law firm can use T5 to summarize lengthy contracts, helping them identify critical clauses and potential risks more efficiently.

    &#x20;
5.  5\.

    **Machine translation**: Businesses operating in multiple languages can benefit from the translation capabilities of foundational models like BERT and T5. These models can be fine-tuned to perform translations between various languages with high accuracy, enabling businesses to communicate effectively with international customers and partners. For example, a global e-commerce company can use T5 to translate product descriptions and customer reviews into multiple languages, expanding their reach and enhancing customer experience.

    &#x20;
6.  6\.

    **Personalized recommendations**: Foundational models can be applied to develop personalized recommendation systems that can analyze user preferences, browsing history, and purchase patterns to provide tailored product or content suggestions. For example, a streaming platform can use BERT to analyze user preferences and viewing history, recommending movies and TV shows that align with individual tastes, leading to higher user engagement and satisfaction.

    &#x20;

#### Deep Dive into Large Language Models

Given the importance of large language models, I will spend some time to, firstly, give an intuition of how they work – will focus on ChatGPT – and second, provide some advice how to put them into practice in your business. I will include some prompting exercises at the end of the chapter and additional code in my GitHub site.

**Embeddings**

Most of the Internet’s content is text-based, a format not easily processed by neural networks. Converting words to numbers for machine learning is a complex task. For instance, we have a simple vocabulary of four terms: Cat, Dog, Kitten, and Puppy.

A basic approach might assign each term a consecutive number:

* Cat → 1
* Dog → 2
* Kitten → 3
* Puppy → 4

This system can lead to misleading interpretations. A network might infer that a Puppy is four times as valuable as a Cat, which is incorrect. To avoid such misconceptions, we adopt a different strategy called “one-hot encoding,” where we assign binary vectors to each term:

* Cat → \[1, 0, 0, 0]
* Dog → \[0, 1, 0, 0]
* Kitten → \[0, 0, 1, 0]
* Puppy → \[0, 0, 0, 1]

Though this method eliminates false numerical inferences, it’s not scalable due to the vast number of unique words in use, resulting in long vectors with many zeroes.

This is where “word embeddings” come into play. The idea is to map words with similar meanings closer to each other in a multidimensional space. For instance, Cat and Dog may occupy nearby locations, as would Kitten and Puppy. In a two-dimensional space, this could look like

* Cat → \[3, 1]
* Dog → \[3, 2]
* Kitten → \[1, 1]
* Puppy → \[1, 2]

Here, the first coordinate might represent “age” (adult vs. young), and the second could denote “species” (cat vs. dog). While this example uses only two dimensions, more dimensions could encode additional semantic relationships.

Thus, word embeddings not only manage the scalability issue but also capture important semantic relationships between words, making them a powerful tool in machine learning.

**How ChatGPT Works**

Large language models, such as OpenAI’s ChatGPT or Google’s Bard, demonstrate impressive capabilities, generating human-like text that makes them seem as if they truly understand the language. But how do these models work under the hood? To shed light on this, we will take a deep dive into the mechanics of large language models, drawing insights from Stephen Wolfram’s thoughtful analysis.[12](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn12)

At the heart of large language models, including ChatGPT, is a concept called _**Transformer Neural Networks**_. These networks are built on the foundation of deep learning and are incredibly effective at handling sequential data, making them perfect for natural language processing tasks.

The key idea behind transformer models is “attention” – more specifically, “self-attention.” This mechanism allows the model to consider different words in a sentence, determine their relevance, and use this information to better understand the context.

As an analogy proposed by Wolfram, imagine a vast, multidimensional terrain where every point represents a certain arrangement of words, and distances between points indicate how similar these arrangements are. Transformer networks navigate this terrain, jumping from point to point, and this movement signifies the transition from one word or phrase to another.

When processing a sentence, the self-attention mechanism allows the model to focus on the words that provide crucial context for understanding the current word. For instance, when determining the meaning of “she” in a sentence, the model uses attention to focus on the parts of the sentence that indicate who “she” is.

Now, let’s talk about training these models. ChatGPT is trained using unsupervised learning. It’s exposed to a large dataset – in the case of GPT-3, almost half a trillion words. The model learns by predicting the next word in a sentence, adjusting its internal parameters to minimize the difference between its predictions and the actual words.

Here, the “large” in large language models comes into play. The GPT-3 model has 175 billion parameters. These parameters, akin to synaptic connections in a biological brain, are adjusted during the training to capture patterns in the data. This vast number of parameters allows the model to learn a mind-boggling variety of patterns, styles, and structures present in human language.

It’s essential to remember that _**the model is a statistical one**_. It learns the likelihoods of words and phrases following each other, without any innate understanding of the language. It doesn’t have a concept of truth, morality, or the real world. Instead, it’s a giant statistical engine, churning out text based on the patterns it has absorbed from the Internet text.

Finally, when the model generates responses, it uses a method called beam search to ensure coherent and diverse responses. It considers many possible continuations and chooses the one that has the highest overall score according to its learnt parameters.

ChatGPT, powered by transformer neural networks and a vast number of parameters, navigates the terrain of language, using patterns and structures learnt from massive datasets to generate human-like text. Despite its complexity, its core functionality is grounded in fundamental statistical and computational principles, leveraging the power of machine learning to mimic human language in an uncannily effective way.

In the next section, we will explore how this technology is used, its implications, and the ethical considerations that arise when deploying such powerful AI systems.

**Working with LLMs**

When it comes to large language models (LLMs), like OpenAI’s GPT-3 or Meta’s LLaMA, understanding the distinction between pretraining and finetuning is vital. Both processes are fundamental for working with LLMs, and they each come with their own sets of challenges and opportunities.

_**Pretraining an LLM base model involves**_ training a model from scratch on a substantial corpus of text. This process can be likened to training a supercomputer for several months, and it remains a significantly expensive and time-consuming task. The model learns the statistical patterns of language during this phase but does not specialize in any specific task. Training a model utilizing the vast data available on the Internet comes with a hefty price tag. While OpenAI hasn’t revealed precise numbers, it’s estimated that GPT-3 was trained on an enormous 45 terabytes of text data. This amount is equivalent to roughly one million feet of bookshelf space, or about 25% of the total holdings of the Library of Congress. The speculated cost for such a massive undertaking is believed to be in the millions of dollars. Clearly, such resource-intensive training goes beyond the reach of a typical start-up and most mid-size companies.

On the other hand, _**finetuning**_ involves taking this pretrained model and further training it on a smaller, more specific dataset. With recent developments in Parameter Efficient Training (PEFT) techniques,[13](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn13) such as LoRA and LLaMA-Adapter, finetuning can now be performed relatively quickly and inexpensively. These techniques allow the model to specialize in a particular task, like translating text or answering medical questions. A good source of information about LLM and finetuning, including Open Source ones, is the Hugging Face website.[14](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn14)

Meta’s release of the LLaMA models, ranging from 7 billion to 65 billion parameters, was a substantial step forward in this regard. However, these weights are intended for research purposes on.

To this end, initiatives like those from Together Compute[15](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn15) and MosaicML[16](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn16) have emerged, aiming to produce high-quality, openly available pretrained models. This push for openness ensures that advancements in AI and LLMs can continue at a steady pace, enabling broader experimentation and discovery.

With a pretrained model in hand, finetuning can be applied effectively even by smaller companies to address their specific business problems. The choice between training from scratch and finetuning depends on various factors, including data size, complexity, desired outcomes, and available resources.

Finetuning a pretrained LLM is generally quicker, less expensive, and can still yield impressive results. It is suitable for a range of tasks and requires less data. However, it might not perform as well as a freshly trained model, especially for highly specific tasks.

Recent discussions have also compared the efficiency of finetuning with few-shot learning, a method that involves providing the model with a few examples and then asking it to solve a task. Some experts suggest few-shot prompts might suffice in 90% of use cases, making it a worthy consideration.

In summary, working with large language models involves a blend of understanding these AI techniques and knowing how to apply them to specific use cases. As we navigate the rapidly evolving landscape of AI, these concepts provide a foundation for harnessing the full potential of these impressive models.

Foundational models are a powerful technique, but they also have some challenges. Some of the challenges of foundational models include

* **Data requirements**: Foundational models require massive amounts of data to train. This data can be expensive and time-consuming to collect.
* **Computational requirements**: Foundational models can be computationally expensive to train.
* **Interpretability**: Foundational models are often difficult to interpret. It can be difficult to understand how the model makes its decisions.

Foundational models are a rapidly evolving field, and new applications are being discovered all the time. As foundational models continue to develop, it is likely to have a profound impact on many different industries.

In conclusion, foundational models have become an integral part of modern AI applications, offering significant benefits in terms of performance, efficiency, and adaptability. As we continue to witness rapid advancements in AI and machine learning, it is crucial for business executives to stay informed and adopt a First Principles approach to implementing these technologies, maximizing the value derived from AI-driven solutions.

### Best Practices and Considerations for Implementing Neural Networks, Deep Learning, and Foundational Models

As companies increasingly leverage neural networks, deep learning, and foundational models to drive business growth and innovation, it is essential to consider best practices and key considerations when implementing these powerful techniques. This section will discuss five important aspects: data quality and preprocessing, model selection and architecture design, hyperparameter tuning and optimization, model evaluation and performance metrics, and ethical and responsible AI considerations:

1.  1\.

    **Data quality and preprocessing**: The performance of AI models is heavily dependent on the quality of the data used for training and validation. Ensuring high-quality data is a critical step in building effective neural networks and deep learning models. The data should be clean and free of errors, and it should be representative of the problem that the model is being trained to solve.

    &#x20;
2.  2.**Model selection and architecture design**: Choosing the right model architecture for your problem is essential to achieving optimal performance:

    1.  a.

        **Start simple**: Begin with a simpler model, such as a feedforward neural network or a shallow CNN, before moving on to more complex architectures. This approach allows you to establish a baseline performance and understand the nuances of your problem.

        &#x20;
    2.  b.

        **Leverage existing architectures**: For many problems, pre-existing architectures like CNNs for image recognition, RNNs for sequence data, or transformers for NLP have proven effective. Use these as a starting point and tailor them to your specific problem.

        &#x20;
    3.  c.

        **Experiment with different architectures**: Test various architectures to determine which one works best for your problem. This may involve adding or removing layers, changing activation functions, or using different types of layers (e.g., convolutional, recurrent, or attention-based).

        &#x20;

    &#x20;
3.  3.**Hyperparameter tuning and optimization**: Optimizing hyperparameters can significantly improve the performance of your model:

    1.  a.

        **Systematic search**: Perform a grid search or random search to explore various hyperparameter combinations. Alternatively, consider using more advanced techniques such as Bayesian optimization or genetic algorithms.

        &#x20;
    2.  b.

        **Validation set**: Use a separate validation set to tune your hyperparameters, preventing overfitting and ensuring that your model generalizes well to unseen data.

        &#x20;
    3.  c.

        **Regularization**: Techniques such as L1 and L2 regularization, dropout, and early stopping can help prevent overfitting and improve model generalization.

        &#x20;

    &#x20;
4.  4.**Model evaluation and performance metrics**: Evaluate your model’s performance using appropriate metrics and techniques:

    1.  a.

        **Select relevant metrics**: Choose performance metrics that align with your business objectives, such as accuracy, precision, recall, F1 score, or area under the ROC curve.

        &#x20;
    2.  b.

        **Cross-validation**: Employ k-fold cross-validation or stratified k-fold cross-validation to obtain a more reliable estimate of your model’s performance.

        &#x20;
    3.  c.

        **Monitor training progress**: Track your model’s performance on both training and validation sets during training, enabling early identification of potential overfitting or underfitting.

        &#x20;

    &#x20;
5.  5.**Ethical and responsible AI considerations**: Implementing AI solutions requires careful consideration of ethical and responsible AI practices:

    1.  a.

        **Bias and fairness**: Be aware of potential biases in your data and model, which could lead to unfair treatment of certain groups or individuals. Regularly assess and mitigate potential biases by employing fairness metrics and ensuring diverse and representative data.

        &#x20;
    2.  b.

        **Transparency and explainability**: Make your AI models more transparent and interpretable by leveraging techniques such as feature importance, partial dependence plots, or explainable AI methods like LIME and SHAP.

        &#x20;
    3.  c.

        **Privacy and security**: Protect the privacy of your data subjects by implementing data anonymization, data encryption, and secure data storage practices. Additionally, consider using techniques like differential privacy and federated learning to further enhance data privacy during model training.

        &#x20;
    4.  d.

        **Accountability and governance**: Establish a governance framework that outlines the responsibilities of various stakeholders in the AI development and deployment process. Implement processes for ongoing monitoring, maintenance, and auditing of AI systems to ensure compliance with relevant laws, regulations, and ethical standards.

        &#x20;

    &#x20;

PROMPT EXERCISES

We will use Bard/ChatGPT to create code that can be exported and run to Google’s Colab. All the scripts were produced for the first time running code with ChatGPT at the time of writing. However, please note that due to continuous API updates, you will very likely get different answers or even might need to do a bit of debugging.

**Exercise 1: Supervised Learning** **– Neural Network** **with Keras**

Prompt for Bard/ChatGPT:\<Begin Prompt>Generate a Python script to accomplish the following tasks:

1. 1.Load the Titanic dataset available at https://raw.github.com/datasciencedojo/datasets/master/titanic.csv into a pandas DataFrame.&#x20;
2. 2.Preprocess the dataset by handling missing values and converting categorical variables into numerical ones.&#x20;
3. 3.Split the dataset into a training set and a testing set.&#x20;
4. 4.Build a simple neural network model using TensorFlow. The model should take into account the features available in the dataset and predict the 'Survived' column.&#x20;
5. 5.Train the TensorFlow model using the training set and evaluate it using the testing set. Print out the accuracy, precision, recall, and F1-score of the model.&#x20;
6. 6.Also, train a simpler machine learning model for comparison, such as logistic regression from scikit-learn. Train this model with the same training set and evaluate it with the same testing set. Print out the accuracy, precision, recall, and F1-score of this model too.&#x20;
7. 7.Finally, compare the performance of the two models and print a statement about which model performed better and why you think this might be the case.&#x20;

\</End Prompt>**Exercise 2: Implementing a** **Convolutional Neural Network (CNN)** **with TensorFlow**\<Begin Prompt>Generate a Python script to accomplish the following tasks:

1. 1.Load the CIFAR-10 dataset from Keras datasets.&#x20;
2. 2.Preprocess the data and divide it into training and testing sets.&#x20;
3. 3.Build a Convolutional Neural Network (CNN) using TensorFlow and train it on the CIFAR-10 dataset.&#x20;
4. 4.Evaluate the trained model's performance on the test data.&#x20;

\</End Prompt>**Exercise 3: Creating a Generative Adversarial Network (GAN)**\<Begin Prompt>Generate a Python script to accomplish the following tasks:

1. 1.Use the Fashion MNIST dataset from Keras datasets.&#x20;
2. 2.Preprocess the data and implement a Generative Adversarial Network (GAN) using TensorFlow.&#x20;
3. 3.Train the GAN on the dataset and generate new synthetic images.&#x20;

\</End Prompt>**Exercise 4: Implementing an Autoencoder for** **Dimensionality Reduction**\<Begin Prompt>Generate a Python script to accomplish the following tasks:

1. 1.Use the MNIST dataset from Keras datasets.&#x20;
2. 2.Preprocess the data and split it into training and testing sets.&#x20;
3. 3.Implement an autoencoder using Keras to reduce the dimensionality of the data.&#x20;
4. 4.Visualize the output of the autoencoder for a sample of test images.&#x20;

\</End Prompt>**Exercise 5: LLM Finetuning**\<Begin Prompt>Generate a Python script to fine-tune a Large Language Model (LLM), GPT-2 from Hugging Face :

1. 1.Specify the Model and sample Dataset: Please use GPT-2 and the IMDB movie database as sample Dataset.&#x20;
2. 2.Preprocess the Data: Before training, the data needs to be preprocessed into a format that the model can understand. This often involves tokenization, or splitting the text into smaller parts called tokens.&#x20;
3. 3.Fine-Tuning the Model: Once your data is ready, you can proceed with the model fine-tuning. In this step, you will load your specified model and dataset and then initiate the training process.&#x20;
4. 4.Evaluate the Model: After the model has been fine-tuned, it's important to evaluate it to see how well it performs.&#x20;

\</End Prompt>

Please note that these exercises assume a basic understanding of Python and machine learning concepts. The exercises are designed to be introductory and are not exhaustive of the breadth of possibilities in neural networks, deep learning, and generative AI foundational models.

### Key Takeaways

As we reach the conclusion of this chapter, it is crucial to recap the key concepts we have explored and emphasize the importance of understanding neural networks, deep learning, and foundational models from a First Principles perspective. We have discussed the core components, popular architectures, real-world applications, and best practices associated with these advanced AI techniques. Now, we encourage you to explore and apply these powerful tools to solve real-world problems and grow your business. Let’s recap the key takeaways:

1.  1.**Takeaway 1: Prioritization of data quality and model selection**

    1.  a.

        **Data quality and preprocessing**: The quality of data is critical in AI. Invest time in data cleaning, handling missing values, outliers, and ensuring data is representative of the problem domain.

        &#x20;
    2.  b.

        **Model selection and** **architecture design**: Choose models that are suitable for the problem at hand and desired outcomes, not just because they are trendy.

        &#x20;

    &#x20;
2.  2.**Takeaway 2: Importance of systematic optimization, evaluation, and ethical considerations**

    1.  a.

        **Hyperparameter tuning and optimization**: Utilize systematic techniques for hyperparameter tuning. Avoid the temptation of random or manual trial-and-error methods.

        &#x20;
    2.  b.

        **Model evaluation and performance metrics**: Use comprehensive performance metrics to evaluate model performance, and do not ignore interpretability or fairness for the sake of model performance.

        &#x20;
    3.  c.

        **Ethical and responsible AI considerations**: Always consider the ethical implications of your AI solutions, including fairness, transparency, privacy, and governance measures.

        &#x20;

    &#x20;
3.  3.**Takeaway 3: Importance of understanding and applying advanced techniques**

    1.  a.

        **Understand neural networks, deep learning, and foundational models**: Understand these techniques from a First Principles perspective.

        &#x20;
    2.  b.

        **Explore and apply advanced techniques to solve real-world problems**: These techniques, while still under development, have the potential to revolutionize many industries. Businesses can gain a competitive advantage by exploring and applying these techniques, which can solve a wide variety of problems in business, such as fraud detection, customer service, and product development.

        &#x20;

    &#x20;

Footnotes[1](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn1\_source)

[www.numenta.com/resources/books/a-thousand-brains-by-jeff-hawkins/](http://www.numenta.com/resources/books/a-thousand-brains-by-jeff-hawkins/)

&#x20;[2](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn2\_source)

[https://cloud.google.com/tpu/docs/inception-v3-advanced](https://cloud.google.com/tpu/docs/inception-v3-advanced)

&#x20;[3](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn3\_source)

[https://research.facebook.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/](https://research.facebook.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/)

&#x20;[4](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn4\_source)

[https://github.com/mozilla/DeepSpeech](https://github.com/mozilla/DeepSpeech)

&#x20;[5](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn5\_source)

[www.deepmind.com/research/highlighted-research/alphago](http://www.deepmind.com/research/highlighted-research/alphago)

&#x20;[6](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn6\_source)

[www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx](http://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx)

&#x20;[7](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn7\_source)

[https://openai.com/research/musenet](https://openai.com/research/musenet)

&#x20;[8](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn8\_source)

[www.globenewswire.com/en/news-release/2023/04/24/2653269/31533/en/Insilico-Medicine-Successfully-Discovered-Potent-Selective-and-Orally-Bioavailable-Small-Molecule-Inhibitor-of-CDK8-Using-Generative-AI.html](https://www.globenewswire.com/en/news-release/2023/04/24/2653269/31533/en/Insilico-Medicine-Successfully-Discovered-Potent-Selective-and-Orally-Bioavailable-Small-Molecule-Inhibitor-of-CDK8-Using-Generative-AI.html)

&#x20;[9](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn9\_source)

[www.prometheanai.com/](http://www.prometheanai.com/)

&#x20;[10](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn10\_source)

[https://cloud.google.com/ai-platform/training/docs/algorithms/bert-start](https://cloud.google.com/ai-platform/training/docs/algorithms/bert-start)

&#x20;[11](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn11\_source)

[https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html)

&#x20;[12](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn12\_source)

Stephen Wolfram (2023), “What Is ChatGPT Doing ... and Why Does It Work?”

&#x20;[13](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn13\_source)

[https://huggingface.co/blog/peft](https://huggingface.co/blog/peft)

&#x20;[14](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn14\_source)

[https://huggingface.co/](https://huggingface.co/)

&#x20;[15](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn15\_source)

[www.together.xyz/](http://www.together.xyz/)

&#x20;[16](https://learning.oreilly.com/library/view/grow-your-business/9781484296691/html/605840\_1\_En\_10\_Chapter.xhtml#Fn16\_source)

[www.mosaicml.com/](http://www.mosaicml.com/)
