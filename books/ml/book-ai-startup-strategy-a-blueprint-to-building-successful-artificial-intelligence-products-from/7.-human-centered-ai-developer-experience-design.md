# 7. Human-Centered AI Developer Experience Design

In the previous chapter, we learned how to build a human-centered AI experience design oriented toward the end user. In this chapter, we will learn how to design AI developer experience (DX), a methodology aimed at making the development process of AI-powered applications more straightforward and intuitive for developers. By focusing on the needs and preferences of developers, this approach can help streamline the creation of AI-based products and services. In addition, by providing a framework for incorporating AI into applications, AI developer experience design can help reduce the risk of errors and glitches during development. In building a developer experience for AI products, design thinking is essential to create an intuitive and user-friendly experience that contributes to the AI product’s robustness and trustworthiness. By empathizing with the needs and preferences of developers and using design thinking methodologies to guide the development process, teams can create an experience tailored to their target audience’s needs. This allows for a more efficient and effective development process and an end product more likely to succeed. In this chapter, we will explore the role of design thinking in creating a successful developer experience for AI products and provide two case studies that illustrate its application in practice.

### AI Products for Developers

As an AI product manager, one of the main goals is to develop products targeted to developers that make AI development and integration easy. Four main types of AI products are targeted toward developers: AI as a Service, AI as an Engine (AIaaE), AI toolkits, and AI Platform as a Service (Figure [7-1](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig1)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig1_HTML.jpg" alt="" height="636" width="1418"><figcaption><p>Figure 7-1 </p></figcaption></figure>

The developer experience for AI as a Service, AI as an Engine, AI toolkits, and AI PaaS can differ depending on the specific service or toolkit and the intended use case:

* AI as a Service (AIaaS) is a cloud-based subscription model that allows businesses to access AI capabilities without needing in-house expertise or infrastructure. These services can include natural language processing, image recognition, and machine learning. Examples of AIaaS include FaceTec, Identifai, Onfido, OpenAI, and Routific. These AIaaS providers allow developers to easily access and utilize AI without expensive infrastructure or specialized knowledge. Developers can access the AI capabilities provided by the service through API calls, which can be integrated into their applications or services. This allows developers to utilize AI capabilities without worrying about the underlying infrastructure or maintenance.
* AI toolkits are pre-built tools and libraries that developers can use to build, train, and deploy AI models. These toolkits can include platforms and libraries for machine learning, deep learning, computer vision, natural language processing, pre-trained models, data visualization tools, and development frameworks. Examples of AI toolkits include Landing AI, Clarifai, Roboflow, Viso AI, and Super AI. These toolkits provide developers with a way to build and deploy AI models without the need for extensive expertise in AI or machine learning quickly and easily. AI toolkits are also typically delivered as command-line tools that developers can use to build, train, and deploy AI models (i.e., Masterful AI). These toolkits often include libraries for machine learning, deep learning, computer vision, natural language processing, pre-trained models, data visualization tools, and development frameworks. Toolkit outputs can also be deployed to operating systems, containers, or virtual machines (VMs), allowing developers to run them in their preferred environment.
* AI as an Engine (AIaaE) refers to integrating AI capabilities directly into a product or application, typically as part of the product’s core functionality. With AI as an Engine, businesses can build AI-powered products and services tailored to specific use cases and industries. Examples of AI engines include Trueface and Visionaire AI. These AI engines allow developers to add advanced AI capabilities to their products and services, allowing them to build cutting-edge applications that can be used in a wide range of industries. AI as an Engine is typically delivered as a Software Development Kit (SDK) that can be integrated into the developer’s existing product or application. SDKs are tools and libraries that developers can use to access the AI engine’s capabilities and integrate them into their products or services. These SDKs can also be delivered via _operating systems_, containers, or virtual machines (VMs) to provide flexibility for developers to run them in the preferred environment.
* AI Platform as a Service (AI PaaS) is a platform that provides a complete environment for developing, deploying, and managing AI applications, including data storage, compute power, and a suite of AI development tools. Examples of AI PaaS are Amazon Machine Learning, Azure Machine Learning, and IBM Watson. These platforms provide developers with a comprehensive environment for building and deploying AI applications, allowing them to focus on the development and integration of AI without worrying about the underlying infrastructure. AI Platform as a Service (AI PaaS) is typically delivered through API, SDK, and a graphical user interface (GUI). Developers can use the GUI to access the platform’s capabilities and manage their AI models, while the API and SDK allow them to programmatically access the platform’s capabilities and integrate them into their products or services. These platforms can also be delivered via operating systems, containers, or virtual machines (VMs), allowing developers to run them in their preferred environment.

Overall, the delivery method of an AI product to developer users can vary depending on the product itself. Still, most commonly, it is delivered through API, SDK, command-line interface (CLI), operating systems, containers, VMs, or GUI. These delivery methods are designed to make it easy for developers to access and use the AI capabilities provided by the product and to allow them to integrate AI into their products and services most efficiently.

Building an AI Platform as a Service (PaaS) can be daunting, requiring significant resources and expertise. It’s a realm typically reserved for tech giants like Google, Amazon, IBM, and Microsoft. AI PaaS is beyond any startup capability and is not recommended to be developed by them, so we are not discussing it in this chapter. However, smaller companies still have opportunities to significantly impact AI by building an exceptional developer experience for AI as a Service, AI as an Engine, and AI toolkits. These AI products can provide similar and overlapping developer journeys, allowing developers to access advanced AI capabilities without requiring extensive infrastructure or maintenance. By providing developers with easy-to-use and flexible tools, companies can help bridge the gap between cutting-edge AI research and real-world implementation, making it possible for developers of all skill levels to create innovative and intelligent applications.

In summary, while AI as a Service, AI as an Engine, and AI toolkits can provide developers with powerful AI functionality, they can focus differently on the developer experience, with AI as a Service and AI as an Engine emphasizing ease of use and integration and AI toolkits emphasizing flexibility and control.

### Principles of AI DX Design

When designing the developer experience for AI products, several key principles should be considered:

1.  1\.

    _Ease of use and integration_: The AI product should be easy to use and integrate into a developer’s workflow, with a clear and consistent user interface and minimal setup required.

    &#x20;
2.  2\.

    _Flexibility and control_: The AI product should provide developers with the flexibility and control they need to tailor the product to their specific needs and use cases.

    &#x20;
3.  3\.

    _Comprehensive tools and capabilities_: The AI product should provide a comprehensive set of tools and capabilities for developing, deploying, and managing AI models and data infrastructure.

    &#x20;
4.  4\.

    _Good documentation and support_: The AI product should come with clear and comprehensive documentation and responsive support channels to help developers understand how to use the product and get help if needed.

    &#x20;
5.  5\.

    _Monitoring and visibility_: The AI product should provide developers with visibility and insight into their AI models’ performance and the underlying systems that support them to identify and debug issues and track performance.

    &#x20;
6.  6\.

    _Scalability and maintenance_: The AI product should be able to handle large volumes of data and scale to meet the demands of the developer’s use case. It also should be well-maintained and supported, with regular updates and bug fixes.

    &#x20;
7.  7\.

    _Collaboration and community_: The AI product should facilitate collaboration and knowledge sharing among developers and encourage the participation of a community of users who can share their expertise and best practices.

    &#x20;
8.  8\.

    _Trustworthiness_: Trust is a critical factor in any AI system, so the developer experience should include clear explanations of how the AI models work, how they were trained, what data they were trained on, and what the limitations and potential biases of the models are. This will help developers understand how the models are likely to behave in different situations and make informed decisions about when and how to use them.

    &#x20;
9.  9\.

    _Fairness_: AI models can perpetuate and even amplify societal biases, so fairness must be considered when designing AI products. The developer experience should include tools and capabilities that help developers identify and mitigate biases in their models and ensure that the models are fair and unbiased.

    &#x20;
10. 10\.

    _Feedback_: The AI product should include feedback mechanisms, such as evaluation metrics, monitoring systems, and user feedback, to allow developers to measure the performance of the models, identify errors, and improve the models over time.

    &#x20;

An example of a good developer AI product is GPT-3 from OpenAI, which excels in developer experience design, aligning well with the principles of good developer experience. Its easy integration, flexibility, comprehensive tools, and responsive support enable developers to build sophisticated applications effortlessly.

### AI Developer Experience Process Framework

Design thinking is a user-centered approach to design that emphasizes empathy, prototyping, and testing to understand and solve problems. In designing a developer experience (DX) process, design thinking is essential because it allows the team to understand the needs and pain points of the target audience (developers) and create solutions tailored to their specific needs. The similarity between developer experience (DX) and typical user experience (UX) based on design thinking is that both design approaches are user-centered and start with understanding the needs and pain points of the target audience. Both processes also involve using prototypes and testing to validate the design concept with the target audience.

The difference is that developer experience (DX) specifically targets developers as users. At the same time, user experience (UX) can target any user. Developer experience focuses on improving the developer experience, while user experience enhances the overall user experience. Developers have different needs and pain points than other users, and the DX process is tailored to address these needs.

#### 1. Empathize

The first phase of building AI product developer experience using design thinking is the Empathize phase. This phase is crucial in understanding the needs and pain points of our target audience, the developers using the AI product. The goal of this phase is to create a preliminary hypothesis of the developer persona that will shape the design of the AI product and improve the developer experience. The step-by-step and outputs from each stage will be explained.

Steps:

This is what is needed in the _Empathize_ phase:

1.  1._Hypothesize_: Hypothesize about the types of developers using our product and what they need to succeed in their AI development. The task will involve understanding the target audience and their roles, such as front-end developers, mobile developers, back-end developers, and data scientists, as a persona. To have a more detailed persona, we will also identify the development tasks, problems, and pain points these target developers face, such as AI development, integration, and performance. Therefore, the persona of the developers is defined as follows:

    1.  a.

        _Developer user_: What is the specific title and function of the developer?

        &#x20;
    2.  b.

        _Applications developer_: What is the application they develop?

        &#x20;
    3.  c.

        _Goals and motivations_: What are the goals and motivations of the developer using the AI product?

        &#x20;
    4.  d.

        _Pain points and challenges_: What are the developer’s pain points and challenges when working with AI?

        &#x20;
    5.  e.

        _Metrics_: What metrics are used to measure the performance of the AI?

        &#x20;

    &#x20;
2.  2\.

    _Define data-gathering methods_: We will define data-gathering methods to support our hypothesis. We will also examine prominent product review platforms such as producthunt.com, unite.ai, futurepedia.io, and saashub.com. We will gain valuable insight into the current product landscape to locate potential gaps in market demand based on feedback and reviews. We will also conduct in-depth interviews and collect user analytics from the sandbox to understand their pain points, feedback, and success criteria.

    &#x20;

Output:

The output of this phase will be an understanding of the benefits of AI tools or services, which will include information about the developer user of our target audience, such as front-end engineer, mobile engineer, back-end engineer, and data scientist. Additionally, we will gather information about the persona and problems and pain points developers face regarding AI development and integration, performance monitoring, and the types of applications they develop, such as SaaS, mobile, or ecommerce websites. We also collect information on the AI tasks they are working on, such as prediction, object recognition, forecasting, generation, optimization, and recommendation, as well as the specific tasks and metrics they use to measure success, such as latency and accuracy. To summarize, the following are the outputs expected from this phase (Table [7-1](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Tab1)).Table 7-1&#x20;

Hypothesize the Developer’s Need for AIaaS, AIaaE, or AI Toolkit

| **Components**             | **Sample Data**                                                                   |
| -------------------------- | --------------------------------------------------------------------------------- |
| **Developer user**         | Front-end developer, mobile developer, back-end developer, data scientist         |
| **Applications developed** | Accounting SaaS, ecommerce mobile app, CRM SaaS                                   |
| **Cognitive tasks**        | Recommending books, forecasting weather                                           |
| **Metrics**                | Click rate, prediction accuracy, classification accuracy                          |
| **Business values**        | Improving revenue, reducing cost, reducing risk, increasing customer satisfaction |

We will use the general persona data to create the preliminary hypothesis of the AIaaS, AIaaE, or AI toolkit along with its user developer persona with the following format: “_We believe the \[developer users] who develop \[applications] will benefit from integrating the application with our \[AI as a Service/AI toolkit] to \[augment/automate] some \[cognitive tasks] to optimize \[metrics] which results in \[business values]_.”

#### 2. Define

The Define phase of design thinking for a developer product is focused on detailing the developer persona, mapping the developer experience journey, and understanding the tasks and mental models of the target audience. This phase aims to understand the developer’s experience from initial engagement with the product to ongoing use and maintenance.

Steps:

We will do the following steps in the _Define_ phase:

1.  1.Define the persona of the developers using the AIaaS, AIaaE, or AI toolkits. A developer persona is a fictional representation of a specific type of developer who will be using your product. Here are some of the key components of a developer persona:

    1.  a.

        _Demographics_: This includes age, gender, education level, and job title.

        &#x20;
    2.  b.

        _Applications developed_: The type of applications they usually develop.

        &#x20;
    3.  c.

        _Type of developer user_: The development title and function include back-end developer, machine learning engineer, or data scientist.

        &#x20;
    4.  d.

        _Technical skills_: The developer’s level of expertise in specific programming languages, frameworks, and technologies.

        &#x20;
    5.  e.

        _Goals_: The developer’s goals and objectives, such as increasing productivity, improving the quality of their code, or reducing development time.

        &#x20;
    6.  f.

        _Pain points_: The challenges and frustrations the developer typically experiences, such as lack of documentation, poor tooling, or lack of support.

        &#x20;
    7.  g.

        _Integration method_: The way developers prefer to integrate and interact with AIaaS, AIaaE, or AI toolkits, such as using an API to integrate AI functionality into an existing system, using an SDK to customize AI functionality to specific needs, using a CLI for command-line integration, using a GUI for graphical user interface integration, and using a WebSocket for real-time data streaming.

        &#x20;

    &#x20;
2.  2\.

    Map the developer’s journey from their current state to their desired future state. There is a slight difference between the developer journey of AIaaS, AIaaE, and AI toolkits. The main difference is that in AIaaS and AIaaE, the developers focus more on integrating the AI service with their own applications. In AI toolkits, the developers are focused more on the AI model development using the AI tool and the integration with the existing workflows and technology stacks.

    Therefore, the stages of the developer journey for AIaaS and AIaaE are the signup process, learning how to use the product, trial and experimentation, integration with other tools, and ongoing monitoring and maintenance:

    1.  a.

        _Signup_: In the signup process, we focus on understanding how the developer first finds out about the product, what information they need to decide to use it, and what value they expect to gain from it.

        &#x20;
    2.  b.

        _Learning_: In the learning process, we focus on how the developer acquires the knowledge and skills needed to effectively use the product, what resources they need, and what challenges they may encounter.

        &#x20;
    3.  c.

        _Trial_: In the trial process, we focus on how the developer experiments with the product, what they are trying to accomplish, and what feedback they provide.

        &#x20;
    4.  d.

        _Integration_: In the integration process, we focus on how the developer integrates the product into their existing workflow, what challenges they may encounter, and what changes they make to their application.

        &#x20;
    5.  e.

        _Operationalization_: In the operationalization and monitoring process, we focus on how the developer maintains the AI models developed, what metrics they are monitoring, and what challenges they may encounter.

        &#x20;

    While the stages of the developer journey for AI tools are the same in signing up, learning, and trial, the operationalization step is replaced with development and integration with existing workflow. To summarize, the following are the stages of the developer journey for AI tools:

    1.  a.

        _Signup_: The signup process is the first step for developers to register for the AI tool. It should be simple, user-friendly, and secure.

        &#x20;
    2.  b.

        _Reading instruction_: Developers must read through the product documentation and instructions to understand the features and how to use the tool.

        &#x20;
    3.  c.

        _Trial_: Developers will have the opportunity to test the tool, either through a free trial or a sandbox environment, to ensure it meets their needs.

        &#x20;
    4.  d.

        _Development_: Developers can start building AI models using the tool, taking advantage of pre-built models and libraries and easy-to-use interfaces.

        &#x20;
    5.  e.

        _Integration_: The tool should provide integration options like REST API, SDK, CLI, web-based UI, and event-driven to integrate with existing systems and workflows easily.

        &#x20;

    &#x20;
3.  3\.

    The next step is to understand the mental models of the target audience. This includes understanding the developer’s assumptions, beliefs, and expectations about the product and their goals and motivations for using it. This information is used to create a developer experience journey map, which visually represents the developer’s journey, highlighting key stages, pain points, and opportunities for improvement. By understanding the developer’s journey and mental models, we can identify areas for improvement and design a more effective and satisfying product experience for the developer. This can ultimately lead to better product adoption and usage, improved developer satisfaction, and, ultimately, better business outcomes.

    &#x20;

Output:

The output of this phase is a developer persona canvas (Figure [7-2](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig2)) and a developer experience journey map for AIaaS and AIaaE products (Table [7-2](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Tab2)) and an AI toolkit product (Table [7-3](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Tab3)), which is a visual representation of the process that developers go through when interacting with an AI product.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig2_HTML.jpg" alt="" height="795" width="1418"><figcaption><p>Figure 7-2 </p></figcaption></figure>

Table 7-2&#x20;

Developer Journey Map for AIaaS and AIaaE Products

| **Developer Journey** | **Signup**                                     | **Reading Instruction**                                                                               | **Trial**                                                                                                                     | **Integration with Other Apps**                                                                               | **Operation**                                                                                                            |
| --------------------- | ---------------------------------------------- | ----------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| **User goals**        | Understand what AIaaS can accomplish.          | Understand the basic functionalities.                                                                 | To evaluate the API or SDK and decide whether this is suitable or not.                                                        | To integrate the API/SDK with their own apps.                                                                 | Seamlessly smooth operation.                                                                                             |
| **Expectation**       | Understand what it should do.                  | Understanding of benefits, limitations, and whether the API/SDK can easily integrate with their apps. | To be able to easily use the API or SDK to create simple working apps.                                                        | To be able to integrate the API/SDK with their own applications easily.                                       | To be able to monitor system performance and be notified when something happens, such as error, maintenance, and update. |
| **Task**              | <p>Read description.</p><p>Try some demo.</p>  | <p>Read Getting Started guides.</p><p>Read technical specifications.</p><p>Read example codes.</p>    | <p>Follow along with the tutorials.</p><p>Perform trial with different inputs and parameters.</p><p>Evaluate performance.</p> | <p>Evaluate sample codes.</p><p>Pick boilerplate codes.</p><p>Embed the boilerplate code into their apps.</p> | <p>View performance dashboard.</p><p>View usage and its charge.</p><p>Read release notes.</p>                            |
| **Components**        | <p>Landing page</p><p>Demo</p><p>Use cases</p> | <p>Getting Started guide</p><p>API reference</p><p>Data sheets</p><p>Data acquisition guide</p>       | <p>API sandbox</p><p>Installation SDK</p>                                                                                     | <p>API client libraries</p><p>SDK client libraries</p>                                                        | <p>Performance dashboards</p><p>Usage dashboards</p><p>Release notes</p>                                                 |
| **Pain points**       | Hard to understand the value of the AIaaS.     | Documentation is hard to understand.                                                                  | Unable to create simple AI-powered working apps.                                                                              | Unable to integrate with other applications.                                                                  | Error without explanation during operations.                                                                             |

Table 7-3&#x20;

Developer Journey Map for AI Toolkits

| **Developer Journey** | **Signup**                                     | **Reading Instruction**                                                                               | **Trial**                                                                                                                     | **Development**                                                                                                           | <p><strong>Integration</strong></p><p><strong>with Existing</strong></p><p><strong>Workflow</strong></p>                   |
| --------------------- | ---------------------------------------------- | ----------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- |
| **User goals**        | Understand what AIaaS can accomplish.          | Understand the basic functionalities.                                                                 | To evaluate the API or SDK and decide whether this is suitable or not.                                                        | To use the tool as part of the model development process.                                                                 | To integrate the tool with the current AI model development environment/stack.                                             |
| **Expectation**       | Understand what it should do.                  | Understanding of benefits, limitations, and whether the API/SDK can easily integrate with their apps. | To be able to easily use the API or SDK to create simple working apps.                                                        | To be able to successfully develop an AI model according to the expectation.                                              | To be able to integrate the AI tool with current workflow and environment successfully.                                    |
| **Task**              | <p>Read description.</p><p>Try some demo.</p>  | <p>Read Getting Started guides.</p><p>Read technical specifications.</p><p>Read example codes.</p>    | <p>Follow along with the tutorials.</p><p>Perform trial with different inputs and parameters.</p><p>Evaluate performance.</p> | <p>Develop the AI model using the tool provided.</p><p>Evaluate and monitor the tool’s benefit, cost, and efficiency.</p> | <p>Try the tool.</p><p>Use the tool to be integrated with the current workflow.</p><p>Monitor the benefit of the tool.</p> |
| **Components**        | <p>Landing page</p><p>Demo</p><p>Use cases</p> | <p>Getting Started guide</p><p>API reference</p><p>Data sheets</p><p>Data acquisition guide</p>       | <p>API sandbox</p><p>Installation SDK</p>                                                                                     | <p>API client libraries</p><p>SDK client libraries</p>                                                                    | Integration end point                                                                                                      |
| **Pain points**       | Hard to understand the value of the AIaaS.     | Documentation is hard to understand.                                                                  | Unable to create simple AI-powered working apps.                                                                              | Unable to integrate with other applications.                                                                              | Unable to integrate seamlessly with current AI workflow.                                                                   |

As an AI product developer, creating a persona canvas is essential in understanding your target audience and designing a product that meets their needs. It is a visual tool that helps you identify key characteristics such as technical skills, experience, pain points, and behavior patterns of your product’s developers. By creating a developer persona canvas (Figure [7-2](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig2)), you can better tailor your product to the specific needs of your target audience, increasing the chances of success.

The developer journey map for AI as a Service and AI as an Engine is focused on seamlessly integrating existing applications and ensuring smooth operation. On the other hand, the developer journey for AI toolkits is centered around the development and integration with current workflows and technology stacks, providing developers with the flexibility to build and train their models (Table [7-3](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Tab3)).

The developer journey map for AI toolkits is a set of steps developers go through when working with these tools. It is designed to help developers understand how to build and integrate AI models into their applications. The developer journey typically starts with installing and setting up the toolkit and then building, training, and validating the models using the provided APIs and SDKs. Once the models are built, developers will then integrate them into their existing workflows and technology stacks. The journey also includes ongoing maintenance and monitoring of the models and updating them as necessary.

One key aspect of the developer journey for AI toolkits is the flexibility it provides to developers. Unlike AI as a Service and AI as an Engine, where the models are pre-built and provided by the provider, developers using AI toolkits can build and train their own models. This allows them to customize the models to their specific use case and incorporate domain-specific knowledge. Additionally, the integration process with existing workflows and technology stacks is designed to be as smooth as possible, allowing developers to easily add AI capabilities to their existing applications.

This journey map helps identify pain points and opportunities and guides the rest of the design thinking process. It also helps understand the mental models of the developers, which is essential in creating a product that is aligned with their needs and expectations.

#### 3. Ideate

The Ideate phase in the design thinking process for AI products targeted toward developers is a crucial step in development.

First, we must address the difference between AIaaS, AIaaE, and AI toolkits. AI as a service (AIaaS) and AI as an Engine (AIaaE) differ regarding their target user and usage. AIaaS is typically targeted toward developers or end users, where the AI model is packaged as a service that can be consumed through an API. An example is OpenAI, where they sell GPT for developer users or ChatGPT for end users. The user experience is focused on ease of use, accuracy, and quality of the results. The main goal is to provide a ready-to-use AI solution that can be integrated into an existing application or workflow.

On the other hand, AI as an engine (AIaaE) is targeted toward developers and data scientists, where the AI model is packaged as an engine that can be integrated into an existing application or workflow. The user experience is focused on performance, scalability, and flexibility. The main goal is to provide a robust and customizable AI solution that can be fine-tuned to fit specific use cases.

AI toolkits, on the other hand, are targeted toward developers and data scientists who want to build their own AI models. The user experience is focused on ease of use, flexibility, and control. The main goal is to provide a set of tools and libraries that can be used to build, train, and deploy AI models.

Therefore, the steps and output for each product will be different as they cater to different user needs and use cases. AIaaS and AIaaE will have steps and output focused on user experience and integration, while AI toolkits will have steps and output focused on development and customization.

It is crucial to identify and understand the potential use cases for the AI models packaged as AIaaS and AIaaE and the developers using them. In this phase, the following steps should be taken to ensure a successful outcome of AIaaS and AIaaE developer experience (DX) design:

Steps:

1.  1\.

    _Identify applications:_ The first step in the Ideate phase is identifying the applications that can leverage the AI models packaged as API and SDK. This includes understanding the tasks and problems the AI models will solve and the data types that will be used as input.

    &#x20;
2.  2\.

    _Determine deployment:_ Determine how the AI models will be deployed. This includes understanding the various deployment options such as Web, mobile, virtual machines, or bare-metal servers. It also has to determine which deployment option is the most suitable for the specific use case and the developers using the AI models.

    &#x20;
3.  3\.

    _Define_ _input-output:_ Define the input and output of the AI models. This includes understanding the types of data that will be used as input and the types of outputs that will be generated. It also includes determining the input and output data format and any preprocessing or post-processing that needs to be done.

    &#x20;
4.  4\.

    _Understand in-house development challenge_: Understand the developer’s challenge if they instead build their own AIaaS/AIaaE in-house.

    &#x20;
5.  5\.

    _Define_ _AI type:_ Define the type of AI that will be used. This includes understanding the different types of AI models, such as machine learning, decision optimization, rule-based systems, expert systems, and knowledge representation and reasoning models. It also includes determining which type of AI is the most suitable for the specific use case.

    &#x20;
6.  6\.

    _Define performance monitoring:_ Define the performance monitoring of the AI models. This includes understanding the metrics that will be used to measure the performance of the AI models, the minimum acceptable performance, and how the AI models will be monitored. It also includes understanding how the results of the AI models will be explained to the developers.

    &#x20;
7.  7\.

    _Define version update:_ Define the version update of the AI models. This includes understanding how the AI models will be updated and the frequency of the updates. It also includes understanding how to notify developers that the AI models have been updated to ensure that it does not violate Hyrum’s law. Hyrum’s law emphasizes the importance of designing APIs for AI services that are easy to use and hard to misuse. This means providing clear documentation, well-defined interfaces, error messages, and constraints to limit unintended consequences. By doing so, AIaaS/AIaaE providers can prevent errors, security vulnerabilities, and other issues that may negatively impact their customers’ experience.

    &#x20;
8.  8\.

    _Define_ _parameter optimization_ _and_ _data post-processing:_ We define and understand what parameters or hyperparameters of the AI models that developers themselves can optimize. Parameter optimization that users can handle during inference time is important and necessary because it enables developers to fine-tune model performance based on specific use cases and real-time data. This allows for greater flexibility and adaptability of machine learning models and more efficient and accurate results.

    &#x20;
9.  9\.

    _Define workflow:_ We define which workflow this API/SDK runs in the application and what task has been automated or augmented.

    &#x20;
10. 10._Define feedback:_ We define the feedback given by the AI models. This includes understanding both implicit and explicit feedback given by the AI models. Implicit and explicit feedback are two types of feedback that are commonly used in machine learning:

    1.  a.

        _Implicit feedback:_ This type of feedback is not explicitly provided by the user or data source but is inferred from the data itself. It can come from various sources, such as user behavior or data characteristics, and is typically used when obtaining explicit feedback is not feasible or too expensive.

        &#x20;
    2.  b.

        _Explicit feedback_: This type of feedback is provided by the user or data source, such as through surveys, ratings, or labels. It is typically used when the goal is to train a machine learning model to accurately predict a specific output, such as a classification or a numerical value.

        &#x20;

    _Self-supervised learning_ and _active learning_ are two techniques that can be used to improve the performance of machine learning models using these types of feedback:

    * _Self-supervised learning_: This technique uses unlabeled data to train a model to predict a certain output. By doing so, the model can learn to identify key features of the data without relying on explicit labels. Self-supervised learning can be integrated with the implicit feedback mechanism to train the models.
    * _Active learning_: This technique uses explicit feedback to identify errors in the model’s predictions and then uses these errors to select new training data to improve the model’s performance. _Active learning_ can be integrated with the explicit feedback mechanism to improve the models.

    Furthermore, many different types of feedback can be used to train machine learning models, and the choice of feedback will depend on the specific application and use case. For example, in a natural language processing system, feedback could come in explicit labels (such as correct/incorrect classifications) or implicitly (such as the user’s engagement with the system). In a recommendation system, feedback could come from user ratings or user interactions with the system.

    &#x20;
11. 11\.

    _Define_ _risks and errors_: Explain what potential errors can be caused by the developers, environment (input images from different cameras), and systems, including edge cases that may happen. This will help developers understand how to mitigate these risks and handle errors when they occur.

    &#x20;

Output:

The output of this Ideate phase is the development design experience canvas for AIaaS and AIaaE products (Figure [7-3](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig3)), which will summarize all of the preceding points in a single, easy-to-use visual representation. This canvas will serve as a valuable tool for developers, helping them understand the AI product’s key components and how it can be integrated into their existing workflows.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig3_HTML.jpg" alt="" height="813" width="1418"><figcaption><p>Figure 7-3 </p></figcaption></figure>

AIaaS or AIaaE typically provides a ready-to-use AI model that can be integrated into an existing application or workflow. The developer journey for these types of AI products involves understanding the input and output of the model, as well as the different use cases and applications where the model can be applied. The output of the Ideate phase for AIaaS or AIaaE would typically be a canvas outlining the input and output of the model, as well as the different use cases and applications where the model can be applied.

On the other hand, an AI toolkit is a set of tools and frameworks developers can use to build and train their AI models. The developer journey for an AI toolkit focuses on the development process, including understanding the different AI models and ecosystems that can be developed, assisted, or optimized. The output of the Ideate phase for an AI toolkit would typically be a detailed document outlining the different AI models and ecosystems that can be developed, assisted, or optimized using the toolkit, as well as the different workflows and use cases that the toolkit is designed for.

These are the steps and output for ideating AI developer experience for AI toolkits.

Steps:

1.  1\.

    Identify the AI models and supporting infrastructure that can be developed, assisted, or optimized using the AI toolkits. This includes determining the type of AI models that can be created, such as machine learning, large language model, decision optimization, rule-based systems, expert systems, or knowledge representation and reasoning. The supporting infrastructure includes data acquisition, annotation, and AI model optimization or monitoring.

    &#x20;
2.  2\.

    Define the deployment options for the AI models developed using the toolkits. This includes identifying the deployment options available, such as Web, mobile, virtual machines, or bare-metal servers.

    &#x20;
3.  3\.

    Define the input and output of the AI toolkits. This includes identifying the data types and inputs the toolkits can handle and the outputs they can produce.

    &#x20;
4.  4\.

    Understand in-house development challenge. Understand the developer’s challenge if they instead build their own AI tools in-house.

    &#x20;
5.  5\.

    Define the potential cost- and time-saving benefits of using the AI toolkits.

    &#x20;
6.  6\.

    Define how the AI toolkits support trustworthiness aspects such as robustness, fairness, and explainability.

    &#x20;
7.  7\.

    Define the scope of the development workflow covered by the AI toolkits. This includes identifying which stages of the development process are supported and which are not.

    &#x20;
8.  8\.

    Explain how to monitor the performance and cost of the models developed using the toolkits. This includes identifying the metrics that will be used and the minimum acceptable performance.

    &#x20;
9.  9\.

    Define the compatibility of the AI model builder to common tech stacks, including deep learning libraries and hardware providers.

    &#x20;

Output:

Once all of these steps have been completed, the result is the development design experience canvas for AI toolkits (Figure [7-4](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig4)), which summarizes all of the key points and provides a clear and concise overview of the AI toolkit ideation components and how developers can use them.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig4_HTML.jpg" alt="" height="836" width="1418"><figcaption><p>Figure 7-4 </p></figcaption></figure>

#### 4. Prototype

In the Prototype phase of design thinking for AI products targeted to developers, the development team conducts brainstorming sessions to develop a prototype of the AI product. This team typically includes the product manager, front-end engineer, back-end engineer, machine learning engineer, and data engineer. The prototype is based on the product hypothesis, developer persona, developer journey map, and developer experience canvas previously gathered during the Ideate phase. In terms of creating the prototype, there are two different methods for creating prototypes for AI as a Service (AIaaS) and AI as an Engine (AIaaE) and AI toolkits.

For AIaaS and AIaaE, the team creates a user interface (UI) design for API endpoints, command-line interfaces (CLI), or Software Development Kits (SDKs) that package the AI models developed by AI experts. These AI models can include large language models, computer vision deep learning models, decision optimization models, and more. The prototype must take into account several key considerations.

Step:

1.  1\.

    Before the user interaction, the development team should focus on providing easy-to-understand documentation and instructions for the AI product prototype. This includes clear explanations of the API endpoints, CLI, or SDK and any parameters or hyperparameters that can be configured. It should also include instructions on how to set up the developer sandbox and any prerequisites that need to be met before using the prototype.

    &#x20;
2.  2\.

    During the user interaction, the development team should focus on creating an intuitive API and SDK for the developer sandbox. This includes designing error-handling mechanisms and notifications to make it easy for developers to understand and diagnose any issues that may arise. The team should also consider what parameters and hyperparameters can be configured and how they can be accessed and modified within the developer sandbox.

    &#x20;
3.  3\.

    After the user interaction, the development team should focus on providing developers with the tools and information they need to monitor and explain the results of the AI models. This includes metrics, performance monitoring capabilities, and fairness and explainability mechanisms. The team should also consider how the AI models can be integrated with other applications and how implicit and explicit feedback, including active learning mechanisms, can be implemented as part of the prototype.

    &#x20;

In addition to these, for AI toolkits, the team should focus on providing an intuitive GUI or CLI for building and optimizing AI models, data operations, or operational infrastructure. The team should also consider how the results of the AI toolkits can be deployed and integrated into existing development workflows and how compatibility with common technology stacks can be ensured. The team should also provide tools for monitoring and calculating the benefits of using the AI toolkits instead of in-house development, such as cost and time savings.

Output:

A working prototype of the AI product, including the API or SDK and any necessary documentation, that can be accessed or open-sourced for developers to test and experiment with.

#### 5. Test

The testing phase in _design thinking_ is when the prototype is put in the hands of real users to gather feedback and validate the solutions developed during the previous phases of _Empathize_, _Define_, and _Ideate_. This phase is crucial in AI product development targeted to developer users because it allows the development team to understand how their solutions perform in a real-world context and identify any pain points or areas for improvement.

For AIaaS (AI as a Service) and AIaaE (AI as an Engine) products, the Test phase can involve deploying the API or SDK to a small group of developer users and gathering feedback on the ease of use, performance, and accuracy of the AI model. This can include evaluating metrics such as response time, error rate, and user satisfaction. It can also involve gathering feedback on the documentation, developer portal, and other developer-facing aspects of the product.

For AI toolkits, the testing phase can involve providing developer users with access to the toolkit and gathering feedback on its usability, functionality, and overall effectiveness. This can include evaluating metrics such as user engagement, task completion time, and user satisfaction. Additionally, it can also include gathering feedback on the documentation, tutorials, and other developer-facing aspects of the product.

It is important to note that during the testing phase, the team should also validate their assumptions about the users and the problem they are trying to solve. This can be done by observing the users during testing, conducting user interviews, and analyzing the feedback data.

The steps for design thinking’s Test phase in the developer experience (DX) process for AIaaS/AIaaE and AI toolkits are as follows.

Steps:

1.  1\.

    The first step in the testing phase is to provide the developers with a playground or sandbox to access the prototype’s user interface. This allows them to understand how AI works and how it can be used in their development projects. Their behavior and feedback are helpful for us to improve our AI products.

    &#x20;
2.  2\.

    Next, developers can test and interact with the AI product. The products are tested in three phases (before, during, and after interaction with the product).

    For AIaaS/AIaaE, the components are as follows:

    * Before the user interaction
      * _Documentation_: Before using the API/SDK, developers should have access to clear and comprehensive documentation that includes examples of how to use the API/SDK. This can help ensure that developers understand the API/SDK’s capabilities and how to use it effectively. OpenAI API is renowned for its excellent and well-structured developer documentation, which has been widely recognized and appreciated.
      * _Dashboard_: The usage dashboard can provide developers with insight into how the API/SDK is being used, such as the number of hits, billing information, and credit top-ups. This can help developers better understand the usage of the API/SDK and make informed decisions about how to use it.
      * _Usability_: The user interface and overall developer experience of the API/SDK should be intuitive and easy to navigate. This can help developers quickly and easily find the information they need to use the API/SDK effectively.
    * During the user interaction
      * _Functionality_: The API/SDK should work as intended and meet the minimum acceptable performance requirements. Developers should be able to use the API/SDK to accomplish the tasks they need to complete.
      * _Performance_: The API/SDK’s response time and scalability should be satisfactory. Developers should not have to wait long for responses, and the API/SDK should be able to handle many requests.
      * _Errors_: Human and system errors should be handled gracefully. Human errors should be notified and automatically corrected, and system errors should be notified.
      * _Transparency_: The API response should be based on an AI algorithm, and the response should be well explained. Also, uncertainty and confidence levels should be explained.
      * _Integration_: The API/SDK should be easy to integrate with other applications using mechanisms such as WebSockets and webhooks.
      * _Flexibility_: Developers should be able to change certain parameters or configurations of the API/SDK, such as input-output, threshold, hyperparameters, model, and evaluation metrics.
      * _Deployment_: The API/SDK should be easy to deploy to various platforms, such as the Web, Android, and ARM.
    * After the user interaction
      * _Monitoring_: The API/SDK’s performance, such as accuracy and latency, should be monitorable.
      * _Update feedback_: The API/SDK should ask for feedback clearly, and this feedback should be used to improve the API/SDK’s performance. Feedback should be actionable, and any updates to the model should be communicated clearly.

    For AI toolkits, the components are as follows:

    * Before user interaction
      * _Functionality testing_: This tests that the AI toolkit includes all the features and capabilities developers expect.
      * _Compatibility testing_: This tests that the AI toolkit is compatible with the developer’s existing development environment and tools.
      * _Documentation testing_: This tests the quality and clarity of the documentation provided to developers to ensure that it is easily understood and provides clear instructions for using the toolkit.
    * During user interaction
      * _Usability testing_: This tests how intuitive and easy the GUI of the AI toolkit is to empower the developers in building AI systems.
      * _Integration testing_: This tests how well the AI toolkit integrates with other systems and applications that the developer is using.
      * _Performance testing_: This measures how well the AI toolkit performs regarding response time and scalability to ensure it can handle the expected volume of usage.
      * _Debugging and troubleshooting_: This allows developers to debug and troubleshoot issues that may arise using the AI toolkit.
    * After user interaction
      * _User feedback testing_: Measures developers’ satisfaction with the AI toolkit and what areas can be improved.
      * _Maintenance testing_: This tests the AI toolkit’s ability to be maintained and updated overtime to ensure that it continues to meet the needs of the developer audience.
      * _Bug reporting and tracking_: This allows developers to report issues they encounter while using the AI toolkit and track the progress of these issues as the development team addresses them.

    &#x20;
3.  3\.

    Finally, the development and business teams must assess the technical feasibility of these AI products in a real-world setting. This includes evaluating user satisfaction, the team’s capabilities, the technology and infrastructure required, and the cost of building and operating the AI product. The final goal is to determine whether the AI product is commercially viable.

    &#x20;

Output:

For AIaaS/AIaaE, the output of this test process should be a scorecard of the API/SDK’s testing performance. The scorecard can be used to make improvements to the API/SDK and to ensure that it continues to meet the needs of developers. The scorecard of the AIaaS/AIaaE is depicted in the AI testing canvas (Figure [7-5](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig5)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig5_HTML.jpg" alt="" height="699" width="1418"><figcaption><p>Figure 7-5 </p></figcaption></figure>

Likewise, for the AI toolkit, the output is the scorecard of AI toolkit testing performance, which is depicted in the AI testing canvas (Figure [7-6](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig6)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig6_HTML.jpg" alt="" height="698" width="1418"><figcaption><p>Figure 7-6 </p></figcaption></figure>

It is also important to note that this is a cyclical process. Testing should be done repeatedly to make sure that the AI product is continuously improving. To improve the developer’s experience, the AI product should be tested by different groups of developers and in different use cases. This can help identify potential issues that may not have been discovered during initial testing.

CASE STUDY 1 (AI AS A SERVICE): DEVELOPER EXPERIENCE DESIGN FOR IDENTITY VERIFICATION

Identifax is an identity verification AIaaS company founded by Barbara, a former bank risk manager, and Nguyen, an accomplished computer vision engineer with experience in developing biometrics systems. Barbara and Nguyen met while working at a large bank, where Barbara was a risk manager responsible for implementing robust identity verification systems and Nguyen was developing eKYC software.

They quickly realized a gap in the market for an easy-to-use and reliable eKYC (electronic know-your-customer) identity verification system (Figure [7-7](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig7)). They decided to leave the bank to start their own company, Identifax.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig7_HTML.jpg" alt="" height="879" width="779"><figcaption><p>Figure 7-7 </p></figcaption></figure>

The company aimed to create an eKYC identity verification AI as a Service (AIaaS) for developers to build identity verification features for their mobile and web applications.

1.  1\.

    _Empathize_: The first step in the development process was the Empathize phase, where Barbara and Nguyen researched their potential customers’ needs and hypothesized. They interviewed developers and businesses in various industries to learn about the challenges they faced when implementing identity verification in their products. They also reviewed the existing identity verification solutions on the market and identified gaps in functionality and usability. The output of this phase is the table and hypothesis in the following (Table [7-4](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Tab4)).

    &#x20;

Table 7-4&#x20;

Developer Persona of eKYC AIaaS

| **Developer user**         | Back-end developer                                                             |
| -------------------------- | ------------------------------------------------------------------------------ |
| **Applications developed** | Mobile banking, loan application, insurance claim                              |
| **Cognitive tasks**        | Matching faces, checking face liveness, character recognitionfrom ID           |
| **Metrics**                | Face matching accuracy, liveness detection accuracy, OCR accuracy              |
| **Business values**        | Increased new user onboarding, reduced personnel cost, reduced onboarding time |

The Identifax team then creates the preliminary hypothesis as follows:

We believe that the _**back-end engineers**_ who develop _**mobile banking or FinTech applications**_ will benefit from integrating the application with our _**AI as a Service**_ to automate some _**face and ID matching**_ to attain optimal face matching accuracy and OCR detection accuracy, which increases _**the number of users onboarded, reduces the number of personnel, and decreases new customer time to onboard**_.

1.  2._Define_: The developer persona is detailed further in the second phase, and the developer experience journey is mapped. The Identifax team analyzes the developer user and comes up with a more specific developer persona hypothesis on the following:

    * _Developer user_: The developers using Identifax are mostly back-end or mobile application engineers looking for easy-to-use API and SDK of face matching and OCR solutions.
    * _Applications developed_: Most are developing banking or financial technology applications, where identity verification of the new users is crucial.
    * _Demographics_: Most of the developers targeted by Identifax are male, with an undergraduate degree in a technical subject such as computer science, engineering, and physics. The average age is below 30 years old, and as banking and fintech industries are high-risk industries, the applications are developed mainly by senior back-end developers with experience of more than five years.
    * _Technical skills_: The back-end engineers are primarily experts in back-end webs such as server-side programming, database, RESTful API, containerization technology such as Docker, and cloud platforms such as Amazon Web Services, Microsoft Azure, and Google Cloud.
    * _Pain points_: The pain points of back-end engineers developing AI for identity verification are handling large amounts of facial and identity data, developing and deploying complex machine learning models based on the data, scaling their models to meet demand, maintaining and updating models, and understanding complex biometrics-related machine learning algorithms.
    * _Metrics_: The metrics of the back-end engineers developing banking and FinTech solutions are the development cost, the latency, and the accuracy of identity verification machine learning models.

    The next thing is that the Identifax team brainstorms to ensure a smooth journey for the developer using their product and the different stages a developer would go through when integrating the identity verification AIaaS into their workflow:

    1.  1\.

        _Signup_: The developers realize that they need the identity verification module when the product managers having discussions with the business development managers and risk managers are given the requirements to onboard the new users as seamlessly and safely as possible. The developers realize that developing their identity verification machine learning model is complex, costly, and time-consuming. Therefore, they start to search for ready-made APIs and SDKs. After searching around, they find the Identifax landing page, explaining the benefits, use cases, and USPs of Identifax AIaaS that can be accessed through API and SDK. The important principle of this step is that the CTA (call to action) must be obvious and direct: to click the free trial button to enable the developer to access the developer sandbox.

        &#x20;
    2.  2\.

        _Learning_: In this phase, the developers are tasked with familiarizing themselves with the API and SDK documentation, including sample programs written in various programming languages such as Java, Python, and JavaScript. This step is crucial as it allows developers to understand how to effectively access and utilize the API and SDK to achieve their desired outcomes. By studying and comprehending the documentation and sample programs, developers can gain the necessary knowledge to integrate the API and SDK into their projects effectively.

        &#x20;
    3.  3\.

        _Trial_: In this step, the developers are trying out some API sandbox to try API requests and get responses accordingly on some real images. The available APIs are _face matching_ with an enrolled face on the database, facial liveness detection, and ID recognition.

        &#x20;
    4.  4\.

        _Integration_: After the developer tinkers with the APIs and tries some requests, adjusting some parameters (i.e., thresholds) and getting responses, they can integrate the APIs with their own applications.

        &#x20;
    5.  5\.

        _Operationalization_: The developer can monitor the API’s usage and performance.

        &#x20;

    The Identifax team creates a developer persona canvas and journey map based on the brainstorming sessions and findings.

    &#x20;
2.  3._Ideate_: In this stage, the Identifax team brainstorms and elaborates on the technicality of the developer experience aspects of eKYC services, such as the AI algorithms, deployment, and application type.

    1.  a._Identify applications_: The Identifax team lists the applications needing AI-based eKYC solutions:

        1.  i.

            _Banking and financial services_: Account opening, loan applications, and other financial transactions

            &#x20;
        2.  ii.

            _Telecommunication_: SIM card activation, customer onboarding

            &#x20;
        3.  iii.

            _Government services_: ID card issuance, voter registration, tax compliance

            &#x20;
        4.  iv.

            _Healthcare_: Patient onboarding, verification of insurance coverage

            &#x20;
        5.  v.

            _Ecommerce_: Customer onboarding, fraud prevention, age verification

            &#x20;

        &#x20;
    2.  b.

        _Determine deployment_: The API and SDK of AI-based eKYC can be deployed on the Web and mobile (Android and iOS). Hence, the team must prepare mobile SDKs for face liveness and ID OCR as boilerplate codes for various platforms such as iOS and Android. The mobile SDKs are useful for integrating the API with mobile applications. The main interaction with the FinTech and banking application users is mostly through a smartphone. The developer can integrate active liveness mechanism available as a mobile SDK, for example, asking the users to blink, hold still, or shake their head for ID verification in mobile applications to make sure the users are not spoofing the system using printed face or mask (Figure [7-8](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig8)).

        &#x20;
    3.  c.

        _Define input-output_: The API input is the image of the user’s face, and the input of the SDK is the video of the user taken with various poses. The output is that the face is matched or not matched with the liveness score. A low score (0–5) means the face is probably a spoof. A high score (>8) means the face is more likely an actual living person. This score can be adjusted accordingly by users.

        &#x20;
    4.  d._Understand in-house development challenge_: Some of the challenges of developing AI-based eKYC in-house are as follows:

        1.  i.

            Building AI models based on computer vision, especially related to facial liveness detection and ID recognition, is challenging and needs lots of research and development.

            &#x20;
        2.  ii.

            Data availability to train and validate computer vision models needs large amounts of high-quality labeled data. Acquiring and preparing such data can be a significant challenge.

            &#x20;
        3.  iii.

            Training AI models requires a significant amount of computational power.

            &#x20;
        4.  iv.

            AI models such as eKYC require ongoing maintenance and updates to remain effective. The company must possess MLOps tools and capabilities.

            &#x20;

        &#x20;
    5.  e._Define AI type_: There are three main AI models for eKYC. The Identifax AI team brainstorms the AI type used as follows:

        1.  i.

            _Face matching_: Deep neural network such as the Siamese network

            &#x20;
        2.  ii.

            _Liveness detection_: An ensemble of several deep neural network models, such as the _Siamese network_ and sequential CNN (_convolutional neural network_)

            &#x20;
        3.  iii.

            ID OCR: A combination of deep neural network models such as CNN and ViT (_Vision Transformer_)

            &#x20;

        &#x20;
    6.  f.

        _Define performance monitoring_: Performance monitoring regularly assesses machine learning models’ accuracy and reliability to ensure they meet a minimum acceptable performance level. The minimum acceptable performance for the face matching model would be high accuracy in matching faces to the correct individual. For face liveness detection, the minimum acceptable performance would be accurately identifying whether the detected face is real or fake to prevent fraud or unauthorized access. For the ID OCR model, the minimum acceptable performance would be a high level of accuracy in reading and interpreting text on identification documents, to prevent errors or fraud in the verification process.

        &#x20;
    7.  g.

        _Define version update_: Version update in the context of machine learning models for face matching, face liveness detection, and ID OCR involves updating the models with new data or improved algorithms to enhance their accuracy and performance (fine-tuning). The frequency of updates will depend on the availability of new data and the evolving needs of the application. The updated version of the models should be made available to the developers and users, with clear documentation of the changes made and their potential impact on the performance of the models. This will help developers stay informed of the updates and make any necessary adjustments to their application, thereby avoiding any violations of Hyrum’s law, which is a phenomenon that occurs when an implementation relies on assumptions that are not explicitly guaranteed by the interface specification. For face matching, the model may require updates when there are changes in the subject’s appearance due to aging or trend changes in hairstyle or trends in accessories like glasses or masks (e.g., during a pandemic). For face liveness detection, updates may be required when new types of spoofing attacks are identified or when changes in the system’s hardware or software components affect the detection performance. The frequency of updates may depend on the rate of false positives or false negatives and the rate of change in the input data. For ID OCR, the frequency of updates may depend on the quality and diversity of the input data, the required accuracy, and the rate of change in the input data. The ideal time for updates may be determined by the rate of error in recognizing characters or words or the frequency of changes in the ID formats used. Generally, updates should be performed regularly to ensure the model remains accurate and reliable over time.

        &#x20;
    8.  h.

        _Define_ _parameter optimization_: Some parameters that developers can optimize and adjust during inference time for various machine learning models include threshold values, input image size, and confidence scores. For a face matching machine learning model, developers can adjust the threshold value, which determines the minimum level of similarity required to classify two faces as a match. Depending on the use case, this parameter can be adjusted to increase the model’s sensitivity or specificity. In addition, developers can adjust the input image size to optimize performance and reduce computational requirements. For a liveness detection machine learning model, developers can adjust the confidence score, which determines the minimum level of certainty required to classify a face as a live detection. This parameter can be adjusted to increase or decrease the sensitivity of the model. Additionally, developers can adjust the input image size and the number of frames required for liveness detection. For an ID document OCR machine learning model, developers can adjust the input image size to optimize performance and reduce computational requirements. They can also adjust the confidence score, which determines the minimum level of certainty required to classify a particular character or word. Additionally, developers can adjust the language and font settings to improve accuracy and reduce errors.

        &#x20;
    9.  i.

        _Define_ _workflow optimization_: The eKYC machine learning models such as face matching, liveness detection, and OCR of ID documents are integrated into the user verification process of an application in industries such as banking, finance, and ecommerce. These models automate the tasks of comparing the face in the photo to the face on the ID document, verifying the user’s physical presence, and extracting relevant information from the ID document. This automation allows for a more efficient and secure user verification process, reducing the risk of fraud and improving the user experience.

        &#x20;
    10. j.

        _Define feedback_: The implicit and explicit feedback for eKYC AI as a Service, such as face matching, liveness detection, and ID OCR, are critical for improving the accuracy and reliability of the models. _Self-supervised learning_ can be integrated with the implicit feedback mechanism to train the machine learning models using unlabeled data, while _active learning_ can be integrated with the explicit feedback mechanism to improve the machine learning models using user feedback to identify errors and train the models with new data. For example, in face matching, implicit feedback comes from the similarity between faces, and explicit feedback comes from user input on the accuracy of the match. At the same time, _self-supervised learning_ can be used to train the model on unlabeled data, and _active learning_ can be used to improve the model using user feedback. For liveness detection, implicit feedback comes from the data characteristics of the images presented to the model, and explicit feedback comes from user input on the success of the verification process. For ID OCR, implicit feedback comes from the consistency and similarity of the characters recognized by the model. In contrast, explicit feedback comes from user input on the accuracy of the OCR result. In both cases, _self-supervised learning_ can be used to train the model on unlabeled data, and _active learning_ can be used to improve the model using user feedback.

        &#x20;
    11. k._Define risks and errors_: eKYC AI services, such as face matching, liveness detection, and OCR ID, carry inherent risks and errors that can arise in their use. Here are some examples:

        1.  i.

            _Face matching_: One risk is that the model can produce false positives or false negatives, meaning that it can incorrectly identify a person as a match or not identify a person who is a match. Errors can arise due to poor image quality, lighting or pose changes, and facial feature variations.

            &#x20;
        2.  ii.

            _Liveness detection_: One risk is that the model can be fooled by fraudsters who use advanced techniques to mimic live person behavior, such as using high-quality videos or 3D masks. Errors can arise due to poor image quality, background noise, and variations in facial expressions.

            &#x20;
        3.  iii.

            _ID OCR_: One risk is that the model can produce incorrect or incomplete results, meaning it can misread or miss parts of the ID document. Errors can arise due to variations in text and font, poor image quality, and background noise.

            &#x20;

        &#x20;

    These risks and errors can have serious consequences, such as identity theft or fraud, if not managed carefully. It is important to continuously monitor and evaluate the eKYC AI services’ performance to mitigate these risks and provide feedback and corrections when errors occur. It is also important to use secure and reliable systems to ensure that personal data is protected and used only for its intended purpose. Finally, it is important to establish clear policies and guidelines for using eKYC AI services to ensure they are used responsibly and ethically.

    &#x20;
3.  4._Prototype_: In this stage, the development team of Identifax conducts a brainstorming session to develop the prototype of the eKYC AIaaS:

    1.  a.

        _Before the user interaction_: The development team focuses on providing easy-to-understand documentation and instructions before any interaction. They want to ensure their product is accessible to a wide range of developers, with clear explanations of the API endpoints, CLI, or SDK and any configurable parameters or hyperparameters. They also provide instructions on how to set up the developer sandbox and any prerequisites that must be met before using the prototype.

        &#x20;
    2.  b.

        _During the user interaction_: The team works hard to create an intuitive eKYC AIaaS API and SDK for the developer sandbox. They design error-handling mechanisms and notifications to make it easy for developers to understand and diagnose any issues that may arise. They consider what parameters and hyperparameters can be configured and how they can be accessed and modified within the developer sandbox. The team wants to create a product that is user-friendly and easy to work with.

        &#x20;
    3.  c.

        _After the user interaction_: The team shifts their focus to providing developers with the tools and information they need to monitor and explain the results of the eKYC AI models. They provide metrics, performance monitoring capabilities, and fairness and explainability mechanisms. The team also considers how the AI models can be integrated with other applications and how implicit and explicit feedback, including active learning mechanisms, can be implemented as part of the prototype. They work tirelessly to create a product that is not only functional but also ethical and responsible.

        &#x20;

    &#x20;
4.  5._Test_: After the eKYC AIaaS prototype was developed, the Identifax team decides to test it with a small number of developer users as API sandbox and mobile SDK. The goal is to gather feedback on the AI model’s ease of use, performance, and accuracy. To evaluate the product’s performance, they measure response time, error rate, and user satisfaction metrics:

    * Before the user interaction, the team provides clear and comprehensive documentation for the API/SDK, including examples of using it effectively. They also include a usage dashboard that allows developers to track the usage of the API/SDK and make informed decisions about how to use it. The user interface and overall developer experience of the API/SDK are designed to be intuitive and easy to navigate.
    * During the user interaction, the team focuses on ensuring that the API/SDK works as intended and meets the minimum acceptable performance requirements. They evaluate the functionality, response time, scalability, error handling, transparency, integration, flexibility, and deployment capabilities of the API/SDK for each AI model. They also ask for feedback on the performance of the API/SDK and make any necessary improvements to the model.
    * After the user interaction, the team monitors the API/SDK’s performance, such as accuracy and latency, and continues gathering developer feedback. They use this feedback to improve the product, such as updating the AI model and enhancing the user experience. The team also continues to ensure that the API/SDK is easy to deploy to various platforms and can be integrated with other applications using mechanisms such as WebSockets and webhooks.

    &#x20;

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig8_HTML.jpg" alt="" height="1075" width="1170"><figcaption><p>Figure 7-8 </p></figcaption></figure>

The team also considers how the AI models can be integrated with other applications and how implicit and explicit feedback, including active learning mechanisms, can be implemented as part of the prototype for each AI model.

Through this process, the Identifax team created a successful eKYC AIaaS MVP and, later, a fully commercial product with face matching, liveness detection, and ID OCR that met the needs of developers. The feedback they received allowed them to improve the product and make it more accessible to a broader range of users for each of the AI models. The team was proud of the hard work and dedication that went into creating the eKYC AIaaS product, and they looked forward to its continued success.

CASE STUDY 2 (AI TOOLKIT): DEVELOPER EXPERIENCE DESIGN FOR A NO-CODE COMPUTER VISION PLATFORM

Gunther and Franz were both driven by a passion for technology, and they shared a vision of a world where anyone could create powerful machine learning models. Gunther, a former sales VP at SAP GMBH, had a talent for identifying customer needs and bringing products to market. Franz, a computer vision consultant with PhD in computer science, was an expert in machine learning and had a knack for solving complex technical problems.

However, they also understood the challenges faced by businesses and developers who lacked the resources or technical expertise to build and deploy deep learning models for computer vision problems.

To address this issue, Gunther and Franz founded Visionix, a low-code computer vision AI tool that would make it easy for anyone to build and deploy powerful deep learning models. They used design thinking principles to identify the pain points of businesses and developers and create a solution to address their needs.

One of the key challenges that they identified was the complexity of building and deploying deep learning models. Many developers, even seasoned data scientists, lacked the skills and experience to build and train models effectively. Businesses often struggled to find the resources to hire data scientists and build their models. Gunther and Franz believed that by making deep learning more accessible and easier to use, they could empower businesses and developers to achieve their goals without requiring extensive technical expertise.

To solve this problem, they created a no-code platform with a drag-and-drop graphical user interface to simplify the data annotation and model training process (Figure [7-9](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Fig9)). The platform also included a suite of pre-trained models that users could use as starting points for their models, saving time and resources.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_7_Chapter/522265_1_En_7_Fig9_HTML.jpg" alt="" height="573" width="1418"><figcaption><p>Figure 7-9 </p></figcaption></figure>

One of the key advantages of Visionix was its ability to quickly deploy models in the cloud, on-premise, or on mobile devices. This allowed businesses and developers to deploy models in the best environment.

Underlying the platform was a powerful deep learning engine that provided users access to state-of-the-art computer vision models. The engine was built using the latest deep learning and computer vision research, ensuring that Visionix’s models were accurate and effective.

Overall, Gunther and Franz aimed to democratize deep learning and make it accessible to businesses and developers of all sizes. By creating a low-code platform that simplified the process of building and deploying deep learning models, they aimed to unlock the full potential of AI and empower businesses to achieve their goals in new and exciting ways.

The step-by-step of their design thinking process from ideation to validation is as follows:

1.  1\.

    _Empathize_: Gunther and Franz initiated the development process with the Empathize phase. They researched to comprehend the requirements of their potential customers and hypothesized the types of developers who would benefit from their product, Visionix. They interviewed developers and businesses from a wide range of industries to gain insights into the difficulties they faced when developing, deploying, and operating computer vision–based deep learning models in their products. Additionally, they scrutinized the current computer vision builder toolkits available in the market and identified inadequacies in functionality and usability. The outcome of this phase is the table and hypotheses mentioned in the following (Table [7-5](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_7\_Chapter.xhtml#Tab5)).

    &#x20;

Table 7-5&#x20;

Developer Persona of the No-Code Computer Vision Platform

| **Developer user**         | Data scientist, back-end developer                                                                                                               |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Applications developed** | Any applications that require computer vision models                                                                                             |
| **Cognitive tasks**        | Object detection, object recognition, object tracking                                                                                            |
| **Metrics**                | Accuracy, latency, model size                                                                                                                    |
| **Business values**        | Cost and time efficiency for developing and deploying computer vision models and improved accuracy and productivity for businesses that use them |

The Visionix team then creates the preliminary hypothesis as follows:

We believe that the _**data scientists and software engineers**_ who develop _**any applications that need computer vision models**_ will benefit from integrating the application with our _**AI toolkit**_ to automate some _**object detection, object recognition, and object tracking**_ to _**optimize the accuracy and latency of computer vision models,**_ which results in an _**increasingly shorter time for computer vision model development.**_

1.  2._Define_: The Visionix team details the developer persona and maps the experience journey in the second phase. They analyze the developer user and generate more specific hypotheses on the following developer persona:

    1.  a.

        _Developer users_: Visionix is used by data scientists or back-end engineers seeking an easy way to develop computer vision models quickly.

        &#x20;
    2.  b.

        _Applications_: The platform is used to develop applications for various use cases, such as image recognition for inventory management, ecommerce SKU analysis, or object detection for surveillance.

        &#x20;
    3.  c.

        _Demographics_: Users are typically under 30 years old; have a technical undergraduate or master’s degree in computer science, engineering, or physics; and are predominantly male or female.

        &#x20;
    4.  d.

        _Technical sk_ills: The data scientists using Visionix are experts in machine learning and have experience building and optimizing machine learning models using various machine learning frameworks.

        &#x20;
    5.  e.

        _Pain points_: Users face challenges managing large amounts of computer vision data, annotating and selecting data for model development, deploying complex models, scaling to meet demand, maintaining and updating models, and monitoring performance.

        &#x20;
    6.  f.

        _Metrics_: The primary metrics of interest are the time and development cost for annotating and building deep learning computer vision models.

        &#x20;

    User experience design is a crucial part of any successful software development process. The Visionix team is aware of this and is currently focused on brainstorming ways to ensure a smooth journey for developers using their product. The team has identified five key stages of the developer journey for the AI tool: signup, reading instruction, trial, development, and integration. Each stage is designed to make the experience as user-friendly, efficient, and intuitive as possible:

    1.  a.

        The signup stage is the first step in the journey and is critical to ensuring a positive user experience. The Visionix team is working hard to make the signup process as simple and secure as possible, with streamlined registration procedures to minimize potential roadblocks.

        &#x20;
    2.  b.

        The reading instruction stage is equally important. It provides developers with the necessary product documentation and instructions to understand the features and how to use the Visionix no-code computer vision platform. The team is carefully crafting these materials to ensure they are easy to understand and follow.

        &#x20;
    3.  c.

        The trial stage allows developers to test the Visionix platform in a free trial or sandbox environment to ensure it meets their needs and requirements. This stage is a critical part of the user experience, allowing developers to test the platform and provide feedback before committing to using it.

        &#x20;
    4.  d.

        The development stage begins the actual work, and the Visionix team is committed to making it as straightforward and efficient as possible. The no-code interface, combined with pre-built models and libraries, makes it easy for developers to create advanced no-code computer vision deep learning models easily.

        &#x20;
    5.  e.

        Finally, in the integration stage, the Visionix team is focused on providing flexible integration options, allowing developers to easily integrate their models into their existing development workflow and infrastructure.

        &#x20;

    &#x20;
2.  3._Ideate_: At this stage, the Visionix team is fully immersed in the technical intricacies of developing a low-code computer vision building tool that addresses the many challenges associated with creating, annotating, training, and deploying AI algorithms. To accomplish this goal, the team has identified several key technical aspects of the platform:

    1.  a.

        _Identifying AI models and supporting infrastructure_: The Visionix team has defined the platform’s focus as helping developers build basic computer vision models, such as object detection, classification, tracking, and object segmentation using various deep learning techniques.

        &#x20;
    2.  b.

        _Deployment options_: The Visionix platform can deploy computer vision models into the cloud using REST API and WebSocket or into any container, such as Docker and Kubernetes, enabling deep learning models to be deployed to any on-premise servers.

        &#x20;
    3.  c.

        _Input and output_: The Visionix platform takes image and video data as input and outputs insights, such as object location, number, and behavior.

        &#x20;
    4.  d.

        _In-house development challenges_: Developing computer vision models using deep learning is challenging because of the need to annotate images, mix and match different neural network architectural designs, experiment, optimize hyperparameters, and deploy the model, all coded and scripted in an unintuitive manner.

        &#x20;
    5.  e.

        _Cost- and time-saving benefits_: The cost of using the no-code computer vision platform is lower because fewer data scientists are needed and development time is shorter because the entire end-to-end process from annotating images to monitoring the model can be handled by one platform.

        &#x20;
    6.  f.

        _Trustworthiness_: The computer vision models produced by the Visionix platform can be explained through an image saliency mechanism.

        &#x20;
    7.  g.

        _Scope of development workflow_: The Visionix platform builds a black box for any application where insight generation and decision-making can be built on that black box.

        &#x20;
    8.  h.

        _Performance and cost monitoring_: The success metrics used are accuracy, size, and development time.

        &#x20;
    9.  i.

        _AI model builder compatibility_: This no-code deep learning computer vision platform supports machine learning libraries like TensorFlow and PyTorch and runs on Nvidia and Intel OpenVINO.

        &#x20;
    10. j.

        The Visionix team is dedicated to providing developers with a powerful, easy-to-use, cost-effective low-code computer vision building tool that overcomes the technical challenges of building advanced computer vision models. With the capabilities of the Visionix platform, developers can focus on the creative aspects of computer vision model development while the platform handles the technical intricacies.

        &#x20;

    &#x20;
3.  4._Prototype_: The development team of Visionix has embarked on a new project to create a low-code computer vision platform. The team began brainstorming and outlining the project’s objectives, features, and technical requirements. The team prioritized ensuring their product would be user-friendly and accessible to a wide range of developers:

    1.  a.

        Before the interaction stage, they focused on developing easy-to-understand documentation and instructions to clearly explain the graphical user interface, API endpoints, and command-line interface. The team also provided instructions on using the drag-and-drop GUI and any prerequisites to be met before using the prototype to annotate and build computer vision models.

        &#x20;
    2.  b.

        During the interaction stage, the team focused on creating an intuitive drag-and-drop GUI that allows developers to quickly annotate, mix and match deep learning models, and modify preprocessing algorithms such as data augmentation. They designed error-handling mechanisms and notifications to help developers understand and diagnose any issues that may arise. The team also considered the types of experimentations that model developers can analyze to create a product that is user-friendly and easy to work with.

        &#x20;
    3.  c.

        After the interaction stage, the team shifted their focus to providing developers with comprehensive auditing and monitoring tools built into the Visionix platform. These tools enable proactive application performance management and make detecting issues in real time easier. Visionix provides dashboard tools to monitor events and metrics in the cloud. At the same time, its automated infrastructure and no-code capabilities enable the implementation of a responsive and fast computer vision development, update, and upkeep strategy. The platform also includes powerful diagnosis tools, system alerts, and automated health checks, enabling developers to detect issues early. When problems are identified, Visionix provides integrated tools for remote troubleshooting, fast rollbacks, and disaster recovery.

        &#x20;

    &#x20;
4.  5._Test_: After developing the Visionix no-code computer vision prototype, the development team wanted to test it with a few developer users as a web application that could be accessed from anywhere. The main goal of the testing was to gather feedback from the developers about the ease of use and performance of the low-code computer vision platform. To evaluate the prototype, the team measured metrics such as time to annotate images and train, validate, and deploy computer vision models and how easy the Visionix platform was to use. The Visionix team analyzed the testing results in three stages: before, during, and after the developers’ interaction with the Visionix platform.

    1.  a.

        Before the user interaction stage, the development team conducted functionality testing to ensure that Visionix includes all the features and capabilities developers expect. They also tested compatibility to ensure that the Visionix platform is compatible with the developer’s existing development environment and tools. Finally, the team conducted documentation testing to ensure that the documentation provided to developers is easily understood and provides clear instructions for using the no-code computer vision platform.

        &#x20;
    2.  b.

        During the user interaction, the team conducted usability testing to measure how intuitive and easy to use the GUI of the Visionix no-code platform is for developers to build AI systems. They also tested integration to measure how well Visionix integrates with other developers’ development libraries and infrastructures. In addition, the team conducted performance testing to measure how well the Visionix platform performs in terms of response time and scalability to ensure that it can handle the expected volume of usage. The team also tested the debugging and troubleshooting mechanisms of the platform.

        &#x20;
    3.  c.

        After the user interaction, the team tested user feedback to measure developers’ satisfaction with Visionix and what areas could be improved. They also conducted maintenance testing to measure the capability of Visionix models to be maintained and updated overtime, ensuring that it continues to meet the needs of developers. Finally, the team conducted bug reporting and tracking testing that enables developers to report issues they encounter while using Visionix and track the progress of these issues as the development team addresses them.

        &#x20;

    &#x20;

Through this process, the Visionix team created a successful no-code computer vision tool that met the needs of developers. The feedback from developers enabled the team to improve the product and ensure that it is a user-friendly, high-performance platform easily integrated with other development libraries and infrastructures.

### Conclusion

This chapter teaches how AI developer experience (DX) design can help examine the creation of AI-based products and services while providing a framework for incorporating AI into applications. Using the design thinking principle, focusing on developers’ needs and preferences helps create user-friendly high-quality AI products that meet their requirements. The feedback from users enables teams to improve existing products and ensure they meet end user expectations. Two case studies of AI as a Service and AI toolkits are presented.

### Key Takeaways

* The developer experience for AI services can differ depending on the specific service or toolkit and the intended use case.
* AI services can be provided in various ways such as AIaaS, AI toolkits, AIaaE, and AI PaaS, which can be delivered through different methods, including API, SDK, CLI, operating systems, containers, VMs, or GUI. These services aim to provide developers with an easy and flexible way to access advanced AI capabilities without worrying about the underlying infrastructure.
* By providing developers with easy-to-use and flexible tools, companies can help bridge the gap between cutting-edge AI research and real-world implementation, making it possible for developers of all skill levels to create innovative and intelligent applications.
* When designing the developer experience for AI products, key principles should be considered, such as ease of use and integration, flexibility and control, and comprehensive tools and capabilities.
* Good documentation and support, monitoring and visibility, scalability and maintenance, collaboration and community, trustworthiness, fairness, and feedback are essential components that should be included in the developer experience.
* The developer experience for AI products should aim to provide developers with tools that allow them to understand how the AI models work, identify and mitigate biases, measure the performance of the models, and improve them overtime.
* Design thinking is important for designing a developer experience (DX) process, as it allows the team to understand developers’ needs and pain points and create solutions tailored to their specific needs.
* The _Empathize_ phase is the first step in building an AI product developer experience using design thinking. This phase involves hypothesizing about the types of developers using the product, defining data-gathering methods, and gathering information about the developer persona, problems, and pain points. The output of this phase is an understanding of the benefits of AI tools or services for the target audience, including the developers’ specific needs and pain points.
* The _Define_ phase of design thinking for a developer product focuses on detailing the developer persona, mapping the developer journey, and understanding the target audience’s tasks and mental models. The output of this phase is a developer persona canvas, a developer journey map, and an AI toolkit product, which helps developers understand how to build and integrate AI models into their applications while identifying pain points and opportunities for improvement.
* The _Ideate_ phase for AI products targeted toward developers involves different steps and outputs for AIaaS, AIaaE, and AI toolkits. Understanding each product’s target user and usage is crucial for identifying potential use cases and designing a successful developer experience (DX). For AIaaS/AIaaE, the output of this phase is a canvas with the input/output of the model and its potential use cases. For AI toolkits, the output of this phase is a document detailing the different AI models that can be developed using the toolkit and the workflows and use cases it supports.
* In the _Prototype_ phase, the development team creates a user-friendly design for the AI product’s interface, with clear documentation and error-handling features. They also develop tools for monitoring and measuring the product’s benefits. The output of this phase is a functioning prototype, including the GUI, API or SDK, and necessary documentation, which developers can test and use. The _Prototype_ phase is essential in the design thinking process for AI products targeted toward developers, where the development team creates a prototype based on the product hypothesis, developer persona, developer journey map, and developer experience canvas.
* The _Test_ phase is crucial in AI product development targeted to developer users. It allows the development team to understand how their solutions perform in a real-world context and identify areas for improvement. The _Test_ phase for AIaaS/AIaaE and AI toolkits involves different components, such as documentation, usability, functionality, and integration testing. It should be a cyclical process to ensure continuous improvement and to identify potential issues in different use cases.
