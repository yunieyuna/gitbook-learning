# 8. Building an AI Platform

As an AI startup, it is essential to have a clear strategy for designing, developing, and operating an AI platform that can meet market demands. In the previous chapters, we learned about validating AI products from various perspectives. This chapter will explore the details of building a successful AI platform that involves designing, developing, and operating the AI system. Building an AI platform is a complex process that requires careful consideration of many factors. We will explore the importance of the three pillars of AI platform design: system design, process design, and team design. We will provide a comprehensive framework that unifies these pillars into a single approach to building an effective AI platform. Measuring the maturity of an AI platform is also an essential aspect of the building process. We will discuss how to assess the platform at different stages, from initial development to optimized operation. This chapter will also discuss the challenges and best practices of building an AI platform. We will explore common issues and provide practical solutions to ensure success. To illustrate how the framework and best practices discussed in this chapter can be applied in practice, we will provide a case study of designing, developing, and operating an eKYC AI as a Service platform. This case study will provide real-world examples of the key considerations and decisions in building an effective AI platform. By the end of this chapter, you will have a comprehensive understanding of what it takes to build a successful AI platform and the steps involved in designing, developing, and operating such a system.

### Introduction

Artificial intelligence (AI) is increasingly being integrated into modern software platforms known as AI platforms. However, the development and deployment of an AI platform can be a complex and challenging task. To successfully build and deploy a scalable and robust AI platform, it is important to understand the cycle of how to architect, develop, and operationalize an AI software platform (Figure [8-1](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig1)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig1_HTML.jpg" alt="" height="814" width="884"><figcaption><p>Figure 8-1 </p></figcaption></figure>

Conway's law is one concept underpinning the AI platform's success. This law states that a system's design reflects the communication structures of the organization that builds it. In other words, the organizational structure and communication between teams as part of the overall process can significantly impact the design and effectiveness of the AI platform.

In designing the AI platform, other books and frameworks only focus on one pillar. However, this chapter presents a unified framework emphasizing the importance of the three pillars of AI platform design: system, process, and team design (Figure [8-2](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig2)). Each pillar has its unique set of requirements and characteristics that contribute to the overall success of the AI platform.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig2_HTML.jpg" alt="" height="828" width="945"><figcaption><p>Figure 8-2 </p></figcaption></figure>

System design focuses on the technical infrastructure required for the AI platform. For example, the data layer (data pipelines), experimentation layer (model training and testing), and deployment layer (model serving) must adhere to established systems engineering principles.[1](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn1) The principles ensure the optimal functioning of these elements, creating scalable, maintainable, and fault-tolerant AI platforms and facilitating cutting-edge AI solutions.

Process design emphasizes implementing proper AI model development and operationalization, which crystallized into ModelOps/MLOps practices, such as version control, automated testing, and continuous deployment.

Team design refers to the organizational structure, communication, and collaboration between the various teams building and operating the AI platform.

This chapter will explore each pillar in more detail and guide how to build and operate a scalable and robust AI platform. By understanding the importance of each pillar and the interconnection between them, we can design and deploy AI solutions that meet the highest standards of quality and reliability.

#### Key Components and Layers of an AI Software Platform

Building an AI platform presents significant challenges, given the complexities involved in creating a system that can handle large amounts of data and perform complex computations efficiently in a dynamic environment. Furthermore, AI systems must be capable of emulating human cognitive capabilities, which adds another layer of complexity to the development process.

Focusing on the three pillars of system, process, and team design is essential to address these challenges. This section will provide an overview of an AI software architecture's key components and layers, including the concepts of process and team topologies, which offer a unified approach to building a software platform.

These concepts will be explored in depth, giving you a deeper understanding of their importance and how they contribute to developing a robust AI platform. The ideal AI software platform must be designed to handle the complexities of large-scale data processing while remaining flexible, scalable, and secure. The process of building and operating an AI platform requires a deep understanding of the technology involved and the ability to navigate the complexities of building a system that can adapt to changing business needs and remain effective overtime, which consists of the team structure.

**AI Platform Design**

**Six Layers of the AI Platform**

An AI platform consists of a complex system of interconnected components working harmoniously to deliver AI-based solutions.

Understanding the AI platform architecture and its six layers is crucial for a successful AI platform because they represent a structured approach to building a complex system of interconnected components that work together to deliver AI-based solutions.

Each layer is designed to handle a specific platform aspect, from the underlying infrastructure required to support it to the tools and mechanisms necessary to deploy and manage AI models.

By breaking down the platform into these individual layers, AI teams can ensure that each component is developed and optimized for its specific purpose, resulting in a more efficient and effective platform overall. Additionally, the layering approach allows for easier maintenance and scaling of the platform as it grows and evolves. Overall, the six layers provide a framework for building a robust and scalable AI platform to deliver user value (Figure [8-3](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig3)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig3_HTML.jpg" alt="" height="931" width="1069"><figcaption><p>Figure 8-3 </p></figcaption></figure>

1.  1\.

    The first layer is the infrastructure layer, which includes the hardware and software components needed to support the platform, such as _compute_ and virtualization.

    &#x20;
2.  2\.

    The second layer is the data and integration layer, which deals with the acquisition, annotation, quality control, governance, storage, and integration of data from various sources.

    &#x20;
3.  3\.

    The third layer is the AI model experimentation layer, where the actual AI models are developed, tested, and optimized. This layer includes feature engineering, model development, model testing, model interpretability, and model management.

    &#x20;
4.  4\.

    The fourth layer, the operation and deployment layer, deals with the tools and mechanisms required to manage the containerized deployment of various models and other components across the platform. This layer also includes model monitoring and governance.

    &#x20;
5.  5\.

    The fifth layer is the intelligence inference layer, which runs the AI models in real time to provide insights, recommendations, and predictions based on defined logic and business rules. This layer includes an inference pipeline on runtimes, such as business process management and rules and logic management.

    &#x20;
6.  6\.

    Finally, the sixth layer is the experience layer, which provides a user-friendly interface for interacting with the AI platform, such as a GUI, API, or conversational user interface.

    &#x20;

By understanding the six layers of the AI platform architecture, developers can ensure that each layer is properly designed, optimized, and integrated to create a robust and scalable AI platform. This can help ensure that the platform can handle large volumes of data, perform complex computations efficiently, and provide valuable insights and recommendations to users. Additionally, a well-designed AI platform can provide a competitive advantage for organizations by improving decision-making, reducing costs, and increasing efficiency.

**MLOps/ModelOps**

MLOps (machine learning operations) is a set of practices and technologies used to build, deploy, and manage machine learning models in production.

Similarly, ModelOps is an approach that focuses on automating the development, deployment, and monitoring of all types of AI models, including machine learning, decision optimization, and symbolic logic models. MLOps and ModelOps aim to make the process of building and operating AI models more efficient, reliable, and scalable (Figure [8-4](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig4)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig4_HTML.jpg" alt="" height="465" width="1418"><figcaption><p>Figure 8-4 </p></figcaption></figure>

The components of MLOps and ModelOps include data operations (DataOps), such as data acquisition/ingestion, ETL (Extract, Transform, Load), and annotation, followed by model experiments where the feature engineering, model development, and testing are performed (TrainingOps).

Next, there is continuous integration/continuous delivery (CI/CD) of model deployment and serving (ServingOps), followed by model monitoring and governance (MonitorOps). The newest trend includes XAI (explainable AI) into the cycle (XAIOps). These components ensure that AI models are built and deployed correctly and can be updated and managed overtime.

MLOps and ModelOps are similar in that they both aim to automate and streamline the process of building and deploying AI models. However, ModelOps is a broader term encompassing all types of AI models, while MLOps focuses specifically on machine learning models. MLOps often involves more advanced techniques such as hyperparameter tuning, transfer learning, and model interpretability.

In this section, we will focus more on the MLOps process of building AI products because machine learning is currently one of the most popular methods used in AI development. For example, predictive analytics relies heavily on machine learning, while computer vision applications are often based on deep learning, a branch of machine learning.

Embracing MLOps is important because it helps ensure that AI models are built and deployed correctly, can be updated and managed overtime, and can provide reliable and scalable results. This is crucial for building high-quality AI products that can meet the needs of businesses and end users.

MLOps is interrelated with the six layers of AI platform architecture discussed earlier because the MLOps components are integral to building and deploying AI models within the framework of the six layers. The data and integration layer is responsible for data acquisition and annotation, which are key components of MLOps. The AI model experimentation layer encompasses the feature engineering, model development, and testing components of MLOps. The operation and deployment layer is responsible for model deployment and serving, which are critical components of CI/CD in MLOps. Finally, the intelligence inference layer and experience layer are where the AI models are used and experienced by end users, making them important for monitoring and governance of the models.

**LLM, VLP, and LLMOps**

Most advanced generative AI products such as GPT, CLIP and DALL-E[2](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn2) from OpenAI rely on machine learning methods, specifically a type of model known as transformers, which belong to the broader class of large language models (LLMs) and Vision-Language Pretraining (VLP). These models are characterized by their ability to process and generate human-like text as well as image, a significant advancement from traditional machine learning models.

Traditional machine learning models are often tailored for specific tasks, ranging from spam detection to image recognition. Their learning process is primarily based on identifying patterns in the training data, and they require explicit feature engineering where relevant features are manually selected and fed into the model. While these models have been successful in many applications, they often struggle with tasks that involve understanding and generating natural language due to the inherent complexity and ambiguity of human language.

LLMs are trained on vast amounts of text data, enabling them to generate coherent and contextually relevant text based on a given prompt. Models like GPT-4,[3](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn3) a well-known example of an LLM, are designed to predict the next word in a sequence, having been trained on a diverse range of Internet text. They can answer questions, write essays, summarize texts, translate languages, and even generate Python code. However, they primarily operate in the textual domain and lack the ability to interpret or generate visual content.

On the other hand, VLP models, like DALL-E and CLIP from OpenAI, are designed to understand both textual and visual data. These models are pretrained on a large corpus of paired image-text data, allowing them to generate images from textual descriptions, answer questions about images, and even provide textual descriptions of images. This cross-modal understanding significantly expands the capabilities of AI models, bridging the gap between visual and textual data.

The integration of LLMs and VLPs could potentially lead to even more robust AI models capable of understanding, interpreting, and generating information across both textual and visual domains, much like humans do. These multimodal models can have wide-ranging applications, from more interactive and capable virtual assistants to advanced content creation tools.

When it comes to operations, MLOps (machine learning operations) is the discipline of AI model development and operations. It aims to unify ML system development and ML system operation, intending to shorten the ML lifecycle and provide high-quality, reliable ML products.

However, with the rise of LLMs and VLPs, there's an increasing need for large language model operations (LLMOps) and Vision-Language Pretraining operations (VLPOps), respectively. These operations are specialized subsets of MLOps that focus on the unique requirements and challenges of deploying and maintaining LLMs and VLPs. This includes managing the vast computational resources these models need, handling the diverse and large-scale data required for training, and implementing measures to mitigate potential ethical and fairness issues these models might raise.

**Team Topologies**

_Conway's law_ states that the design of an organization's system will reflect the organization's communication structure. In other words, the organization's structure will impact the design of the system it creates. This is highly relevant to building AI platform architecture because it highlights the importance of team design in the overall architecture of the platform.

Team topologies is a concept that builds on _Conway's law_[4](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn4) and offers a framework for designing teams that can effectively build and operate modern software systems, including those with machine learning components. It is based on three main ideas:

1.  1\.

    _Simplify the team's cognitive load_: Teams should be designed to minimize the complexity of the system they work on, reducing the amount of cognitive overhead required to understand and work on the system.

    &#x20;
2.  2\.

    _Enable fast and safe changes_: Teams should be designed to allow for fast and safe changes to the system they work on, enabling the team to deliver value quickly and respond to changing requirements.

    &#x20;
3.  3\.

    _Build a foundation of effective communication_: Teams should be designed to promote effective communication and collaboration within the team and with other teams involved in the system.

    &#x20;

The team topologies framework emphasizes four types of team interactions: stream-aligned teams, platform teams, enabling teams, and complicated subsystem teams. These teams work together to create an architecture optimized for the organization's needs and the product being built.

Stream-aligned teams are responsible for the end-to-end delivery of a particular product or service. Platform teams provide foundational services that are leveraged across multiple stream-aligned teams. Enabling teams are responsible for supporting and improving the flow of work across all teams. Finally, complicated subsystem teams work on highly specialized areas of the system that require deep expertise.

Here’s an example for team topologies for a machine learning product such as _fraud analytics_:

* The _stream-aligned team_ for _fraud analytics_ includes the data acquisition team responsible for obtaining high-quality fraud data, data analysis team for identifying fraud patterns and anomalies, and fraud machine learning team for building and maintaining the machine learning models for various fraud patterns.
* The _platform team_ includes the infrastructure team responsible to build the data streaming acquisition, data transformation, data labeling, feature store, computing environment, and data storage and the MLOps team to develop MLOps components from model experiments to model serving.
* The _enabling team_ includes the data governance team for ensuring data protection regulations and the security team for platform security.
* The _complicated subsystem team_ includes the fraud explainability team and the machine learning model optimization team.

The team topologies concept defines three interaction modes for teams: collaboration, X as a Service, and facilitating. Collaboration involves teams working closely, while X as a Service involves consuming or providing something with minimal collaboration. Facilitating consists of helping (or being helped by) another team to clear impediments.

Here are some examples of how the fraud analytics team might use the three different interaction modes:

* _Collaboration_: The fraud data acquisition team and fraud data analysis team work collaboratively to ensure the data being collected is of high quality and analyzed effectively to identify patterns and anomalies. The fraud machine learning team and machine learning model optimization team work collaboratively to improve the machine learning models continuously.
* _X as a Service_: The infrastructure team provides a machine learning model serving infrastructure for the fraud machine learning team to deploy their models to production, with minimal collaboration required. The data governance team provides data policies and guidance on data ethics to the other teams as a service, with minimal collaboration required.
* _Facilitating_: The MLOps team facilitates the deployment of the machine learning models by helping the fraud machine learning team clear any impediments in the deployment pipeline. The security team facilitates the platform's security by providing guidance and support to the other teams to ensure the platform remains secure.

Team topologies is highly relevant to building and architecting a robust AI platform because it provides a structured approach to designing teams that can work effectively within modern AI systems' complex and dynamic environment. It helps ensure that teams are optimized for the specific requirements of the system they are building while promoting effective communication and collaboration between teams.

MLOps processes must embrace team topologies to effectively manage the complex interactions between teams and components within a machine learning system. By designing teams and communication structures that are optimized for the system's specific requirements, MLOps teams can effectively manage the entire process of building, deploying, and maintaining machine learning models.

An example of building a team for a machine learning product using team topologies might involve creating a cross-functional team that includes data scientists, software developers, and DevOps engineers. The team would be designed to minimize the cognitive load by focusing on specific tasks related to the machine learning component while also enabling fast and safe changes to the system through Agile methodologies and continuous integration/continuous delivery practices. The team would also be designed to facilitate effective communication and collaboration between team members and with other teams involved in the overall AI platform architecture.

**Unifying All**

To build a successful end-to-end AI platform, it is important to understand the six layers of AI platform architecture and the process of building and operating AI models, known as MLOps. The MLOps process consists of data operations such as data acquisition/ingestion, ETL, annotation, and model experiments, where feature engineering, model development, and testing are performed. This is followed by CI/CD of model deployment and serving. By integrating MLOps into the six layers of AI platform architecture (Figure [8-5](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig5)), organizations can ensure that the models are built and deployed consistently, with best practices for testing and monitoring.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig5_HTML.jpg" alt="" height="725" width="1418"><figcaption><p>Figure 8-5 </p></figcaption></figure>

Additionally, the importance of team structure in building and operating an AI platform cannot be overstated. Due to Conway’s law, I believe that team topologies lends itself well to building and operating AI platforms. Team topologies is a set of organizational patterns that aim to improve communication and collaboration between teams while enabling teams to work more effectively and efficiently. By incorporating team topologies into the MLOps process and the six layers of AI platform architecture, organizations can ensure that the teams are structured and operate effectively, with clear roles and responsibilities, communication processes, and feedback loops for continuous improvement.

It is important to note that all these elements must be integrated into a unified design, process, and teaming framework. By understanding and implementing this framework, organizations can build end-to-end AI platforms that are scalable, efficient, secure, and capable of delivering high-quality results. With a well-designed AI platform and a team that is structured and operates effectively, organizations can ensure that their AI models are built and deployed in a consistent and repeatable manner, with best practices for testing and monitoring, and that they meet the evolving needs of the organization overtime.

#### Challenges in Building an AI Platform

Building an AI platform comes with its challenges that must be overcome to ensure success. The first challenge is that training and inferencing AI is expensive. This is due to the need for powerful computing resources and specialized hardware, such as GPUs, to handle the vast amounts of data involved in AI training and inference. Additionally, maintaining these resources can be expensive, leading to higher overall costs.

The second challenge is that collecting data is complex and expensive. To train AI models, a significant amount of high-quality data is required. Collecting this data can be a complex and time-consuming process, and the cost of data acquisition can also be high.

The third challenge is that AI is inherently probabilistic, non-stationary, and non-deterministic. This means that AI models can be highly sensitive to changes in the input data and can produce different results depending on the data that is presented. This introduces a level of uncertainty into the AI system, making it difficult to rely on the results with absolute certainty.

The fourth challenge is that AI is an effort to replicate human thinking and operates in a dynamic environment where we cannot control the input. This means that AI systems must be able to handle unpredictable inputs and adapt to changes in the environment. We have edge cases, which are the situations where the model performs unexpectedly due to encountering data that falls outside the norm of what it was trained on. For example, a computer vision model may struggle to identify objects in images with low lighting, or a natural language processing model may struggle to accurately identify sentiment in reviews with unusual language or slang. Edge cases are important to consider and address as they can significantly impact the performance of machine learning models in the real world. Creating a reliable AI systems that can consistently produce accurate results is challenging.

The impact of these challenges is significant. The reliability of AI is still questionable, and there is a risk that models can decay overtime due to changes in the data or environment (Figure [8-6](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig6)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig6_HTML.jpg" alt="" height="597" width="1422"><figcaption><p>Figure 8-6 </p></figcaption></figure>

Edge cases, or situations that are outside the normal range of inputs (Figure [8-7](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig7)), can also be difficult for AI systems to handle. Additionally, the high cost of AI development and deployment can be a barrier for many organizations.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig7_HTML.jpg" alt="" height="744" width="1418"><figcaption><p>Figure 8-7 </p></figcaption></figure>

Careful attention must be paid to the system architecture, MLOps process, and team to overcome these challenges. System design should be optimized for performance, flexibility, interoperability, trustworthiness, and scalability. MLOps processes should be designed to ensure efficient and effective training and inferencing and robust data quality control and validation. Team design should be optimized for collaboration, flexibility, trustworthiness, and scalability.

In summary, building a successful AI platform requires careful consideration of the challenges involved and a well-designed approach to the system architecture, MLOps process, and team. By addressing these challenges and creating a solid foundation for AI development and deployment, organizations can overcome the barriers to success and create reliable, effective AI systems.

**Ideal AI Platform Design**

Despite the challenges described earlier, the ideal AI platform design must consider five factors for success: performance, flexibility, interoperability, trustworthiness, and scalability.

* Performance refers to the ability of the AI platform to handle large volumes of data and process it quickly and efficiently, delivering accurate and reliable results in real time or near real time. An example of this success factor for an AI platform would be the ability to process and analyze customer behavior data to make accurate real-time recommendations for personalized products or services.
* Flexibility involves the ability of the AI platform to adapt to changing business requirements and evolving technology trends, supporting multiple programming languages and frameworks and integrating with other systems and tools. An example of this success factor for an AI platform would be the ability to easily incorporate new data sources and change the AI models based on the new requirements.
* Interoperability refers to the ability of the AI platform to work seamlessly with other systems and tools, allowing for easy data sharing and collaboration. An example of this success factor for an AI platform would be the ability to integrate with third-party data sources and analytics tools.
* Trustworthiness involves designing the AI platform with reliability, security, and privacy in mind, ensuring robust data governance and compliance mechanisms, and providing tools and processes for monitoring and mitigating risk.
* Scalability involves the ability of the AI platform to scale up or down as needed to handle changing workloads, adding or removing computing resources and distributing workloads across multiple nodes or clusters. An example of this success factor for an AI platform would be the ability to quickly expand data processing capabilities to support a surge in customer demand during peak seasons.

The three pillars of the AI platform design, system design, process design, and team design, must adhere to these five success factors.

System design must be optimized for performance, flexibility, interoperability, trustworthiness, and scalability.

Process design must be optimized for efficiency, flexibility, trustworthiness, and scalability. And team design must be optimized for collaboration, flexibility, trustworthiness, and scalability.

For example, the identifai.id eKYC biometrics AI as a Service platform adheres to these success factors by utilizing a high-performance computing environment with distributed data storage and processing capabilities, allowing for real-time facial recognition and biometrics identification. The platform is flexible and scalable, allowing for integration with various data sources and analysis tools to enhance fraud detection and compliance monitoring capabilities. The platform is interoperable, seamlessly integrating with third-party verification systems and customer relationship management tools. The platform is trustworthy, implementing robust data governance and compliance mechanisms and providing clear roles and responsibilities for team members. The platform's team design fosters collaboration, flexibility, trust, and scalability, with cross-functional teams working together to improve the platform's capabilities and address customer needs continuously.

To summarize, the ideal AI platform design requires a combination of the five success factors – performance, flexibility, interoperability, trustworthiness, and scalability – across the three pillars of system design, process design, and team design. The success of an AI platform depends on its ability to optimize each of these factors, as exemplified by the identifai.id eKYC biometrics AI as a Service platform.

### Architecting an AI Platform

Building an AI software platform requires careful consideration of various factors, including accuracy, cost, scalability, fault tolerance, and reliability. To achieve these objectives, it is necessary to measure the maturity of the AI platform and adhere to Conway's law while applying data-centric principles. In addition, identifying the AI product archetypes and requirements is essential. This involves designing the architectural layers of the AI platform and aligning them with the team design, utilizing the principles of team topologies. Finally, evaluating technology choices, including buying or building a framework, is critical to building a successful AI software platform. This section will explore these topics in greater detail to help architects and product managers understand how to build an effective AI platform.

#### AI Product Archetypes and Their Architectural Complexity

This section will reintroduce several AI product archetypes referring to products incorporating AI technology.

The first category is AI-enabled products, which use AI to enhance their functionality. These products can be further categorized into AI-first solutions, where AI is the application's core, and AI-powered solutions, where AI is an optional feature.

Examples of AI-first solutions include ChatGPT, Exceed AI, and Grammarly, while AI-powered solutions include HubSpot, Shutterstock, and Canva.

Another category of AI-enabled products is AIaaS or AI as a Service, which allows users to access AI services via the cloud. Examples of AIaaS platforms include FaceTec and Identifai ID.

AIaaE or AI as an Engine is another category of AI-enabled products that refers to AI engines that can be deployed on devices via SDKs. Examples of AIaaE products include Trueface and Nodeflux Visionaire.

The second category is AI toolkits, products that help in AI development. These products can be further categorized into data tools, such as annotation, versioning, and synthetic data generators, and modeling tools, such as experimenting, training, workflow orchestration, packaging, serving, optimization, and monitoring. Examples of data tools include Scale, Labelbox, and Pachyderm, while modeling tools include Weights & Biases, MLflow, and Comet.

Each AI product archetype has six layers with varying levels of complexity. These six layers are infrastructure, data, experimentation, deployment, intelligence, and experience. For AI-enabled products, the complexity scores are as follows (Table [8-1](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Tab1)).Table 8-1&#x20;

AI Product Archetype and Its Complexity by Layers

![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265\_1\_En\_8\_Chapter/522265\_1\_En\_8\_Figa\_HTML.png)

In the preceding table, each AI product archetype is listed along with a score for each of the six layers of complexity. The scores range from light green (lowest complexity) to dark green (highest complexity). The scores are based on the level of complexity for each layer for each specific AI product archetype.

#### Measuring the Maturity Level of Your AI System

Designing a software systems architecture for an AI platform can be a complex and challenging process. It is important to measure the maturity level of the AI systems, from the initial stage to the optimized stage, based on the six layers previously described. This helps understand the progress and identify the areas that need improvement (Figure [8-8](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig8)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig8_HTML.jpg" alt="" height="465" width="1418"><figcaption><p>Figure 8-8 </p></figcaption></figure>

The maturity level of an AI system is

1.  1\.

    _Initial_: The infrastructure layer is in the early stages of development, with limited resources and little automation. The data layer is not well-established, with limited data sources and basic data management processes. The data annotation procedure and system are non-existent. The experimentation layer is not yet developed, with ad hoc model testing and no clear approach to model selection or evaluation. The deployment layer is not yet established, with no clear approach to deploying models to production. The intelligence layer is limited, with simple models, standard logical pipeline, and limited automation. The experience layer is not yet developed, with no clear approach to user experience design, error handling, or feedback gathering.

    &#x20;
2.  2\.

    _Managed_: The infrastructure layer is managed and monitored, with some automation in place. The data layer is well-established, with a clear data management process and growing data sources. The experimentation layer is being developed, with some standardization in model selection and evaluation. The deployment layer is in the early stages of development, with some standardization in deployment processes. The intelligence layer is expanding, with a growing range of models and some capability to perform pipeline automation. The experience layer is being developed, with some attention to user experience design, error handling, and feedback gathering.

    &#x20;
3.  3\.

    _Defined_: The infrastructure layer is well-defined, with clear strategies for automation and scaling. The data layer is well-established, with clear data management processes and a wide range of data sources. The experimentation layer is well-established, with standardized model selection and evaluation approaches. The deployment layer is well-established, with clear processes for deploying models to production. The intelligence layer is expanding rapidly, with a wide range of models and significant pipeline automation capability. The experience layer is well-established, with clear attention to user experience design, error handling, and feedback gathering.

    &#x20;
4.  4\.

    _Quantitatively managed_: The infrastructure layer is monitored and optimized, with data-driven decision-making guiding further development and scaling. The data layer is monitored and optimized, with clear metrics for data quality and management processes. The experimentation layer is monitored and optimized, with clear metrics for model performance and model selection. The deployment layer is monitored and optimized, with clear metrics for model deployment and production performance. The intelligence layer is monitored and optimized, with clear metrics for model performance and pipeline that can be automated. The experience layer is monitored and optimized, with clear metrics for user experience design and feedback gathering.

    &#x20;
5.  5\.

    _Optimized_: The infrastructure layer is highly optimized and automated, with efficient infrastructure and system architecture that can handle high traffic and data volumes with ease. The data layer is highly optimized, with advanced data management processes and a wide range of high-quality data sources. The experimentation layer is highly optimized, with advanced model selection and evaluation processes and a wide range of high-performing models and automated model hyperparameterization. The deployment layer is highly optimized, with advanced deployment processes and high levels of production performance. The intelligence layer is highly optimized, with advanced model development and pipeline automation processes that are constantly improving. The experience layer is highly optimized, with advanced user experience design, error handling, and feedback gathering processes that are constantly improving.

    &#x20;

To understand where we are in the maturity level of an AI system based on the six layers, we need to measure with the following steps:

1.  1.Evaluate each layer separately.

    * _Infrastructure layer_: Evaluate the state of the hardware and software infrastructure that supports the platform, including the availability, scalability, and reliability of resources such as compute, virtualization, storage, and networking.
    * _Data layer_: Assess the quality, quantity, and diversity of data that can be processed by the platform, as well as the mechanisms in place for data processing, transformation, labeling, cleaning, quality control, governance, and storage.
    * _Experimentation layer_: Evaluate the platform's ability to do model mix and match, support different types of experimentation (i.e., champion-challenger testing, A/B testing, multi-armed bandit testing), and evaluate model performance.
    * _Deployment layer_: Assess the platform's ability to deploy models to production and perform shadow deployment, including the speed and efficiency of the deployment process, the level of automation, performance monitoring, and the frequency of updates.
    * _Intelligence layer_: Evaluate the level of sophistication of the platform's AI models, including their accuracy, speed, and ability to adapt to changing conditions.
    * _Experience layer_: Assess the user experience of the platform, including the ease of use, accessibility, and effectiveness of the interface.

    &#x20;
2.  2.Once each layer has been evaluated, assign a maturity level to each layer based on the following scale:

    * _Initial_: Basic infrastructure is set up, with no clear strategy for how to scale or optimize the layer.
    * _Managed_: Infrastructure is managed and monitored, with some optimization and scaling strategies in place.
    * _Defined_: The layer has a well-defined strategy for optimization and scaling based on specific business needs and usage patterns.
    * _Quantitatively managed_: Performance metrics are actively monitored and optimized, with data-driven decision-making guiding further development and scaling.
    * _Optimized_: The highly optimized layer has efficient infrastructure and processes that can easily handle high traffic and data volumes.

    &#x20;
3.  3\.

    After assigning a maturity level to each layer, you can determine the overall maturity level of the platform by taking the average of the maturity levels across all layers.

    &#x20;

Measuring the maturity level of an AI platform is an ongoing process as the platform continues to evolve and new challenges arise. Organizations can focus on optimizing the platform to achieve the desired outcomes as the platform matures. This may involve implementing new features, refining existing models, or integrating new technologies.

Therefore, measuring the maturity level of an AI platform is an essential step in designing a software architecture for the platform. By evaluating various aspects of the platform and identifying areas that require improvement, organizations can allocate resources more effectively and optimize the platform for maximum performance.

#### Best Practices of Architecting an AI Software Platform

Architecting an AI platform involves addressing important aspects such as accuracy, cost, scalability, fault tolerance, security, and flexibility. However, building AI platforms also involves challenges such as edge cases, model decay, reliability, and trustworthiness. To address these challenges, several best practices can be followed.

One of the best practices is to embed Conway's law into the system by designing team topologies to optimize communication and collaboration between various teams involved, including data scientists, machine learning engineers, software engineers, and DevOps engineers. Another best practice is to build a data flywheel by making the process data-centric. By making the process data-centric, the focus is on optimizing the whole process from annotation to training and inferencing.

A data-centric platform can help solve edge cases and accuracy decay by using techniques that optimize data as input to AI models, such as data augmentation, feature engineering, ensemble models, regularization, and active learning.

Data augmentation can increase the amount and variety of data used to train the model. Data augmentation can address edge cases by creating new synthetic data that can help improve the performance of AI models in rare or underrepresented scenarios. At the same time, feature engineering can carefully select and engineer more robust features for edge cases. Ensemble models can combine the predictions of multiple models with improving accuracy and robustness, and regularization techniques can prevent overfitting to the training data and improve generalization to new data, including edge cases. Active learning involves iteratively selecting samples from the most informative or uncertain dataset and using them to train the model. Active learning can help the model adapt to edge cases and improve its performance overtime.

Furthermore, a data-centric platform can help build a data flywheel that optimizes the entire annotation, training, and inferencing process. This involves creating a closed-loop feedback system where data is constantly fed back into the system to improve accuracy and performance. The focus is on collecting high-quality data, cleaning and preparing it for training, selecting the best models and hyperparameters, and iteratively improving the models overtime. This process can help improve the accuracy of the model and reduce the impact of edge cases and accuracy decay. The more we have the data, the more accurate the machine learning system.

In short, architecting an AI platform requires addressing important aspects such as accuracy, cost, scalability, fault tolerance, security, and flexibility. Building a data-centric platform and following best practices such as embedding Conway's law, using data augmentation techniques, building ensemble models, and using active learning can help address challenges such as edge cases, model decay, reliability, and trustworthiness. Furthermore, a data-centric platform can help build a data flywheel, optimizing the whole process from annotation to training and inferencing and improving the accuracy of the model overtime.

#### Designing the AI Platform Architecture

Designing an AI platform based on the six layers (infrastructure, data, experimentation, deployment, intelligence, experience) requires careful consideration to ensure scalability, accuracy, maintainability, fault tolerance, flexibility, and security. Here are the step-by-step methods for designing the architecture of an AI platform:

1.  1\.

    _Define the system requirements_: This involves identifying the business use cases and requirements to establish the necessary components of the AI platform. Consider factors such as data sources, performance requirements, user interface, and compliance with the AI platform's necessary features, functionalities, and performance criteria. It is important to clearly understand the requirements up front to guide the design process and ensure that the final product meets user needs.

    &#x20;
2.  2._Design the system architecture_: This involves identifying the subsystems and components of the AI platform and how they interact. The architecture should be designed with scalability, maintainability, and fault tolerance in mind.

    1.  a.

        _Design the infrastructure layer_: Determine the hardware and software infrastructure to support the AI platform. This includes selecting appropriate cloud services, server configurations, and network infrastructure.

        &#x20;
    2.  b.

        _Build the data layer_: Develop a data strategy and architecture that includes data acquisition, data storage, data labeling, data processing, and data management. Consider factors such as data quality, security, governance, and privacy.

        &#x20;
    3.  c.

        _Create the experimentation layer_: Develop a process for model selection, training, evaluation, and iteration. Consider techniques such as hyperparameter optimization, cross-validation, and ensemble modeling.

        &#x20;
    4.  d.

        _Deploy the AI models_: Develop a deployment pipeline that includes packaging, deployment, and monitoring. This should include considerations for version control, scalability, and reliability.

        &#x20;
    5.  e.

        _Develop the intelligence layer_: Develop the algorithms and models pipeline facility that will be used in the AI platform. Consider factors such as accuracy, interpretability, and explainability.

        &#x20;
    6.  f.

        _Build the experience layer_: Develop the AI platform's user interface and user experience (UI/UX). Consider factors such as accessibility, feedback (implicit and explicit), ease of use, and design consistency.

        &#x20;

    &#x20;
3.  3\.

    _Choose appropriate technologies_: The choice of technologies used in the AI platform can significantly impact its performance, reliability, and scalability. It is important to carefully evaluate and choose appropriate technologies, including buy vs. build, which we will discuss in the next section.

    &#x20;
4.  4\.

    Identify the teams involved in building, maintaining, and operating the AI platform and designing the system architecture in a way that optimizes communication and collaboration between them.

    &#x20;
5.  5\.

    _Implement and test the system_: Once the system architecture has been designed and appropriate technologies chosen, the system can be implemented and tested. Testing should be performed at multiple stages of development, including unit testing, integration testing, and system testing, to ensure that the system meets the requirements and performs as expected.

    &#x20;
6.  6\.

    _Deploy and monitor the system_: After the system has been tested and verified, it can be deployed and put into production. Ongoing monitoring and maintenance are crucial to ensure that the system continues to perform optimally and meets user needs.

    &#x20;

Implementing an effective and robust artificial intelligence (AI) platform necessitates the adoption of established best practices. Specifically, using the systems engineering approach, data-centric approach, Conway's law, and team topologies principle can ensure the development of a scalable, maintainable, and fault-tolerant AI system. Adherence to these principles can offer a comprehensive framework for designing and implementing AI platforms that meet the evolving demands of modern technology. As such, it is crucial for practitioners in the field of AI to prioritize the application of such best practices in their development efforts.

For example, in an AIaaS platform like Identifai, the infrastructure layer may involve using cloud services such as Amazon Web Services (AWS) or Microsoft Azure. The data layer may include data processing techniques such as data augmentation (augmenting half/full mask to the face). The experimentation layer may involve techniques such as active learning and ensemble modeling. The deployment layer may include containerization and Kubernetes for scalability. The intelligence layer may involve deep learning models such as FaceNet for face matching. Finally, the experience layer may include the development of a user-friendly dashboard for customers to access the AI services.

For an AI-first application like ChatGPT, the infrastructure layer may involve using cloud services such as Microsoft Azure to host the application. The data layer may involve natural language processing (NLP) techniques to process user input. The experimentation layer may involve the use of language models based on transformers such as GPT-3 for generating responses. The deployment layer may involve the use of APIs for integration with other applications. The intelligence layer may involve techniques such as sentiment analysis for understanding user emotions. Finally, the experience layer may include the development of a chatbot interface for users to interact with the AI.

#### Evaluating Technology Choices

Designing and building an AI platform requires careful consideration of the tools and frameworks used in each of the six layers: infrastructure, data, experimentation, deployment, intelligence, and experience. These tools can be open source or paid and may involve building from scratch or purchasing pre-made solutions. To ensure the platform is built effectively, it is important to clearly understand the available options and how they align with the business requirements and use cases. The selection process should involve identifying the strengths and weaknesses of each tool, evaluating their performance and scalability, and considering their compatibility with the overall system architecture. Additionally, a decision must be made whether to buy or build the necessary tools and framework, which involves balancing factors such as cost, time to market, and the level of customization required. By following a structured approach to tool selection and considering both buy and build options, it is possible to build a robust and effective AI platform that meets the business's unique needs.

The following is a step-by-step structured approach to tool selection and considering buy vs. build for an AI platform:

1.  1\.

    _Identify business requirements_: Understand the AI platform's business requirements and use cases. This will help identify the platform's necessary components, including the required tools and frameworks. Consider scalability, accuracy, fault tolerance, flexibility, and security.

    &#x20;
2.  2\.

    _Evaluate available tools_: Conduct research to identify the tools and frameworks available for each layer of the AI platform. Consider both open source and proprietary options and tools that can be bought or built in-house. Evaluate each tool based on its features, performance, and cost.

    &#x20;
3.  3\.

    _Assess buy vs. build_: Based on the evaluation, determine whether buying an existing tool or building one in-house using open source software stacks is more cost-effective. Consider factors such as the time and resources required to build a tool, the level of expertise available in-house, the unique selling proposition offered, intellectual property, and the Total Cost of Ownership.

    &#x20;
4.  4\.

    _Test and validate_: Once the tools have been selected, test and validate them to ensure that they meet the requirements of the AI platform. Conduct testing at multiple stages of development, including unit testing, integration testing, and system testing.

    &#x20;
5.  5\.

    _Monitor and update_: After integrating the tools into the AI platform, monitor their performance and functionality regularly. Update them to ensure they meet the business and technical evolving needs.

    &#x20;
6.  6\.

    _Consider scalability_: Consider the scalability of the tools and frameworks chosen. Determine whether they can handle the expected increase in data and usage overtime. Ensure that the tools can be easily scaled up or down as needed.

    &#x20;

The rule of thumb is that if you want unique technology differentiation, then it is better to build from scratch in-house than buy ready-made solutions. The observation on several AI startups on the buy vs. build for our AI product archetypes is as follows (Table [8-2](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Tab2)).Table 8-2&#x20;

AI Product Archetype: Buy vs. Build

| AI Product Archetype | Infrastructure | Data  | Experimentation | Deployment | Intelligence | Experience |
| -------------------- | -------------- | ----- | --------------- | ---------- | ------------ | ---------- |
| **AI-first**         | Buy            | Buy   | Build           | Build      | Build        | Build      |
| **AI-powered**       | Buy            | Buy   | Buy             | Buy        | Buy          | Build      |
| **AIaaS**            | Buy            | Buy   | Build           | Build      | Build        | Build      |
| **AIaaE**            | Buy            | Buy   | Build           | Build      | Build        | Build      |
| **Data tools**       | Buy            | Build | N/A             | N/A        | N/A          | Build      |
| **Modeling tools**   | Buy            | N/A   | Build           | Build      | Build        | Build      |

An AI-first product company tends to build almost everything in-house because they must have strong technology propositions compared with their competitors. This is why an AI-first product such as ChatGPT is developed exclusively in-house.

On the other hand, the AI-powered product company can use a ready-made platform for data and model engineering (from data acquisition to model training/testing) because AI is only an option/additional feature for them.

Note that these recommendations are based on a general assessment of cost vs. value and may vary depending on each organization's specific needs and resources. It is important to carefully evaluate the costs and benefits of buying vs. building for each layer of the AI platform, considering factors such as time to market, customization, and maintenance.

### Developing an AI Platform

With the rapid development of machine learning algorithms and deep learning techniques, the potential applications of AI are endless.

However, software development for AI software using machine learning differs from that of traditional non-AI software, requiring special consideration.

This section will explore the key differences between the two and examine the software development principles for AI software platforms.

We will explain in more detail the ten stages of AI software development. We will also discuss the AI software maturity model and how to measure AI software development process maturity. Finally, we will delve into the AI software development process, including MLOps, and highlight the ten stages of developing AI software. By understanding these topics, software developers will be better equipped to design, build, and deploy robust and effective AI software that meets the needs of their clients or organizations.

#### Why AI Software Development Is Different from Traditional Software Development

AI software development is different from conventional non-AI development due to several reasons:

1.  1\.

    Traditional software development relies on predefined logic and rules, while AI software development involves creating algorithms that can learn and improve overtime. This requires a different approach to problem-solving, testing, and quality assurance, as the behavior of the AI software is not always predictable.

    &#x20;
2.  2\.

    AI software development involves dealing with large datasets and complex models requiring specialized skills and tools. The development process involves coding, extensive data preparation, and feature engineering to create effective machine learning models.

    &#x20;
3.  3\.

    AI software development requires continuous monitoring and optimization to ensure that the models remain accurate and effective overtime. Discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering. This is because the data needs to be collected, cleaned, and labeled to ensure high-quality and unbiased data, which can be time-consuming. Additionally, model customization and model reuse require very different skills than are typically found in software teams.

    &#x20;
4.  4\.

    Developing machine learning models requires specialized knowledge in statistics and mathematics and domain-specific knowledge.

    &#x20;
5.  5\.

    AI components exhibit greater interaction complexity than non-AI software components, making them more difficult to manage as separate modules. Models in AI systems may be intertwined in intricate ways, leading to non-monotonic error behavior that is hard to predict and diagnose. This complexity calls for specialized software development practices and tools to handle the intricacies of AI systems.

    &#x20;
6.  6\.

    The probabilistic and dynamic nature of the input environment causes edge cases and unexpected behavior, which can be challenging to predict and manage.

    &#x20;

These factors make AI software development a specialized and complex process that requires unique skills and expertise. The following section will discuss how to deal with the preceding challenges from a software development perspective.

#### The Principles of Software Development for an AI Software Platform

To overcome these challenges, several solutions can be implemented.

First, we must embrace machine learning operations (MLOps) and use specialized tools and frameworks (i.e., Neptune, Valohai, Iguazio)[5](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn5) that can help streamline the development process and ensure accuracy and efficiency while reducing model decay.

Implementing version control and data management techniques can also help manage the complexity of data used in AI software development, ensuring that data is accurate, up to date, and easily accessible to developers.

Conducting thorough testing and validation is also essential to ensure that AI models are accurate, effective, and safe, including testing for edge cases and unexpected behavior and validating the model's performance against relevant benchmarks.

In addition, implementing active learning mechanisms can help subside edge cases,[6](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn6) while applying trustworthy and responsible AI through the development of XAI mechanisms can enable root cause analysis and ensure transparency and explainability.

Implementing monitoring and alerting mechanisms can detect and mitigate issues in the platform, ensuring that AI models remain accurate and effective overtime. Adopting Agile and DevOps methodologies can enable flexibility, collaboration, and continuous integration and deployment, which are essential for AI software development.

Finally, fostering cross-functional and interdisciplinary teams is crucial to ensure a comprehensive approach to AI software development that accounts for real-world applications. Such teams should include data science, machine learning engineering, data engineering, software development, and domain knowledge experts. By bringing together individuals with diverse skill sets, it becomes possible to consider all aspects of AI software development and ensure that models are built to meet the needs of users and stakeholders. This approach is aligned with the principles of team topologies, which emphasizes the importance of creating teams optimized for specific tasks and empowered to collaborate effectively.

#### Understanding AI Software Development Stages

The development of an AI software application involves a series of stages that are critical to its success (Figure [8-9](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig9)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig9_HTML.jpg" alt="" height="1104" width="1418"><figcaption><p>Figure 8-9 </p></figcaption></figure>

The stages of AI software development are as follows (Figure [8-5](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig5)):

1.  1\.

    _Gather model requirements_: This stage involves identifying the specific goals of the AI software application, including the type of data to be used, the intended users, and the desired outcomes. The goal is to establish a clear understanding of the problem to be solved by the AI software application.

    &#x20;
2.  2\.

    _Data collection_: The second stage involves gathering and preparing the necessary data for the AI software application. This involves identifying data sources, collecting and cleaning the data, and preparing it for use in the application.

    &#x20;
3.  3\.

    _Data cleaning and transformation_: Once the data has been collected, it must be cleaned and transformed to ensure that it is accurate, complete, and in the correct format for use in the AI software application. This may involve data normalization, imputation, and other techniques to ensure that the data is consistent and reliable.

    &#x20;
4.  4\.

    _Data labeling_: In this stage, data is labeled to provide a clear understanding of the features and attributes of the data. This labeling is important for training and validating AI models.

    &#x20;
5.  5\.

    _Feature engineering/data augmentation_: This stage involves transforming the labeled data into a format suitable for use in AI models. This may involve data augmentation techniques to increase the diversity and quantity of labeled data and feature selection to identify the most important features of the model.

    &#x20;
6.  6\.

    _Model training_: The next stage involves training the AI model on the prepared data. This includes selecting appropriate machine learning algorithms, tuning model hyperparameters, and evaluating model performance.

    &#x20;
7.  7\.

    _Model evaluation_: In this stage, the trained model is evaluated to assess its performance and suitability for the intended use case. This may involve various metrics such as accuracy, precision, recall, and validation against external data.

    &#x20;
8.  8\.

    _Model deployment_: Once the model has been evaluated and validated, it can be deployed into a production environment. This may involve packaging the model and integrating it into the software application.

    &#x20;
9.  9\.

    _Model monitoring_: After deployment, the model must be monitored to ensure that it remains accurate and effective overtime. This may involve performance monitoring, error detection, and retraining of the model as necessary.

    &#x20;
10. 10\.

    _UI/UX development_: Finally, the AI software application's user interface and user experience (UI/UX) must be designed and developed. This includes accessibility, ease of use, and design consistency.

    &#x20;

#### Measuring the Maturity Level of an AI Software Development Process

To develop effective and efficient AI software, it is important to have a structured approach incorporating best practices and standards. The Carnegie Mellon Capability Maturity Model (CMM)[7](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn7) provides a framework for assessing the maturity of an organization's software development process. Based on this model, we can define the five stages of AI software development process maturity (Figure [8-10](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig10)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig10_HTML.jpg" alt="" height="451" width="1418"><figcaption><p>Figure 8-10 </p></figcaption></figure>

* _Initial stage_: In this stage, the organization is just starting to develop AI software. There are no defined processes or procedures, and development is typically ad hoc. There is little documentation, and the development team is focused on individual tasks rather than a coordinated effort.
* _Repeatable stage_: In this stage, the organization has established basic processes and procedures for AI software development. There is documentation, and the team is beginning to work together in a coordinated effort. However, the processes are not yet fully mature, and there is still room for improvement.
* _Defined stage_: In this stage, the organization has well-defined processes and procedures for AI software development. There are guidelines and standards that the development team follows, and there is a focus on quality assurance and risk management. The team is working in a coordinated effort, and there is an emphasis on continuous improvement.
* _Managed stage_: In this stage, the organization has established metrics for measuring the effectiveness of its AI software development processes. The development team is focused on meeting these metrics and is continuously monitoring and improving its processes. There is a focus on risk management, quality assurance, and customer satisfaction.
* _Optimized stage_: In this stage, the organization's AI software development processes are fully mature and optimized. The development team is continuously improving its processes and has established a culture of innovation and creativity. There is a focus on metrics, risk management, quality assurance, and customer satisfaction, and the team is working in a coordinated effort to achieve the organization's goals.

**Measuring AI Software Development Process Maturity**

We can use the ten stages of AI software development defined earlier to measure the maturity of an organization's AI software development process. Each stage represents a specific set of practices and procedures the development team should follow. By assessing the organization's practices against these stages, we can identify areas for improvement and develop a plan for achieving higher maturity levels.

**Applying the Measurement Framework to Your Process**

To use the measurement framework for your AI product, follow these steps:

1.  1\.

    Identify the ten stages of AI software development and the practices and procedures associated with each stage.

    &#x20;
2.  2\.

    Assess your organization's practices against each stage.

    &#x20;
3.  3\.

    Identify areas where your organization can improve and develop a plan for achieving higher maturity levels.

    &#x20;
4.  4\.

    Continuously monitor and evaluate your organization's practices and procedures to ensure they remain effective and efficient.

    &#x20;
5.  5\.

    Continuously strive for higher maturity levels, always seeking to improve your organization's practices and procedures.

    &#x20;

#### AI Software Development Process

Developing an AI software platform involves various steps and considerations, from setting up the development environment and infrastructure to building testing and validation pipelines. Here is a detailed breakdown of the process:

* _Setting up the development environment and infrastructure_: This involves setting up the development environment, including the necessary software and hardware components. The infrastructure needs to include hardware resources such as computing power, storage, and memory. Cloud-based services like Amazon Web Services, Google Cloud Platform, and Microsoft Azure provide hardware resources on demand, which can be scaled up and down depending on the needs of the product.
* _Implementing the data pipeline, model training, model serving, and monitoring components_: The data pipeline involves collecting, cleaning, labeling, and transforming data. Open source tools such as Apache Kafka and Apache Beam can be used for data ingestion and streaming. Model training involves selecting an appropriate algorithm, choosing hyperparameters, and training the model. Popular open source machine learning frameworks include TensorFlow, PyTorch, and MXNet. Model serving involves deploying the model for use in production, either as a REST API or in a serverless architecture. Kubernetes and Docker are popular open source tools for model serving. Model monitoring involves tracking the model's performance, including metrics such as accuracy, precision, and recall. Open source tools like Prometheus, Grafana, and Elastic Stack can be used for monitoring.
* _Implementing MLOps mechanisms in the software_: MLOps involves applying DevOps principles to machine learning, including version control for models, automated testing, and continuous integration and deployment (CI/CD) pipelines. Model version control can be achieved using Git, while automated testing can be implemented using tools like Pytest or Nose. This involves setting up a pipeline for testing and validating the AI platform. This includes unit testing, integration testing, system testing, and testing for edge cases and unexpected behavior. CI/CD pipelines can be set up using Jenkins, Travis CI, or CircleCI. The pipeline can be triggered automatically every time new code or models are committed to the repository. Automated retraining involves using continuous learning and active learning mechanisms to improve the performance of the model overtime. There are also ready-to-use end-to-end MLOps platforms such as Neptune, Valohai, Iguazio, and ClearML that can be used.
* _Developing the user interface and integration interfaces_: Developing a user interface (UI) involves designing and building a user-friendly interface for users to interact with the AI platform. This can be achieved using popular front-end frameworks like React or Vue.js. Integration interfaces allow the AI platform to integrate with other systems and platforms, such as web services or databases. This can be achieved using REST APIs or other integration mechanisms.

Overall, developing an AI software platform requires combining technical expertise, domain knowledge, and an understanding of best practices in software engineering and MLOps. By following a structured approach and using open source tools and frameworks, developers can create robust and effective AI software platforms that meet the needs of users and organizations. Several good references exist for a more detailed approach to machine learning development.[8](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn8),[9](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn9)

### Operationalizing an AI Platform

Operationalizing an AI platform refers to the process of deploying an AI system into production so that it can be used to perform real-world tasks or provide value to users. This involves integrating the AI system into the existing infrastructure of an organization or application, testing and validating the system, and ensuring that it is performing as expected. Operationalizing an AI platform involves taking the model from a proof-of-concept or experimental stage to a production-ready state, where it can perform real-world tasks and provide value to users.

The success of an AI software platform relies heavily on the coordination and collaboration of various teams involved in the development and operationalization process. The machine learning team plays a crucial role in developing the models that power the platform. Still, they must work closely with data engineers, software developers, tech operations, and other domain experts to ensure that the platform meets end users' needs. Coordinating the work of different teams can be challenging, but using team topologies can help ensure that teams are structured and aligned for optimal performance.

Aligning MLOps processes with team topologies is also crucial for the success of an AI software platform. MLOps processes manage the entire lifecycle of machine learning models, including development, training, deployment, and monitoring. When these processes are aligned with team topologies, it can ensure that the appropriate teams are responsible for each step of the process and that communication and collaboration are optimized.

In this section, we will explore the use of team topologies in managing and operationalizing AI software platforms. We will discuss how to build effective teams using team topologies for different AI product archetypes and provide examples of how MLOps processes can be aligned with these team structures. By aligning MLOps with team topologies, we can ensure that the development and management of AI software platforms are optimized for success.

#### Team and Task

Developing and operationalizing an AI platform requires a team with diverse skills and expertise. The team must work collaboratively to ensure the AI platform is successfully designed, built, and deployed. The following are the key team members and their tasks for the development and operationalization of an AI platform using the MLOps/ModelOps process:

* _Product manager_: A product manager defines the product vision, strategy, and roadmap. They work closely with the subject matter experts, machine learning scientists, and the MLOps engineer to define product requirements and ensure that the product meets the needs of its intended users.
* _Subject matter expert_: A subject matter expert is a domain expert who understands the business problem that the AI platform is trying to solve. They work with the product manager and the machine learning scientists to define the scope of the problem, provide feedback on the model's outputs, and ensure that the platform meets the business needs.
* _Data labeler_: Data labeling is a crucial part of the AI development process, and a dedicated data labeler team is responsible for this task. They annotate data for training, testing, and validating machine learning models. They ensure the data is accurate, consistent, and labeled according to predefined guidelines.
* _Front-end software engineer_: A front-end software engineer is responsible for developing the user interface of the AI platform. They ensure that the user interface is intuitive, responsive, and easy to use for end users.
* _Machine learning scientist/data scientist_: Machine learning scientists are responsible for developing and training the machine learning models that power the AI platform. They use various algorithms, techniques, and tools to build, test, and optimize the models. They work closely with the subject matter experts and the data engineering team to ensure that the models are accurate and effective.
* _Machine learning/MLOps engineer:_ A machine learning/MLOps engineer is responsible for implementing the MLOps/ModelOps process. They design and build the AI platform's data pipeline, model training, model serving, and monitoring components. They also ensure that the platform is scalable, reliable, and secure.
* _Data engineer_: A data engineer is responsible for designing and building the data infrastructure that supports the AI platform. They ensure that the data is ingested, cleaned, transformed, and stored in an efficient, scalable, and secure way.
* _DevOps/infrastructure/back-end engineer_: They are responsible for designing and building the back-end infrastructure that supports the AI platform. They ensure that the platform is deployed on reliable and scalable infrastructure, that the platform is secure, and that there are mechanisms for backup and disaster recovery.
* _TechOps engineer_: A TechOps engineer is responsible for ensuring the platform is operational 24/7. They monitor the platform for errors, issues, and performance degradation. They work with the MLOps engineer to ensure the platform is retrained and updated regularly to maintain accuracy and effectiveness.
* _Customer success_: This team is responsible for ensuring that the AI product meets the needs and expectations of customers. They work closely with customers to understand their requirements, provide guidance on product features and usage, and address any issues or concerns that arise. Customer success team members may have a background in sales, marketing, or customer support and should have strong communication and problem-solving skills. Their role is crucial for the success of the AI product, as it helps ensure customer satisfaction and retention.

Though MLOps is a good process for streamlining the AI system production and operationalization, most AI teams are working separately with minimal alignment. There must be a way for them to align and collaborate well even with minimum communication. Team topologies is the answer. Aligning the team with team topologies is crucial to ensure that each team member understands their roles and responsibilities. It also ensures that each team member has the necessary tools, processes, and communication channels to collaborate effectively.

#### Coordinating the Different Teams with Team Topologies

Team topologies is a modern organizational approach that helps companies build better teams to deliver quality products and services (Figure [8-11](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fig11)). In this approach, different teams are created based on the nature of their work and how they interact with other teams:

* The stream-aligned team is responsible for delivering the product and services to customers, and it works closely with other teams to ensure that the product meets the market needs.
* The complicated subsystem team focuses on building complex software components that are difficult to understand or manage.
* The platform team is responsible for building and maintaining the core platform infrastructure, which other teams can use to develop their products.
* The enabling team focuses on providing tools, services, and support to other teams so they can work effectively.

Interaction mode is another important concept of team topologies. In this approach, different teams interact with each other based on the nature of their work:

* X as a Service means that teams provide services to other teams to focus on their core work.
* Collaborating means that teams work together to achieve common goals.
* Facilitating means that teams provide tools and resources to other teams, so that they can work more efficiently.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781484295021/files/images/522265_1_En_8_Chapter/522265_1_En_8_Fig11_HTML.jpg" alt="" height="705" width="1299"><figcaption><p>Figure 8-11 </p></figcaption></figure>

Aligning the MLOps process and the team using team topologies is a good idea because it helps streamline the AI software development process. MLOps is a set of practices and tools that enable data scientists and machine learning engineers to develop, deploy, and monitor machine learning models at scale. By aligning the MLOps process with team topologies, companies can ensure that each team clearly understands their role in the development process and can work together effectively to deliver quality products.

In the context of the AI platform, the generic team topologies can be structured as follows:

* _The_ _stream-aligned team_: This team is responsible for delivering customer value by aligning all teams to a clear, well-understood mission.
  * _Product manager_: The product manager is a critical member of the stream-aligned team. They are responsible for defining the product vision and roadmap and ensuring that all teams are aligned to the same goals.
  * _Subject matter expert_: The subject matter expert can provide valuable input on customer needs and market trends, which can help shape the product vision and roadmap.
  * _Front-end software engineer_: The front-end software engineer can contribute to developing the user interface, which is a critical component of the customer experience.
  * _TechOps engineer_: The TechOps engineer can contribute to the stream-aligned team by monitoring the platform for errors, issues, and performance degradation.
  * _Customer success_: Customer success can contribute to the stream-aligned team by ensuring that the AI product meets the needs and expectations of customers. In AI products, where sometimes the customer expectation is unrealistic (i.e., comparing the AI capability to the human cognitive capability), good customer service will help channel feedback from the customer to the internal team and vice versa.
* _The_ _complicated subsystem team_: This team is responsible for developing and maintaining the complex subsystems that underpin the AI system.
  * _Machine learning scientist/data scientist_: The machine learning scientist/data scientist is a critical member of the complicated subsystem team. They are responsible for developing complex models that power the AI system.
* _The_ _platform team_: This team is responsible for developing and maintaining the platform on which the AI system runs.
  * _DevOps/infrastructure/back-end engineer_: The DevOps/infrastructure/back-end engineer is a critical platform team member. They are responsible for building and maintaining the AI system's infrastructure.
  * _Machine learning/MLOps engineer_: The machine learning/MLOps engineer can contribute to the platform's development by ensuring that the models are properly deployed and monitored and that the infrastructure is in place to support the AI system.
  * _Data engineer_: The data engineer is responsible for building and maintaining the data pipeline, a critical component of the AI system.
* _The_ _enabling team_: This team provides the tools and processes that enable the other teams to do their jobs effectively.
  * _Data labeler team_: The data labeler team can contribute to the enabling team by providing high-quality labeled data necessary for developing and training the AI system.

CASE STUDY: BUILDING AN EKYC AI AS A SERVICE PLATFORM

Identifai ID is a startup that provides AIaaS solutions for biometrics-based eKYC API and SDK for digital verification and identification. Their product includes face recognition, face liveness detection, OCR ID, and demography recognition deployed as API and SDK.

They are designing, developing, and operationalizing the AI platform based on the framework described in this chapter by the unifying system, process, and team design to ensure that the platform is scalable, maintainable, and fault tolerant. The framework emphasizes the importance of adhering to established best practices such as the systems engineering principle, data-centric approach, Conway's law, and team topologies principle. By following this comprehensive framework, the team can design and develop an AI platform that is optimized for real-world use and can effectively address the needs of the target application or system. Additionally, the team will be better equipped to overcome potential challenges that may arise during the operationalization of the platform, such as data integration or model accuracy issues.

These are the steps they are following:

1.  1._Designing the AI platform based on the six layers_: Identifai ID designs their AI platform using the six layers of AI application development: data, model, training, optimization, execution, and feedback. They carefully consider the complexity of each layer, especially in facial liveness detection, which is a challenging problem.

    * The data layer includes collecting, processing, and cleaning data. Identifai ID uses various data sources, such as public databases and private datasets, to ensure data accuracy and privacy.
    * Identifai ID builds machine learning models in the model layer to perform the biometrics-based eKYC process. They use deep learning techniques to achieve high accuracy and performance.
    * Identifai ID trains their models in the training layer using labeled data and algorithms, such as convolutional neural networks and recurrent neural networks.
    * In the optimization layer, Identifai ID optimizes their models for efficiency and performance using techniques like hyperparameter tuning and pruning.
    * In the execution layer, Identifai ID deploys their models as APIs and SDKs to provide their eKYC solutions to customers.
    * Identifai ID continuously monitors their models in the feedback layer and collects customer feedback to improve their system.

    &#x20;
2.  2._Designing the_ _MLOps process_: Identifai ID designs their MLOps process to ensure efficient model development, testing, deployment, and monitoring. They use Git for version control, Jenkins for continuous integration and deployment, and Kubernetes for container orchestration.

    * _MLOps process applied for their eKYC product_: Identifai ID uses the MLOps process to improve their eKYC product continuously. They test and validate their models using real-world data and customer feedback and deploy new versions of the models as necessary.
    *   _Technology stack selection_: Identifai ID considered building and buying options for their technology stack. They opted to use a mix of open source and proprietary technologies to achieve the best balance of cost, performance, and support. For their face recognition component, they selected the OpenCV library to perform the initial feature extraction and then used the FaceNet model from Google's TensorFlow framework to perform the final face recognition step. They used an ensemble of specialized convolutional neural networks (SCNN) and the Inception network for face liveness detection.

        For OCR ID and demography recognition, they used U-Net for segmentation and RCNN for character recognition. They integrated these components as a pipeline into their AI platform and used an API gateway to provide a unified interface for their customers.

    &#x20;
3.  3._Team topologies_: Identifai ID implemented the stream-aligned team topology, which focused on delivering a high-quality eKYC product while responding quickly to customer needs. The team was structured as follows:

    * _Product manager_: Responsible for defining the product roadmap, features, and user experience
    * _Subject matter expert_: Responsible for understanding the biometrics and regulatory requirements of eKYC and guiding the team in developing solutions to meet those requirements
    * _Data labeler team_: Responsible for labeling the large volumes of data needed to train and validate the AI models
    * _Front-end software engineer_: Responsible for designing and developing the user interface for the Identifai ID portal and customer-facing APIs
    * _Machine learning scientist/data scientist_: Responsible for designing and training the AI models for face recognition, liveness detection, OCR ID, and demographic classification
    * _Machine learning/MLOps engineer_: Responsible for implementing the MLOps process, deploying models to production, monitoring their performance, and retraining them as necessary
    * _Data engineer_: Responsible for managing the data pipeline, integrating various data sources, and ensuring data quality
    * _DevOps/infrastructure/back-end engineer_: Responsible for building and maintaining the cloud infrastructure, managing security and compliance, and ensuring high availability and scalability of the platform
    * _TechOps engineer_: Responsible for managing the APIs and SDKs, providing technical support to customers, and ensuring smooth integration with customer systems
    * _Customer success_: Responsible for managing customer expectations and gathering valuable feedback

    &#x20;

The team was organized into feature teams that focused on delivering specific features of the eKYC product, such as face recognition or OCR ID. Each feature team consisted of members from different functional areas, such as machine learning, data engineering, and front-end development. The team used Agile methodologies to enable rapid iteration and collaboration and had daily stand-up meetings to ensure everyone was aligned and any issues were quickly addressed.

By implementing the stream-aligned team topology, Identifai ID delivered a high-quality eKYC product that met its customers' needs while responding quickly to changing market and regulatory requirements.

To manage the project's complexity and ensure that each team member clearly understands their roles and responsibilities, Identifai ID adopts the team topologies approach. The stream-aligned team is responsible for managing the end-to-end delivery of the product, including the development and deployment of the AI models, data pipelines, and APIs. The complicated subsystem team is responsible for developing and maintaining the complex facial liveness detection component. The platform team is responsible for developing and maintaining the API infrastructure, while the enabling team is responsible for developing and maintaining the SDKs.

Identifai ID also focuses on customer success and ensures that their AIaaS product meets the needs of their customers. They conduct user testing and gather feedback to improve their product's accuracy and efficiency. They also provide customer support to address any issues customers may encounter during onboarding or while using the product.

To conclude, Identifai ID is a successful AI startup that designs, develops, and operationalizes an AIaaS biometrics-based eKYC API and SDK for digital verification and identification. They use a six-layer AI platform design, MLOps process, build vs. buy framework, and team topologies to ensure their product's successful development and delivery. By focusing on customer success and continuously improving their product, Identifai ID has become a trusted and reliable solution for digital verification and identification.

### Registering IP of an AI Product

In recent years, there has been a remarkable surge in the patenting of artificial intelligence (AI) technologies, indicating the growing recognition of AI’s significance and potential. According to the World Intellectual Property Organization (WIPO), the number of AI-related patent applications worldwide witnessed an impressive 193% increase between 2013 and 2017. Furthermore, WIPO’s examination of corporate acquisitions in the AI sector revealed that since 1998, 434 companies have been acquired, mostly occurring after 2016.

Today, AI and machine learning have emerged as driving forces behind innovation across numerous industries. Companies that recognize these technologies’ substantial value are prudently safeguarding their intellectual property to secure a competitive advantage. Within this context, the United States Patent and Trademark Office (USPTO) has issued guidelines outlining what can be patented in the realm of AI and machine learning.

To obtain a patent for your AI innovation, it must fall under specific categories such as machine, method, article of manufacture, or composition of matter. However, it must not be related to laws of nature, physical phenomena, or abstract ideas. While some machine learning algorithms and AI inventions may be deemed abstract ideas and fail to gain patent protection, it is possible to patent the sequence of stages in your method. Under US patent law, this is because an algorithm is defined as a series of mathematical steps and operations.

It is important to note that while the software itself can be copyrighted as a finished product, machine learning methods are often considered abstract. To navigate this landscape successfully, best practices derived from software patents can be applied when seeking an AI (machine learning) model patent.

Here’s a breakdown of these practices in simpler terms:

1.  1\.

    _Focus on the structure of the machine learning model in the claim_: Highlight your machine learning model’s unique design and architecture when describing your invention. Explain how it differs from existing models and what makes it innovative.

    &#x20;
2.  2\.

    _Identify the training and execution phases_: Determine whether your invention primarily relates to the training phase, where the model learns from data, or the execution phase, where it applies what it has learned to make predictions or decisions. It could be relevant to both phases as well.

    &#x20;
3.  3\.

    _Claim the training process_: Clearly state the steps in training your model, including any specific techniques or algorithms used. This demonstrates the originality and value of your approach to training the AI model.

    &#x20;
4.  4\.

    _Emphasize the preparation of input data_: Explain how you gather, clean, and preprocess the data before feeding it into the model. Highlight any unique methods or strategies you employ to ensure the quality and relevance of the input data.

    &#x20;
5.  5\.

    _Cover the input mapping to the model_: Describe how the input data is transformed or mapped to work effectively with your AI model. This can involve techniques like feature engineering or data preprocessing to optimize the model’s performance.

    &#x20;
6.  6\.

    _Claim the post-processing and interpretation of output data_: Outline the steps involved in processing and interpreting the output generated by the model. This could include any additional computations or analyses performed on the results to extract meaningful insights.

    &#x20;
7.  7\.

    _Draft different claim sets for training and execution phases_: Create separate sets of claims that specifically address the unique aspects of your invention in the training and execution phases. This ensures that you cover all relevant aspects and increases the chances of obtaining comprehensive patent protection.

    &#x20;
8.  8\.

    _Avoid claiming conventional application to existing data_: Be careful not to make claims involving applying an existing model to existing data without substantial innovation. Please focus on the novel elements and improvements you have made to the AI model or the overall process.

    &#x20;

Registering IP for AI products involves several steps:

1.  1\.

    Conduct a patent search to assess the novelty of your AI product.

    &#x20;
2.  2\.

    Document and describe your inventions, identify patentable aspects, and consult with IP professionals.

    &#x20;
3.  3\.

    File patent applications, prosecute, and defend your patents.

    &#x20;
4.  4\.

    Maintain and monitor them.

    &#x20;

Seeking legal advice and working with experienced IP practitioners enhances your chances of successfully protecting your AI inventions.

### How to Scout Top AI Talents and Compete with Big Tech

In the rapidly evolving field of artificial intelligence (AI), attracting and retaining top talent is crucial for the success of any AI startup. However, competing with established big tech companies such as Google, Meta, OpenAI, Tesla, and others in terms of salary, facilities, and career development can be a daunting task. To overcome these challenges, it is essential to adopt a strategic approach to scouting and hiring the best AI talents as follows:

1.  1\.

    _Stay updated with latest research_: To identify promising AI talents, it is imperative to stay well-informed about the latest advancements in machine learning and AI in general. Regularly read research papers from top universities, research labs, and conferences, keeping an eye on emerging trends and breakthroughs. This will help you understand the cutting-edge techniques and areas relevant to the products you are building.

    &#x20;
2.  2\.

    _Identify relevant authors_: Once you come across research papers relevant to your products, focus on identifying the authors who contributed to those papers. Ideally, look for PhD students as they possess in-depth knowledge and expertise in their respective fields. Master’s students can also be valuable contributors. Consider sponsoring their PhD studies at the best universities near your geographical location, emphasizing the importance of relocation to your organization.

    &#x20;
3.  3\.

    _Leverage value proposition_: Recognize that you may not be able to match the salary, facilities, and career development opportunities offered by big tech companies. Instead, compete by highlighting the unique value your startup provides. Emphasize the impact and value for societies that AI talents can make by working with your organization. Stress that they won’t be mere cogs in a machine but will have the autonomy to make important decisions, collaborate with universities, choose conferences to attend, and publish papers. Additionally, emphasize their involvement in real-world AI deployment, exposing them in an end-to-end process from research to deployment using the MLOps or LLMOps process.

    &#x20;
4.  4\.

    _Offer freedom and intellectual stimulation_: Attract talented AI professionals by offering them the freedom to explore and work on interesting projects during their spare time. Create an environment that encourages experimentation and innovation, allowing them to pursue their passion and curiosity. Emphasize the opportunity to work on diverse and impactful projects that go beyond profit-oriented goals prevalent in big tech companies.

    &#x20;
5.  5\.

    _Communicate value and impact effectively_: Communicate the value and impact your AI startup is making to the world. Highlight the societal benefits, ethical considerations, and the opportunity to contribute to cutting-edge research and technological advancements. Demonstrate that your organization is driven by a mission to solve important problems and make a positive difference, fostering a sense of purpose and fulfillment among AI talents.

    &#x20;

By implementing these tips, your AI startup can attract and retain exceptional talents, creating a competitive advantage even when compared with big tech giants.

### Conclusion

This chapter explains the intricacies of building an AI platform requiring a multidisciplinary approach combining machine learning, software engineering, and data management expertise.

Developing an effective AI platform involves several key steps, including defining the problem, collecting and cleaning data, building and testing models, deploying them, and monitoring and maintaining their performance overtime.

MLOps provides a framework for managing the entire lifecycle of AI models, from development to deployment and beyond. It includes processes such as version control, automated testing, continuous integration and deployment (CI/CD) pipelines, model serving, monitoring, and automated retraining.

Aligning MLOps processes with team topologies ensures that each team member clearly understands their roles and responsibilities and has the necessary tools, processes, and communication channels to collaborate effectively. The stream-aligned, complicated subsystem, platform, and enabling teams provide a flexible framework for building interdisciplinary teams that can effectively develop and manage AI platforms.

To create a successful AI platform, it's essential to unify the system, process, and team design, which requires establishing clear goals and objectives, developing an architecture that accommodates the complexities of AI software, incorporating MLOps methodologies and best practices, and establishing clear roles and responsibilities for each team member, as well as effective communication channels and collaboration tools.

By following these best practices and adopting a flexible, interdisciplinary approach to building AI platforms, organizations can maximize the potential of AI technology and deliver innovative solutions to real-world problems.

### Key Takeaways

* AI software development requires a different approach than traditional software development due to creating algorithms that can learn and improve overtime like human cognitive systems.
* Unifying system, process, and team design is crucial for creating a successful AI platform.
* The ten stages of AI software development include model requirements, data collection, data cleaning and transformation, data labeling, feature engineering, model training, model evaluation, model deployment, model monitoring, and UI/UX development.
* MLOps is a crucial process to streamline the production and operationalization of AI systems. It involves the implementation of version control for models, automated testing, continuous integration and deployment (CI/CD) pipelines, model serving, model monitoring, and automated retraining.
* Aligning the MLOps process and the team using team topologies is essential for effective collaboration and communication. This involves organizing the team into stream-aligned, complicated subsystem, platform, enabling, and customer success teams.
* Developing AI software platforms involves setting up the development environment and infrastructure; implementing the data pipeline, model training, model serving, and monitoring components; building testing and validation pipelines; and developing user interfaces and integration interfaces.
* We can use the Carnegie Mellon CMM to measure AI software development process maturity, which includes five stages: initial, repeatable, defined, managed, and optimized.
* To ensure trustworthy and responsible AI, it is crucial to develop XAI mechanisms for root cause analysis (XAIOps), ensure transparency and explainability of the model's decision-making process, and apply active learning mechanisms to subside edge cases.
* When selecting technology stacks, teams can use the build vs. buy framework to determine which components to build and which to acquire externally.
* The team members in AI development include the product manager, subject matter experts, data labelers, front-end software engineers, machine learning scientists/data scientists, machine learning/MLOps/LLMOps engineers, data engineers, DevOps/infrastructure/back-end engineers, TechOps engineers, and customer success specialists.
* It is important to foster interdisciplinary teams, including data scientists/machine learning experts, machine learning engineers, data engineers, software developers, and domain experts, to ensure that all aspects of AI software development are considered and that models are developed with real-world applications in mind.

Footnotes[1](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn1\_source)

[https://link.springer.com/book/10.1007/978-3-030-13431-0](https://link.springer.com/book/10.1007/978-3-030-13431-0)

&#x20;[2](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn2\_source)

[https://openai.com/product](https://openai.com/product)

&#x20;[3](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn3\_source)

[https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)

&#x20;[4](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn4\_source)

[https://teamtopologies.com/](https://teamtopologies.com/)

&#x20;[5](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn5\_source)

[https://neptune.ai/blog/end-to-end-mlops-platforms](https://neptune.ai/blog/end-to-end-mlops-platforms)

&#x20;[6](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn6\_source)

[https://link.springer.com/article/10.1007/s10462-022-10246-w](https://link.springer.com/article/10.1007/s10462-022-10246-w)

&#x20;[7](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn7\_source)

[https://resources.sei.cmu.edu/asset\_files/technicalreport/1993\_005\_001\_16211.pdf](https://resources.sei.cmu.edu/asset\_files/technicalreport/1993\_005\_001\_16211.pdf)

&#x20;[8](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn8\_source)

[www.oreilly.com/library/view/designing-machine-learning/9781098107956/](http://www.oreilly.com/library/view/designing-machine-learning/9781098107956/)

&#x20;[9](https://learning.oreilly.com/library/view/ai-startup-strategy/9781484295021/html/522265\_1\_En\_8\_Chapter.xhtml#Fn9\_source)

[https://link.springer.com/book/10.1007/978-1-4842-7413-2](https://link.springer.com/book/10.1007/978-1-4842-7413-2)
