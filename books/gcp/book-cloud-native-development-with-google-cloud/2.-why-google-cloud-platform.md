# 2. Why Google Cloud Platform?

## Chapter 2. Why Google Cloud Platform?

> You can’t build a great building on a weak foundation.
>
> Gordon B. Hinckley

At the time of writing, Google Cloud Platform (GCP) holds the third place in the public cloud market, trailing behind Amazon Web Services (AWS) and Microsoft Azure. With AWS commanding a significant mindshare and Azure capitalizing on Microsoft’s expansive corporate presence, one might question the rationale behind opting for Google Cloud. Why not consider other players such as IBM Cloud, Oracle, or Alibaba?

One reason I choose Google Cloud for cloud native development is the integration of services. AWS famously has [two-pizza teams](https://oreil.ly/PG5NG) that work on each service independently. This produces a wide range of services quickly, often with overlapping capabilities. On the other hand, Google seems to put more emphasis on integration, having fewer services that work well end to end, making it easier to build the laboratory, factory, citadel, and observatory.

Although Google Cloud represents approximately 10% of the cloud market share, it powers 70% of tech unicorns at the time of writing. This disproportionate representation suggests that Google Cloud resonates with digital natives for valid reasons. AWS and Azure may host a multitude of traditional applications, but digital natives, unhindered by legacy infrastructure, favor a cloud native development style, and Google Cloud aligns better with this approach. In essence, Google Cloud is built by cloud native engineers for cloud native engineers, and this resonates with developers.

However, it’s important to note that many services discussed in this book also have equivalents in other public clouds. The techniques and considerations, therefore, can be adapted to other platforms. It’s a Herculean task to understand every feature and service of a single cloud, such as Google Cloud, let alone grasp multiple services across diverse cloud platforms.

In my experience, focusing on services built on open standards or those that have become de facto standards can be particularly beneficial. These services are universally accessible, both on-premises and across multiple clouds. Learning them once gives you the ability to apply them anywhere. Containers, Kubernetes, Knative, PostgreSQL, and HTTP are a few notable examples where Google Cloud’s support for standards shines.

If you are familiar with and favor these abstractions, applications will be more portable, and you will minimize “vendor lock-in.” This is where you become reliant on a particular provider’s service. Some cloud providers seek to minimize these concerns. Still, if suddenly they decide to double the price, discontinue service, or stop offering a service in a region you need to run your application, you are stuck. This means vendor lock-in should always be at least a consideration. I use the Google Cloud services that are widely available.

Ultimately, the real strength of Google Cloud lies in its robust foundational infrastructure, the hidden backbone built by Google’s engineers to run their global services. This strength truly sets Google Cloud apart from its competitors.

## Strong Foundations

Google Cloud data centers are purpose-built with proprietary power distribution, cooling, and networking. The compute hardware within them is also custom designed and standardized throughout.

Google uses the term _machine_ to refer to a unit of hardware and server for a piece of software that implements a service. As all hardware is standardized, any machine can run any server.

Machines are the smallest building block, with 10 machines assembled into a rack. Racks stand in a row. One or more rows make a cluster. A data center contains multiple clusters. Multiple data centers make a zone, and a region is then made up of three or four zones.

Each machine in a data center is linked together using a high-speed network fabric called Jupiter. Data centers are then connected using B4, a global software-defined network.

Even though Google Cloud is vast, think of it as thousands of standardized machines distributed around the globe, linked together by a fast network.

## Powerful Abstractions

What makes Google Cloud stand out is the software Google has built to manage the massive global pool of machines. Although the hardware Google uses is custom-designed, it is nothing special—simply hardware constructed to minimize the total cost of ownership. Given the sheer number of components, failures of machines and disks are frequent. The software introduced next manages hardware failures so that any problems are abstracted away.

### Borg

Whether you need to run serverless code for 100ms, need a virtual machine that runs indefinitely, or consume compute through a Google Cloud managed service, Borg will manage the compute. When you make a request, a job is sent to Borg that finds suitable machines to run tasks on. Borg will monitor each task, and if it malfunctions, it will be restarted or moved to a different machine. Borg inspired Kubernetes, so the concepts may be familiar.

However, as a user of Google Cloud, you will know nothing about Borg but will benefit from its abstraction. You request, directly or indirectly, the resources you require in terms of CPU cores and RAM. Borg fulfills everyone’s request behind the scenes, making the best utilization of the machines available and seamlessly working around any failures.

### Colossus

While machines have local disks, these are only used for temporary storage. For managing permanent storage, Google uses a system named Colossus.

Storage pools consist of spinning discs and flash disks of different capacities. Again, these are selected to minimize their total cost of ownership, so they can and will fail. Colossus sets out to work around any failures and fills the disks as optimally as possible, as any empty space is wasted capacity.

Colossus constantly rebalances where data is stored. Frequently accessed (hot) data is stored on the more expensive fast disks. Less frequently accessed (cold) data is on slower, cheaper disks. As with compute, this means the details of storage are abstracted away. As a user, or more accurately, a service requesting on your behalf, you request the bytes and performance characteristics (or input/output operations per second \[IOPS]) required, and Colossus takes care of it.

### Spanner

Colossus also forms the foundation of two core database abstractions that support petabytes of data. Bigtable is a petabyte-scale NoSQL database that is eventually consistent across regions. Spanner is a SQL-compatible database that offers strong consistency across regions. Google uses Spanner internally for many systems. For example, Google Photos stores metadata for 4 trillion photos and videos from a billion users in Spanner. Some public references are available in a [Spanner blog](https://oreil.ly/Xxzd6). These abstractions allow the decisions to be about the type of consistency and level of availability needed rather than the details of how it is achieved.

### Andromeda

Like Borg efficiently allocates compute resources, Andromeda manages network bandwidth over Google Cloud’s global network. This software-defined network ensures traffic from a service or user is routed most efficiently. Google Cloud is a single extensive network, and everything is software. Features like the global load balance or firewalls are just software configurations via an API rather than a physical device. This powerful feature defines how you want the network to appear with code alone.

An enormous benefit for me is having my development environment on the same Google network as my deployment environments with security between them. Gone are the days of having to transfer data over slow VPN connections.

### Combining Abstractions

Taken together, this combination of abstractions is powerful. Being able to request a unit of compute or a unit of storage and knowing that the contract will be met without having to worry about the capacity or reliability of hardware means work is done for you. Similarly, with networks, data replication, and security, being able to declare behavior and being confident that requirements will be met is a liberating way of working. It gets better as Google Cloud combines these building blocks to make higher-level services so a developer can focus on the code, not the infrastructure.

## Why Not DIY?

It can be tempting to use the infrastructure as a service (IaaS) of Google Cloud and treat it like a normal data center with virtual machines, disks, and networks, and run vendor’s products as you would on-premises. Effectively, this is resorting to the lowest common denominator to remain cloud agnostic. This is particularly popular when deploying databases and Kubernetes platforms like OpenShift, and it will work. You will have to pay for licenses and people to operate the services to go down that road, though. This may be practical for a large organization, but it may be no cheaper than an on-prem data center adding complexity for little benefit.

However, I hope by explaining the abstractions that Google Cloud provides, you will see how you are missing out if you do this. Google’s abstractions allow you to work at a higher level and leverage many years of Google engineers’ work. Moreover, you would also be missing out on the managed services Google provides on top of the foundations that raise the abstraction even further. Being able to take advantage of the higher levels of abstraction is what cloud native development is all about.

As an individual developer, you don’t have the choice of doing it yourself. If you have followed Kelsey Hightower’s [“Kubernetes the Hard Way”](https://oreil.ly/pcK7K), for example, you will have some idea of the effort involved. That is why using Google Cloud can be seen as a powerful toolkit to build what you want without needing an organization behind you. However, suppose you are developing as part of a large organization and adopting the same cloud native approach. In that case, there is no reason for complexity and cost to rise, which is how a traditional organization can keep up with any digital-native competitor.

If you work for an enterprise organization, you may have access to a private cloud platform like Red Hat OpenShift, VMWare Tanzu, or even Google Anthos, Google Cloud’s on-premises offering. Like Google Cloud, all these platforms’ applications are container based. Although tools and services vary, the principles of cloud native development I describe for Google Cloud in this book will still be applicable. The difference is that these solutions require a significant initial investment. If you are an individual developer, they are unlikely to be available. Google Cloud, however, has a much lower barrier to entry, especially if you take advantage of the free trial. For an individual developer, it is a much more accessible way to learn.

## Summary

Google Cloud stands out in cloud native development due to its focus on service integration and support for open standards, minimizing vendor lock-in. It boasts a robust infrastructure, built on custom hardware and high-speed networking. Powerful software abstractions like Borg, Colossus, Spanner, and Andromeda manage compute, storage, databases, and networking, respectively, freeing developers to focus on coding rather than infrastructure. A do-it-yourself approach, treating GCP as a typical data center, limits the benefits of these high-level abstractions and may lead to extra costs. Leveraging GCP’s cloud native principles is beneficial for individual developers and large organizations alike.

Google Cloud provides the foundations for building cloud native applications. In [Chapter 3](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch03.html#chapter\_03), you will look at the characteristics of a cloud native application and the tools, techniques, and technologies that support them.
