# 8. Project 4: Profile Service With Pub/Sub And Firestore

## Chapter 8. Project 4: Profile Service with Pub/Sub and Firestore

This chapter delves into the creation of a cloud native, event-driven microservice: the profile service. This profile service will build and continuously update user profiles based on changing facts from the fact service. The architecture will employ Google Pub/Sub for event notifications, Firestore as a serverless database to store user profiles, and Cloud Run for hosting the service.

**NOTE**

The code for this chapter is in the [`profile-service` folder of the GitHub repository](https://oreil.ly/m-4le).

## Requirements

Let’s go straight into the requirements.

### User Story

[Figure 8-1](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch08.html#p4-postit) is the user story you will be focusing on.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098145071/files/assets/cdgc_0801.png" alt="" height="324" width="828"><figcaption></figcaption></figure>

**Figure 8-1. Project 4 user story**

### Elaborated Requirements

It is safe to assume that the system has many users and most are not going to make frequent changes to their skills. This means it is more likely for there to be a request for a profile than for facts to be edited.

You can take advantage of this by storing the profile indefinitely once it’s generated and only updating it when a change is made to the facts. This has the advantage of not needing to access the PostgreSQL database every time a profile is requested, meaning you can keep the instance size small and reduce the cost of the facts service.

Therefore, the requirements are as follows:

* The service should be triggered every time there’s a change in the user facts stored in the fact service.
* The service should generate a user profile as a single JSON document that can be stored and later retrieved on demand.
* Since the profile service is triggered by fact changes and does not require an immediate response to the caller, it can operate asynchronously.
* The service must be able to scale to meet the demands of the system, managing large numbers of profile requests and updates.
* The service should be designed for high availability, ensuring that it’s always ready to respond to change notifications and serve profiles.
* The service should be low cost and require minimal maintenance, leveraging serverless technology to minimize the need for server management and capacity planning.

By designing the service to meet these requirements, you can ensure it will efficiently and reliably manage user profiles, providing up-to-date information for users to share. The remainder of this chapter will guide you through how to build and deploy a service that fulfills these needs.

## Solution

Again, it is possible to produce a low-cost solution to these requirements using Google Cloud Services.

## Summary of Services

To build the profile service that meets these requirements, you are going to make use of a few key Google Cloud services. Let’s take a closer look at each of them.

### Google Firestore

Firestore is a NoSQL document database that is built for automatic scaling, high performance, and ease of application development. Given the small amounts of data you’ll be storing for each user profile, Firestore is an excellent choice for your needs. Its serverless nature allows it to scale automatically according to demand, making it highly available and fault-tolerant.

While Firestore does require usage of a Google Cloud-specific API, and thus might not be ideal for all projects, it fits the current use case perfectly. The fact that it requires minimal configuration compared to other database services, such as Cloud SQL, significantly simplifies the maintenance of your service.

### Google Pub/Sub

This service needs to know when a change has been made to the facts provided by a user. You can get the fact service to report changes by publishing an event to Google Pub/Sub.

Google Pub/Sub is a fully managed event ingestion and delivery system. It supports both event streaming similar to Apache Kafka and queue-based messaging similar to a message queue like RabbitMQ. It is a one-stop event and messaging system. This differs from AWS, for example, where queue (SQS), notifications (SNS), and event bus (Amazon EventBridge) features are provided by separate services. It is a highly available and fault-tolerant service that is scalable, serverless, and cost-effective.

In this project, you will be using Pub/Sub to push a notification to the profile service of changes to facts. The profile service will then update the profile of the user.

### Cloud Run

For your profile service, you’ll write the code in Go and host it on Cloud Run. Go’s quick start-up time makes it ideal for situations where a service needs to start quickly in response to an event, do its work, and then shut down. This is an excellent use case for Cloud Run, which can start and stop instances rapidly, charging only for the time during which the service is running.

With these services, you will have a profile service that is responsive to changes, highly available, and cost-effective. Let’s dive into how to use these services to build the solution.

## Implementation

It is time to get hands-on and implement the service.

### Storing Data in Firestore

The profile service uses Firestore, or more precisely Firestore in Firestore Native mode, to store profiles, each profile being a JSON document. Firestore is part of Firebase and was originally designed for simultaneous connection from many mobile clients. The other mode available is Datastore mode which supports Datastore, a previous Google Cloud service.

Ensure you are in the correct project with:

```
gcloud config set project $PROJECT_ID
```

Then, to use Firestore, you need to enable the Firestore API with this command:

```
gcloud services enable firestore.googleapis.com
```

Create the Firestore database with `--type=firestore-native` to use Firestore Native mode:

```
gcloud alpha firestore databases create --location=$REGION --type=firestore-native
```

Notice that this command has the alpha flag. This is because Firestore, like Firebase authentication, is not fully integrated with Google Cloud, and the command is not yet available in the main gcloud commands at the time of writing.

It used to be that you could only have one Firestore or Datastore database per project, and if you wanted to use Firestore in a different project, you would need to create a new project. In the case of this service, only one database is needed, so the default database is being used. However, during the writing of this book, the restriction was lifted and it is now possible to create multiple Firestore databases in a single project.

### Sending Events to Pub/Sub

The next thing to do is revisit the earlier fact service and add the ability to publish a message to Pub/Sub when a fact is added or deleted. To do this, you need to include the Spring Cloud GCP Pub/Sub Starter and the Spring Integration in the _pom.xml_ file:

```
<dependencies>
...
    <dependency>
      <groupId>com.google.cloud</groupId>
      <artifactId>spring-cloud-gcp-starter-pubsub</artifactId>
    </dependency>
    <dependency>
      <groupId>org.springframework.integration</groupId>
      <artifactId>spring-integration-core</artifactId>
    </dependency>
...
</dependencies>
```

Google Pub/Sub is a robust, fully managed service that enables real-time messaging between applications. However, when integrating Pub/Sub into your Spring applications, you might not want to deal with the specifics of the Pub/Sub API directly. This is where the Spring Cloud GCP library comes into play.

Spring Cloud GCP provides a channel adapter for Spring Integration, allowing Pub/Sub to be used as a message channel in your application. What this means is that you can interact with Pub/Sub using familiar Spring Integration paradigms, effectively abstracting away the underlying Pub/Sub API details. The beauty of this approach lies in its flexibility—while your application benefits from Pub/Sub, it isn’t tightly coupled to it. This makes your code more portable and easier to maintain.

In practical terms, you can leverage the `@ServiceActivator` annotation from Spring Integration to define a method that will act as a message handler. This method is triggered when a message arrives on the subscribed channel.

For instance, if you have a Pub/Sub topic named `factchanged`, the name of this topic can be supplied by an environment variable (`pubsub.topic.factchanged`). This environment variable is set in the _env.yaml_ file used during the Cloud Run deployment.

In the fact service in the code that accompanies this book, the following code has been added to `FactApplication` to enable this:

```
  @Bean
  @ServiceActivator(inputChannel = "pubsubOutputChannel")
  public MessageHandler messageSender(PubSubTemplate pubsubTemplate) {
    return new PubSubMessageHandler(pubsubTemplate, env.getProperty("pubsub.topic.factchanged"));
  }

  @MessagingGateway(defaultRequestChannel = "pubsubOutputChannel")
  public interface PubsubOutboundGateway {
    void sendToPubsub(String payload);
  }
```

Here, a `MessageHandler` bean is being defined, which will handle outgoing messages to the Pub/Sub service. The `@ServiceActivator` annotation is used to specify that this handler will be listening on the `pubsubOutputChannel` for any messages.

The MessageHandler is configured with a PubSubTemplate, which is a helper class provided by the Spring Cloud GCP library to interact with Pub/Sub. The topic to which the messages will be sent is set to the value of the `pubsub.topic.factchanged` environment variable.

Additionally, a `PubsubOutboundGateway` interface is defined. This interface is marked with the `@MessagingGateway` annotation, which indicates it’s a gateway to the messaging system. The method `sendToPubsub(String payload)` will send a message to the `pubsubOutputChannel`, effectively pushing the message to the configured Pub/Sub topic.

In the code then, you can use the `PubsubOutboundGateway` to send a message to Pub/Sub. For example, following is the code added to the `FactController` to send a message. This is called when a fact is added or deleted, sending an updated list of all facts for the user serialized as JSON.

Then the following method has been added to the `FactController` class:

```
  public void factsChanged(Fact fact) {
    List<Fact> facts = factRepository.findByUser(fact.getUser());
    FactsChanged factsChanged = new FactsChanged(fact.getUser(), facts, OffsetDateTime.now());
    try {
      String jsonString = objectMapper.writeValueAsString(factsChanged);
      logger.info("Sending message to Pub/Sub: {}", jsonString);
      messagingGateway.sendToPubsub(jsonString);
    } catch (JsonProcessingException e) {
      logger.error("Error serializing message send to Pub/Sub: {}", e.getMessage());
    }
  }
```

This method is called when a fact is added or deleted. It fetches the updated list of facts for the user and creates a new `FactsChanged` object. This object is then converted into a JSON string and sent to the Pub/Sub topic through the `sendToPubsub(String payload)` method of the `PubsubOutboundGateway`. If there’s an error in the JSON serialization process, it will be logged.

This approach allows your application to send messages to Pub/Sub without being tightly coupled to Google Cloud–specific implementations, making your code more portable and easier to maintain.

### Configuring Pub/Sub

While the fact service can now theoretically deploy to a Pub/Sub topic, that topic does not yet exist. To use Pub/Sub, you first need to enable the Pub/Sub API with this command:

```
gcloud services enable pubsub.googleapis.com
```

Now create an environment variable for the name of the topic you want to create (e.g., `fact-changed`):

```
export FACT_CHANGED_TOPIC=[FACT_CHANGED_TOPIC]
```

You can now create a topic to send the “fact-changed” event to:

```
gcloud pubsub topics create $FACT_CHANGED_TOPIC
```

It is also a good idea to create a second topic to act as a dead letter queue. A dead letter queue is a place to capture messages that can’t be delivered. This is useful as it means you can retry sending the message later or use the failed messages for debugging if there was a problem with the message content. You can create a dead letter topic like this:

```
gcloud pubsub topics create $FACT_CHANGED_TOPIC-deadletter
```

With topics set up, you now need to connect them to the services with those services.

### Configuring Service Accounts

As should be familiar by now, you need to add permissions to the service account that the fact service uses to allow it to publish messages to Pub/Sub. In this case, you need to add the `roles/pubsub.publisher` role to the service account like this:

```
gcloud pubsub topics add-iam-policy-binding ${FACT_CHANGED_TOPIC} \
  --member=serviceAccount:${FACT_SERVICE_SA}@${PROJECT_ID}.iam.gserviceaccount.com \
  --role=roles/pubsub.publisher
```

**TIP**

In general, if something isn’t working in Google Cloud, a good first step is to check for missing permissions on a service account, especially if you are using a service account other than the default. You can do this by going to the IAM & Admin section of the console and checking the permissions for the service account. Checking logs for Cloud Run for the service will also help to identify any issues.

You will also need a service account for the profile service itself. As the service will have events pushed to it, it does not need any permissions to access PubSub; however, it will need permissions to read and write to Firestore and to write logs.

Create an environment variable to hold a service account name (e.g., `profile-service-sa`):

```
export PROFILE_SERVICE_SA=[PROFILE_SERVICE_SA]
```

Then create the service account with the following command:

```
gcloud iam service-accounts create ${PROFILE_SERVICE_SA} \
  --display-name "${PROFILE_SERVICE_NAME} service account"
```

Give the service account permission to write logs to Cloud Logging:

```
gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member=serviceAccount:$PROFILE_SERVICE_SA@$PROJECT_ID.iam.gserviceaccount.com \
  --role=roles/logging.logWriter
```

Also, give the service account permission to read and write to Firestore:

```
gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member=serviceAccount:$PROFILE_SERVICE_SA@$PROJECT_ID.iam.gserviceaccount.com \
  --role=roles/datastore.user
```

You now have a service account to use when deploying the profile service a little later.

### Receiving Pub/Sub Events

With the fact service now set up to publish events about user fact changes, let’s focus on the profile service. The profile service’s task is to subscribe to the fact service’s topic and update the relevant user profile when a message is received.

You could consider using the Go Pub/Sub client to pull messages from the topic, but it’s not ideal for this setup. Why? Because it would require the Cloud Run service to be run all the time, causing unnecessary resource consumption and increased costs. It could be scheduled to run at certain times, but this would mean there would be a significant delay in updating profiles.

Instead, you can adopt a more cloud native approach. Since the profile service is another Cloud Run service, you can set up an HTTP endpoint for Pub/Sub to push messages. When Pub/Sub pushes a message to this endpoint, it triggers an instance that processes the message in the HTTP request’s body. This approach relieves the profile service from maintaining a connection with Pub/Sub, allowing it to focus solely on updating user profiles. Furthermore, it optimizes resource usage as service instances are created and billed only when a message needs processing.

If you have created _.env_ files, use this command to apply the environment variable again:

```
set -a; source ../.env; source .env ;set +a
```

Create a file called _env.yaml_ from _env.yaml.template_, substituting values from your environment variable, including those set in the previous chapters:

```
envsubst < env.yaml.template > env.yaml
```

As with the skill service, Cloud Build will use a buildpack to create a container for the profile service and deploy it to Cloud Run in a single command:

```
gcloud run deploy $PROFILE_SERVICE_NAME --source . \
  --service-account $PROFILE_SERVICE_SA@$PROJECT_ID.iam.gserviceaccount.com \
  --env-vars-file=env.yaml \
  --allow-unauthenticated
```

Again, the environment variables the service needs (the project ID and the Service Name) are stored in the _env.yaml_ file.

With the service deployed, set the `PROFILE_SERVICE_URL` environment variable to the URL of the service, as you will need that to define where Pub/Sub should deliver events:

```
export PROFILE_SERVICE_URL=$(gcloud run services describe $PROFILE_SERVICE_NAME \
--format='value(status.url)')
```

You are now ready to create a subscription to the topic that the fact service is publishing. A subscription is a way of linking events with a service. This subscription will be configured to send messages to the profile service.

### Creating a Subscription

Even though messages are being published and the profile service is there waiting, nothing will happen until you create a subscription to the topic.

Create an environment variable for the name of the subscription to be created (e.g., `fact-changed-subscription`):

```
export FACT_CHANGED_SUBSCRIPTION=[FACT_CHANGED_SUBSCRIPTION]
```

At the moment, Pub/Sub will be able to invoke the Cloud Run profile service as it allows unauthenticated requests; however, you will turn this off later for security reasons. This means you need to create a service account for the subscription to use to be able to invoke the profile service. You can create the service account with this command:

```
gcloud iam service-accounts create ${FACT_CHANGED_SUBSCRIPTION}-sa \
  --display-name="${FACT_CHANGED_SUBSCRIPTION} service account"
```

Then give the service account the `roles/run.invoker` role to allow it to invoke the profile service:

```
gcloud run services add-iam-policy-binding $PROFILE_SERVICE_NAME \
--member=serviceAccount:${FACT_CHANGED_SUBSCRIPTION}-sa@${PROJECT_ID}.iam.gserviceaccount.com \
--role=roles/run.invoker
```

Now you are ready to create the subscription itself with this command:

```
gcloud pubsub subscriptions create ${FACT_CHANGED_SUBSCRIPTION} \
  --topic=${FACT_CHANGED_TOPIC} \                                                                   
  --push-endpoint=${PROFILE_SERVICE_URL}/factschanged \                                             
  --max-delivery-attempts=5 \                                                                       
  --dead-letter-topic=$FACT_CHANGED_TOPIC-deadletter \
  --push-auth-service-account=${FACT_CHANGED_SUBSCRIPTION}-sa@${PROJECT_ID}.iam.gserviceaccount.com 
```

[![1](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098145071/files/assets/1.png)](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch08.html#co\_project\_4\_\_profile\_service\_with\_\_\_span\_class\_\_keep\_together\_\_pub\_sub\_and\_firestore\_\_span\_\_CO1-1)

`--topic` is the name of the topic to which the fact service is publishing.

[![2](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098145071/files/assets/2.png)](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch08.html#co\_project\_4\_\_profile\_service\_with\_\_\_span\_class\_\_keep\_together\_\_pub\_sub\_and\_firestore\_\_span\_\_CO1-2)

`--push-endpoint` is the URL of the profile service with the `/factschanged` path appended. This is the URI where the profile service will accept messages.

[![3](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098145071/files/assets/3.png)](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch08.html#co\_project\_4\_\_profile\_service\_with\_\_\_span\_class\_\_keep\_together\_\_pub\_sub\_and\_firestore\_\_span\_\_CO1-3)

`--max-delivery-attempts` is set to 5. This means that if the profile service returns a non-2xx response code, Pub/Sub will retry sending the message up to five times.

[![4](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098145071/files/assets/4.png)](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch08.html#co\_project\_4\_\_profile\_service\_with\_\_\_span\_class\_\_keep\_together\_\_pub\_sub\_and\_firestore\_\_span\_\_CO1-4)

`--push-auth-service-account` is the service account you just created that the subscription will use to authenticate with the profile service.

This last setting is useful as it means that if the profile service is temporarily unavailable for any reason, the message will be retried later. However, after that, the message will be sent to the dead letter topic.

From now on, each time a message is received by the profile service, it will update the profile of the user. The profile service will also log the message it receives to the console. Each message is an invocation of the profile service and will be billed as such. That is why it is useful to limit the number of retries so it does not keep invoking the service forever. If you did notice that was happening, though, you can always delete the subscription while you debug, using:

```
gcloud pubsub subscriptions delete $FACT_CHANGED_SUBSCRIPTION
```

## Testing the Profile Service

To test the profile service, you can use the `gcloud pubsub` command to publish a message to the topic. This will trigger the profile service to update the profile of the user.

First, retrieve an ID token for the test user from Identity Platform:

```
export ID_TOKEN=$(curl "https://www.googleapis
.com/identitytoolkit/v3/relyingparty/verifyPassword?key=${API_KEY}" \
-H "Content-Type: application/json" \
--data-binary "{\"email\":\"${TEST_EMAIL}\",\"password\":\"${TEST_PASSWORD}\"
\"returnSecureToken\":true}" | jq -r '.idToken')
```

The token that is returned is a JSON Web Token (JWT). Encoded in it is the user ID. Normally, the server side would verify the signature with Identity Platform before trusting any information in it. However, you can extract the user ID locally and store it in a `$USER_ID` environment variable using a command like this, assuming you have `jq` installed, as mentioned in [Chapter 4](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch04.html#chapter\_04):

```
payload=$(echo $ID_TOKEN | cut -d"." -f2)
decoded=$(echo $payload | base64 -d 2>/dev/null || echo $payload | base64 -di)
export USER_ID=$(echo $decoded | jq -r .user_id)
```

The payload of Pub/Sub messages is JSON. You can build an example fact-changed event using the template in the _examples/fact-changed.json.template_ file:

```
envsubst < examples/fact-changed.json.template > examples/fact-changed.json
```

Now publish the example fact-changed event for the test user using:

```
gcloud pubsub topics publish $FACT_CHANGED_TOPIC --message "$(cat examples/fact-changed.json)"
```

You can then check the log for the profile service to see the message it received:

```
gcloud beta run services logs read $PROFILE_SERVICE_NAME
```

You will see a POST with a 200 status to the `/factschanged` path like this:

```
2023-04-24 19:58:37 POST 200 https://profile-builder-j7n5qulfna-uc.a.run.app/factschanged
```

Then a log message that the profile has been updated like this:

```
Updated profile: &{CPK4AwHuxTX9OOuAirPCTwcdTy63 Profile [Python] [JavaScript] [] []}
```

You can also check the Firestore database to see that the profile has been updated.

The URL of the console includes `-default-`, as you will be using the default database:

```
open \
"https://console.cloud.google.com/firestore/databases/-default-/ ↩
data/panel/profiles?project=${PROJECT_ID}"
```

You can do this by going to the Firestore console and selecting the `users` collection. You should see a document with the `id` of the user you published the message for. The document should have a `facts` field with the fact you published.

You can also retrieve a profile for the current user. You can then use this token to access the API:

```
curl -X GET -H "Authorization: Bearer ${ID_TOKEN}" ${PROFILE_SERVICE_URL}/api/profiles/me
```

This will return a JSON file representing the profile for the test user with the facts added:

```
{"User":"CPK4AwHuxTX9OOuAirPCTwcdTy63","Name":"Profile","PhotoURL":"","Interested":["Python"],
"Learning":["JavaScript"],"Using":null,"Used":null}
```

If this were a user with a profile like Google Cloud, the code would also retrieve the real name of the user and even a URL to their photo to show in the profile. You will learn how to do this in [Chapter 11](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch11.html#chapter\_11).

## Evaluation

Let’s evaluate the solution in terms of cost.

Overall, this is a low-cost solution; it is taking good advantage of cloud native services. The costs are broken down as follows.

### Firestore

Firestore is a relatively cheap way to store data, as you are not paying for compute resources and are only storing small amounts of data. Billing is based on the following:

* The number of documents you read, write, and delete
* The number of index entries matched by aggregation queries
* The amount of storage that your database uses, including overhead for metadata and indexes
* The amount of network bandwidth that you use

However, there are generous free tiers for all of these, and you will need to have over 50,000 reads and 20,000 writes per day and store over 1 GB of data before the costs start kicking in. As this service is storing small profiles, the cost of storing the data is likely to be negligible.

### Cloud Run

The cost of Cloud Run is also likely to be small; the service is written in Go with minimal resource requirements and only executes for a small amount of time in response to an event. As the free tier allows for 2 million requests per month and 400,000 GB seconds per month, the cost of running the service is likely to be negligible.

### Cloud Pub/Sub

Pub/Sub has the following components in its cost:

* Throughput costs for message publishing and delivery
* Egress costs associated with throughput that crosses a Google Cloud zone or region boundary
* Storage costs for snapshots, messages retained by topics, and acknowledged messages retained by subscriptions

As you are not retaining messages or crossing boundaries, the cost of using Pub/Sub is limited to the costs for message publication and delivery.

The cost of message publication is based on the number of messages published and the size of the messages. The free tier for Pub/Sub is 10GiB per month, so as it stands, the volume of messages would need to be considered before this service-occurred cost is high.

## Summary

Although a simple example, this is representative of true cloud native service. The service is event-driven and stateless. It is written in a cloud native language (Go) and uses a cloud native storage service (Firestore). It also uses a serverless runtime (Cloud Run), and it is not running all the time and only executes when an event is triggered. The service is also scalable; it is scaled up or down as required. As a result, the service is highly available and fault-tolerant, but also so cost-effective that it is almost free. This is the type of service that made me excited when I first started using the cloud—services that can be run for next to nothing but can perform in a way that would have previously needed a lot of hardware.

For this project, you used the following services directly:

* Cloud Pub/Sub is used to store the profiles.

With all the services in place, in [Chapter 9](https://learning.oreilly.com/library/view/cloud-native-development/9781098145071/ch09.html#chapter\_09), you will be bringing them together into a single API and providing a UI interface for users to interact with.
