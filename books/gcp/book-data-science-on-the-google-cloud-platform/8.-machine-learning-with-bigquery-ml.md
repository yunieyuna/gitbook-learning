# 8. Machine Learning With Bigquery ML

## Chapter 8. Machine Learning with BigQuery ML

BigQuery is a serverless, highly scalable data warehouse. Amazingly enough, it is also an excellent machine learning platform. This combination is very convenient since you can do machine learning without having to extract data out of the data warehouse. If your organization has a lot of privacy-sensitive or confidential data, not having extracts of data floating around in people’s projects is important for security. The auditability that BigQuery provides out of the box means that you know exactly who created the model and which data was used in which model.

Given the scalability, power, ease-of-use, and security of BigQuery ML, I recommend using it, rather than Spark, for the first machine learning model you should build when working with tabular data. In fact, as you will see in this chapter, you can get best-in-class accuracy, explainability, and prediction capabilities using BigQuery ML. Because of its connections to Vertex AI, it can be your production machine learning framework also.

All of the code snippets in this chapter are available in the folder [_08\_bqml_ of the book’s GitHub repository](https://github.com/GoogleCloudPlatform/data-science-on-gcp). See the _README.md_ file in that directory for instructions on how to do the steps described in this chapter.

## Logistic Regression

Let’s start where we left off in [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml)—recall that we trained a logistic regression model, added the airport code, and overwhelmed Spark in the process. So, let’s start by replicating the last working model that we had. We trained the logistic regression model on three features: departure delay, taxi-out time, and distance.

The first step in BigQuery ML is to create the training dataset. We want the three features and the label, so let’s use SQL to craft the dataset just the way we want it:

```
SELECT
  IF(arr_delay < 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
FROM dsongcp.flights_tzcorr f
WHERE
  f.CANCELLED = False AND
  f.DIVERTED = False
LIMIT 5
```

The `SELECT` statement pulls the required fields, taking care to not train on flights that were canceled or diverted. The result consists of the four columns we care about:

| `Row` | `ontime` | `dep_delay` | `taxi_out` | `distance` |
| ----- | -------- | ----------- | ---------- | ---------- |
| `1`   | `ontime` | `-5.0`      | `10.0`     | `399.0`    |
| `2`   | `late`   | `33.0`      | `13.0`     | `1046.0`   |
| `3`   | `ontime` | `-3.0`      | `8.0`      | `95.0`     |
| `4`   | `ontime` | `5.0`       | `9.0`      | `201.0`    |
| `5`   | `ontime` | `-4.0`      | `5.0`      | `204.0`    |

Creating a logistic regression model in BigQuery ML is as simple as running the following query:[1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn155)

<pre><code><strong>CREATE OR REPLACE MODEL dsongcp.arr_delay_lm
</strong><strong>OPTIONS(input_label_cols=['ontime'],
</strong><strong>        model_type='logistic_reg')AS
</strong>SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
FROM dsongcp.flights_tzcorr f
WHERE
  f.CANCELLED = False AND
  f.DIVERTED = False
</code></pre>

We are creating a logistic regression model where the label column is called `ontime`, and the remaining columns will be used as input features to the model. BigQuery ML will take care of splitting the data (randomly) and carrying out evaluation on the withheld dataset.

The resulting model parameters will be stored in a BigQuery model object called `arr_delay_lm` in the dataset `dsongcp`.

### Presplit Data

In [Chapter 5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch05.html#interactive\_data\_exploration\_with\_verte), we discussed why we don’t want to randomly split the flight data—we need to avoid having correlated flights on the same day split between training and test datasets. That’s why we presplit the data and created a table that specifies which days should be used for training and which days for evaluation.

We can explicitly tell BigQuery ML to use one of our columns in the training dataset to split the data. Let’s add that column to our `SELECT` statement as a Boolean value by joining the flight data against the table of prespecified training days:

<pre><code>SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
<strong>  IF(is_train_day = 'True', False, True) AS is_eval_day
</strong>FROM dsongcp.flights_tzcorr f
<strong>JOIN dsongcp.trainday t
</strong><strong>ON f.FL_DATE = t.FL_DATE
</strong>WHERE
  f.CANCELLED = False AND
  f.DIVERTED = False
LIMIT 5
</code></pre>

It returns:

| `Row` | `ontime` | `dep_delay` | `taxi_out` | `distance` | `is_eval_day` |
| ----- | -------- | ----------- | ---------- | ---------- | ------------- |
| `1`   | `ontime` | `-5.0`      | `10.0`     | `399.0`    | `true`        |
| `2`   | `late`   | `33.0`      | `13.0`     | `1046.0`   | `false`       |
| `3`   | `ontime` | `-3.0`      | `8.0`      | `95.0`     | `false`       |
| `4`   | `ontime` | `5.0`       | `9.0`      | `201.0`    | `true`        |
| `5`   | `ontime` | `-4.0`      | `5.0`      | `204.0`    | `false`       |

The fifth column can now be used to tell BigQuery which rows to withhold for evaluation, i.e., when this column is _TRUE_ the corresponding row is reserved for evaluation and not used for training. This involves specifying a custom data split method:

<pre><code>CREATE OR REPLACE MODEL dsongcp.arr_delay_lm
<strong>OPTIONS(input_label_cols=['ontime'], 
</strong><strong>        model_type='logistic_reg', 
</strong><strong>        data_split_method='custom',
</strong><strong>        data_split_col='is_eval_day')
</strong>AS

SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
  IF(is_train_day = 'True', False, True) AS is_eval_day
...
</code></pre>

### Interrogating the Model

When we run the preceding query, BigQuery trains a logistic regression model and puts the weights into the model `arr_delay_lm`. We can obtain the training error (called the loss) as the model is being trained, or even afterwards by querying the result of the special function `ML.TRAINING_INFO`:

```
SELECT * FROM ML.TRAINING_INFO(MODEL dsongcp.arr_delay_lm) 
  
```

This retrieves the loss on the training dataset and on the evaluation dataset iteration-by-iteration:

| `training_run` | `iteration` | `loss`     | `eval_loss` | `learning_rate` | `duration_ms` |
| -------------- | ----------- | ---------- | ----------- | --------------- | ------------- |
| `0`            | `19`        | `0.000003` | `0.000004`  | `104857.6`      | `3306`        |
| `0`            | `18`        | `0.000007` | `0.000007`  | `52428.8`       | `3350`        |
| `0`            | `17`        | `0.000013` | `0.000012`  | `26214.4`       | `2941`        |
| `0`            | `16`        | `0.000027` | `0.000020`  | `13107.2`       | `2921`        |

We can obtain the weights themselves by calling `ML.WEIGHTS`:

```
SELECT * FROM ML.WEIGHTS(MODEL dsongcp.arr_delay_lm) 
```

Because logistic regression is a linear model, we get one weight for each input, plus an intercept term:

| `processed_input` | `weight`    |
| ----------------- | ----------- |
| `dep_delay`       | `-0.132984` |
| `taxi_out`        | `-0.121715` |
| `distance`        | `0.000223`  |
| `__INTERCEPT__`   | `4.762572`  |

However, there is usually no point to getting just the weights. Instead, what we want is the predicted value for some set of inputs. To carry out prediction, we could directly call `ML.PREDICT`:

```
SELECT * FROM ML.PREDICT(MODEL dsongcp.arr_delay_lm,
                        (
SELECT 12.0 AS dep_delay, 14.0 AS taxi_out, 1231 AS distance
                        ))
 
```

While we can use `ML.PREDICT` to actually carry out predictions, the predictions will be subject to the typical BigQuery latency of a second or so. So, `ML.PREDICT` is typically used for batch predictions over large datasets. For online prediction (i.e., exposing the prediction service to a microservice using REST), we can extract the model as a TensorFlow model and deploy it into Vertex AI.

### Evaluating the Model

We can look at the model evaluation by going to the BigQuery Evaluation tab and moving the threshold slider bar as close to 0.7 as possible (see [Figure 8-1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#model\_evaluation\_tab\_in\_the\_bigquery\_co)).

Alternatively, we can evaluate the model by calling `ML.EVALUATE` in SQL. BigQuery will evaluate the model on the withheld data (where `is_train_day` is False), but use a threshold of 0.5:

<pre><code>SELECT * 
<strong>FROM ML.EVALUATE(MODEL dsongcp.arr_delay_lm)
</strong></code></pre>

Unfortunately, in order to change the threshold to 0.7, we have to also explicitly provide the data to evaluate over. So we do:

<pre><code>SELECT * 
<strong>FROM ML.EVALUATE(MODEL dsongcp.arr_delay_lm,
</strong>                 (
                     
SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance
FROM dsongcp.flights_tzcorr f
JOIN dsongcp.trainday t
ON f.FL_DATE = t.FL_DATE
WHERE
  f.CANCELLED = False AND
  f.DIVERTED = False AND
<strong>    is_train_day = 'False'
</strong>                     
                 ),
<strong>                 STRUCT(0.7 AS threshold))
</strong></code></pre>

The resulting evaluation statistics are:

| `precision` | `recall`   | `accuracy` | `f1_score` | `log_loss` | `roc_auc`  |
| ----------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| `0.964337`  | `0.956535` | `0.935174` | `0.96042`  | `0.167233` | `0.956248` |

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0801.png" alt="" height="700" width="600"><figcaption></figcaption></figure>

**Figure 8-1. Model Evaluation tab in the BigQuery console.**

The precision is how often the model is right when it reports a flight as being on time, while the recall is the fraction of on-time flights correctly classified. The receiver operating characteristic (ROC) is a threshold-independent measure of classifier performance.

We can use `ML.PREDICT` to actually carry out predictions in case we want to compute some other metric. For example, the root mean squared error (RMSE) can be computed as:

<pre><code>WITH predictions AS (
SELECT 
  *
FROM ML.PREDICT(MODEL dsongcp.arr_delay_lm,
        ... )


SELECT 
   SQRT(SUM((IF(ontime = 'ontime', 1, 0) - p.prob) * 
            (IF(ontime = 'ontime', 1, 0) - p.prob))
                /COUNT(*)) AS rmse
<strong>FROM predictions, UNNEST(predicted_ontime_probs) p
</strong>WHERE p.label = 'ontime'
</code></pre>

The preceding query pulls out the probability field from the predictions (it’s an array, one for each category, hence the `UNNEST`) and uses it to compute the RMSE. The resulting RMSE was 0.2131.

Note that we cannot compare this number 0.2131 against the RMSE numbers from the previous chapter because they are computed on different datasets. In Spark, we did not compute the RMSE on the independent evaluation dataset because it would have been too slow to load in two datasets, one for training and the other for evaluation.

### Scale and Simplicity

We ended [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml) by saying that the Spark model could not handle the addition of a categorical variable corresponding to an airport because one-hot encoding the airport results in hundreds of new features. To showcase the scalability of BigQuery, let’s add _two_ such fields, the origin and destination airport:

<pre><code>CREATE OR REPLACE MODEL dsongcp.arr_delay_airports_lm
OPTIONS(input_label_cols=['ontime'],
        model_type='logistic_reg',
        data_split_method='custom',
        data_split_col='is_eval_day') AS
SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
<strong>  origin,
</strong><strong>  dest,
</strong>  IF(is_train_day = 'True', False, True) AS is_eval_day
FROM dsongcp.flights_tzcorr f
JOIN dsongcp.trainday t
ON f.FL_DATE = t.FL_DATE
WHERE
  f.CANCELLED = False AND 
  f.DIVERTED = False
</code></pre>

The model that includes the airport information has an RMSE of 0.2098, which is an improvement over the original model.

BigQuery handles the airport fields without any issues. Had I not tried this in Spark and failed, I wouldn’t even have known that including the airport as an input is a challenging undertaking. Notice also that including the airport field didn’t require me to do any of the careful handling of one-hot variables and vocabularies that we needed in Spark. With the help of BigQuery, using a categorical variable was as transparent and straightforward as using a numeric variable.

The scale and simplicity of BigQuery ML make it one of my favorite products in Google Cloud.

## Nonlinear Machine Learning

What’s the point of a scalable, simple machine learning service if it limits you to just linear models? Fortunately, BigQuery ML is not limited to just linear regression and classification models. You can train deep neural networks, forecast time series, and create recommender systems. You can also use gradient boosted trees.

### XGBoost

When it comes to classification models on structured data, one of the best performing techniques is XGBoost (see sidebar). To use this method instead of logistic regression, all that we have to do is to change the `model_type` in the `CREATE MODEL` statement:[2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn156)

<pre><code>CREATE OR REPLACE MODEL dsongcp.arr_delay_airports_xgboost
OPTIONS(input_label_cols=['ontime'], 
<strong>        model_type='boosted_tree_classifier',
</strong>        data_split_method='custom',
        data_split_col='is_eval_day')
AS

SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
  origin,
  dest,
  IF(is_train_day = 'True', False, True) AS is_eval_day
FROM dsongcp.flights_tzcorr f
JOIN dsongcp.trainday t
ON f.FL_DATE = t.FL_DATE
WHERE
  f.CANCELLED = False AND 
  f.DIVERTED = False
</code></pre>

That’s it! No other changes are needed. Ten minutes later, we have a shiny new ML model. The underlying model is now much more complex, but we can use it in the same way that we used the linear model—by calling `ML.EVALUATE` and `ML.PREDICT`.

**WHAT IS XGBOOST?**

[XGBoost](https://oreil.ly/jmQLH) is a gradient boosting algorithm that creates an ensemble of decision trees. That’s quite a word salad, so let’s unpack it a bit.

A _decision tree_ is a set of if-then statements. For example, the rule: if the departure delay is 10 minutes or more, then if the distance is 1,000 miles or more, whether the flight will be on time can be represented as part of a decision tree (see [Figure 8-2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#decision\_tree\_based\_on\_two\_variables\_le)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0802.png" alt="" height="584" width="600"><figcaption></figcaption></figure>

**Figure 8-2. Decision tree based on two variables (departure delay and distance).**

The preceding decision tree consists of three such if-then rules, one for each of the leaves of the tree:

* If the departure delay is less than 10 minutes, the flight will be on time.
* If the departure delay is 10 minutes or more, then if the distance is less than 1,000 miles, the flight will be late.
* If the departure delay is 10 minutes or more, then if the distance is 1,000 miles or more, the flight will be on time.

A machine learning algorithm tunes the variables (`dep_delay`, `distance`) and thresholds (10 and 1,000) for the decision tree based on the data. The more if-then statements there are, the greater the _depth_ of the tree.

It is possible to create multiple such trees by choosing different variables and thresholds. Thus, it is possible to create an _ensemble of decision trees._ We can then average the result of all these trees to come up with a final output. Why is this useful? Because some decision trees might be especially useful for nighttime flights, other decision trees may be very accurate for flights from New York, and so on. Getting a fuller picture of what various decision trees would say for a given flight can give us more opinions and the possibility of a more accurate decision in the end.

Can we employ a strategy in choosing the trees that form this ensemble? Yes. One approach is called _boosting_. The idea is to choose a tree and find the examples that the tree classifies incorrectly. The next decision tree is then trained so that it does better on the misclassified examples—we can do this by artificially boosting their importance.

Mathematically, boosting misclassified examples is equivalent to weighting the gradient associated with those examples. Hence, we end up with a gradient boosting algorithm that creates an ensemble of decision trees: XGBoost.

The training takes longer than logistic regression (12 minutes rather than 6 minutes) because it’s a more complex model. The RMSE that we now get is 0.2072, an improvement over the logistic regression score of 0.2098.

### Hyperparameter Tuning

One of the reasons that BigQuery ML is so nice is that it hides a lot of the knobs or _hyperparameters_ of the model. The default choices usually work pretty well, but there is usually some room for improvement if we are willing to expend compute cycles searching for potentially better choices.

There are two hyperparameters that I’m particularly interested in exploring:

* BigQuery reduces the impact of outliers by imposing a penalty on large weight values. This is called _L2 regularization_, and the intuition underlying the technique is as follows: when you have a very complex model with lots and lots of free parameters (“weights”) and you have an outlier, the model can force the outlier to have the correct label by twisting and warping the optimization space in the vicinity of the outlier. This twisting and warping leads to large weight values (the mathematics behind this gets a little hairy, so let’s take this on trust). By imposing a penalty on large weights, the model avoids getting drawn into this trap. However, the relative amount of L2 regularization that works is highly dependent on the dataset and how significant and prevalent these outliers are. BigQuery uses a default value of 1.0, but that is by no means the authoritative value. I’d like to try out values between 0.5 and 3.0. Maybe some other L2 value will work better.
* Boosted trees work by creating an ensemble of weak learners. Each of the decision trees in the ensemble is pretty bad by itself, but when you average all these weak learners in a special way (called boosting), the ensemble turns out to be better than any single tree. But how weak can each individual tree be? Can we have just two IF-THEN rules? Or should we allow 10? By default, BigQuery uses a maximum tree depth of 6. This is by no means an authoritative value that works on all problems. I’d like to try out values between 2 and 10.

We can do a grid search of the hyperparameter space. If we try L2 regularization values between 0.5 and 3.0 in increments of 0.1 and tree depths between 2 and 10 in increments of 1, we’d need to try out 25 × 8 = 200 possible values. At 10 minutes a training run, that’s 2,000 minutes or 1.4 days. Even though I could parallelize these somewhat, I don’t have that kind of patience.

Fortunately, there’s a better way that employs Bayesian methods to choose the optimization path. We can specify a budget (five trials, for example) and have a Vertex AI optimizer called Vizier do the selection of the five most promising possibilities. To do this, instead of specifying a single value for the `L2_reg` and `max_tree_depth`, we specify a range of values:

<pre><code>CREATE OR REPLACE MODEL dsongcp.arr_delay_airports_xgh
OPTIONS(input_label_cols=['ontime'], 
        model_type='boosted_tree_classifier',
<strong>        num_trials=5, 
</strong><strong>        l2_reg=hparam_range(0.5, 3.0), 
</strong><strong>        max_tree_depth=hparam_range(2, 10),
</strong>        data_split_method='custom',
        data_split_col='is_eval_day')
</code></pre>

However, there is a small hitch. When BigQuery does hyperparameter tuning, what independent dataset should it test out the models on? It cannot use the nontraining-days dataset because that is meant for final testing. So, we need to change the `SELECT` statement slightly:

<pre><code>SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
  origin,
  dest,
<strong>  IF(is_train_day = 'True', 
</strong><strong>     IF(RAND() &#x3C; 0.8, 'TRAIN', 'EVAL'), 
</strong><strong>     'TEST') AS is_eval_day
</strong>FROM dsongcp.flights_tzcorr f
JOIN dsongcp.trainday t
ON f.FL_DATE = t.FL_DATE
WHERE
  f.CANCELLED = False AND 
  f.DIVERTED = False
</code></pre>

The `is_eval_day` column used to be a Boolean column. Now, it is a string with three possible values: `TRAIN`, `EVAL`, and `TEST`. The old training dataset has been broken into `TRAIN` and `EVAL` datasets, and the old withheld data is now called the `TEST` dataset—the `TEST` dataset is the one that consists of days where `is_train_day` is not `True`.

Once the hyperparameter job is complete (it will take a couple of hours), we can query for the trials that were run:

```
SELECT 
   hyperparameters.l2_reg, 
   hyperparameters.max_tree_depth, 
   eval_loss
FROM ML.TRIAL_INFO(MODEL dsongcp.arr_delay_airports_xgh)
ORDER BY eval_loss ASC LIMIT 3
```

This returns:

| `Row` | `l2_reg`             | `max_tree_depth` | `eval_loss` |
| ----- | -------------------- | ---------------- | ----------- |
| `1`   | `2.5`                | `10`             | `0.152403`  |
| `2`   | `1.8827838728344135` | `8`              | `0.154935`  |
| `3`   | `2.9999853271420043` | `6`              | `0.156696`  |

We learn that the lowest evaluation loss is for a tree depth of 10 and L2 regularization of 2.5. This can now be our final model.

The RMSE that we now get is 0.2043, an improvement over the score of 0.2072 that we got with the default values. It is noteworthy that this improvement is more than the improvement (0.2098 to 0.2072) we got when we replaced the logistic regression with XGBoost.

### Vertex AI AutoML Tables

The fact that doing hyperparameter tuning gave us a large improvement gives me a bit of pause. Is XGBoost really the best model? These days, deep neural networks (DNNs) do well, even on structured data. Should I not be trying them? If I use deep neural networks, how many layers and nodes do I need? Do I really want to do hyperparameter tuning of the DNN also?

Instead of trying out a variety of models and hyperparameter tuning each model type, I can call out to Vertex AI’s AutoML service from BigQuery. This, too, is as simple as changing the model type in the SQL command:

<pre><code>CREATE OR REPLACE MODEL dsongcp.arr_delay_airports_automl
OPTIONS(input_label_cols=['ontime'], 
<strong>        model_type='automl_classifier')
</strong>AS

SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
  origin,
  dest
FROM dsongcp.flights_tzcorr f
JOIN dsongcp.trainday t
ON f.FL_DATE = t.FL_DATE
WHERE
  f.CANCELLED = False AND 
  f.DIVERTED = False AND
  is_train_day = 'True'
</code></pre>

Unfortunately, at the time of writing, AutoML as invoked from BigQuery ML doesn’t support a custom data split method, so I had to go with the default random split.[3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn157) This training now takes longer. Considerably longer, over an hour.

Computing the evaluation also takes longer (12 minutes), whereas it was nearly instantaneous with XGBoost. Although the result is heartening—I got an RMSE of 0.1998—it is not really comparable because I was not able to use a custom split method.

The experiments so far are summarized in [Table 8-1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#bigquery\_ml\_experi).

| Method                          | RMSE                          |
| ------------------------------- | ----------------------------- |
| Logistic regression             | 0.2131                        |
| Add origin, destination airport | 0.2098                        |
| XGBoost                         | 0.2072                        |
| XGBoost with hparam (10, 2.5)   | 0.2043                        |
| AutoML tables                   | 0.1998 (note: not comparable) |

While hyperparameter tuning and AutoML were tempting, this was not a good time to do them. I should have waited because I have more ideas about features that I can bring in to improve the model. More data beats a better model, and so I should exhaust the data before I try more sophisticated models.

AutoML can be the final step after we have determined what features to use. I jumped the gun a bit. Sorry. Let’s go back to the main program.

## Time Window Features

One of the data ideas I have is that we could improve the way we use taxi-out times.

I remember a flight from New York to Dallas. My flight sat on the runway at New York’s LGA airport for nearly an hour before finally taking off. Yet, it arrived early in Dallas! At peak hours, taxi-out times on the order of an hour are quite common in New York area airports. So, airlines take that into account when publishing their flight schedules. It is only when the taxi-out time exceeds the average of the airport that we ought to be worried.

### Taxi-Out Time

My one anecdote does not make the average taxi-out time an important factor. Let’s validate my intuition from the data.

Does taxi-out time vary by airport? Is the same value of taxi-out associated with late arrivals in one airport, but with on-time arrivals in another? To check, we can compute the average taxi-out for all airports that start with the letter D (this should give us a small, but random sample):[4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn158)

```
%%bigquery txout

SELECT
  ORIGIN,
  IF (arr_delay < 15, True, False) AS is_on_time,
  AVG(taxi_out) AS taxi_out
FROM dsongcp.flights_tzcorr
WHERE SUBSTR(ORIGIN, 1, 1) = 'D'
GROUP BY ORIGIN, is_on_time
```

The BigQuery magic in the first line of the Vertex AI Workbench notebook ensures that the result of the query is stored in the Pandas dataframe called `txout`. From there, we can plot the data:

```
txout = txout.sort_values(by='ORIGIN')
sns.barplot(data=txout, x='ORIGIN', y='taxi_out', hue='is_on_time');
```

The result is shown in [Figure 8-3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#the\_average\_taxi\_out\_time\_associated\_wi). It is clear that there is a significant difference between late and on-time flights when it comes to the amount of time they spend on the taxiway.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0803.png" alt="" height="157" width="600"><figcaption></figcaption></figure>

**Figure 8-3. The average taxi-out time associated with late and on-time flights at various airports.**

It’s also clear that any threshold we impose on taxi-out delay in our model will vary between airports. At airports like Washington DC (DCA), Denver (DEN), and Dallas (DFW), on-time flights have a 15-minute taxi-out time on average. In smaller airports like DAL (Dallas Love Field) and DBO (Dubbo City), this is more than the average taxi-out time associated with delayed flights.

It seems that the average taxi-out times associated with the airport are worth knowing. We can add it to our training dataset by modifying the `SELECT` statement used. First, we compute the average taxi-out times by airport:

<pre><code>WITH taxiout_by_airport AS (
   SELECT 
<strong>    ORIGIN, AVG(taxi_out) AS avg_taxi_out
</strong>   FROM
    dsongcp.flights_tzcorr
<strong>   GROUP BY ORIGIN
</strong>)
</code></pre>

Then, we join the original data against the average taxi-out times using the origin airport:

<pre><code>SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
<strong>  avg_taxi_out,
</strong>  distance,
  origin,
  dest,
  IF(is_train_day = 'True', False, True) AS is_eval_day
FROM dsongcp.flights_tzcorr f
JOIN dsongcp.trainday t
ON f.FL_DATE = t.FL_DATE
<strong>JOIN taxiout_by_airport USING(ORIGIN)
</strong>WHERE
  f.CANCELLED = False AND 
  f.DIVERTED = False
LIMIT 5
</code></pre>

The dataset now contains the average taxi-out times in each row:

| `Row` | `ontime` | `dep_delay` | `taxi_out` | `avg_taxi_out`       | `distance` | `origin` | `dest` | `is_eval_day` |
| ----- | -------- | ----------- | ---------- | -------------------- | ---------- | -------- | ------ | ------------- |
| `1`   | `ontime` | `-1.0`      | `4.0`      | `7.507122507122507`  | `548.0`    | `OTZ`    | `ANC`  | `true`        |
| `2`   | `ontime` | `-8.0`      | `13.0`     | `16.184090332402953` | `1056.0`   | `HPN`    | `PBI`  | `false`       |
| `3`   | `ontime` | `-2.0`      | `21.0`     | `13.344790914960695` | `1046.0`   | `SJU`    | `FLL`  | `false`       |
| `4`   | `late`   | `91.0`      | `15.0`     | `16.184090332402953` | `1097.0`   | `HPN`    | `FLL`  | `false`       |
| `5`   | `ontime` | `-10.0`     | `8.0`      | `12.900537006770952` | `1192.0`   | `ANC`    | `ADK`  | `false`       |

In the third row, the plane departed 2 minutes early and spent 8 minutes longer than usual on the taxiway. Therefore, it took off 6 minutes later than usual. This will surely have an impact on the arrival delay. So, it makes sense that the taxi-out times associated with late and on-time flights are different.

### Compounding Delays

The delays of flights that take off ten minutes apart are correlated. If a couple of runways are unavailable due to prevailing winds, for example, delays will start to compound. Looking at the average departure delay over the previous hour is potentially a good indicator of how well the airport is clearing these delays.

To compute the moving average, we can use the window functionality of SQL:

```
SELECT
  dep_time,
  AVG(dep_delay) OVER time_window AS dep_delay,
  AVG(arr_delay) OVER time_window AS arr_delay
FROM dsongcp.flights_tzcorr
WHERE
  ORIGIN = 'DFW' AND FL_DATE = '2015-03-02'
WINDOW time_window AS (ORDER BY UNIX_SECONDS(dep_time) 
                       RANGE BETWEEN 3600 PRECEDING AND 1 PRECEDING)
```

The preceding statement computes the average departure and arrival delays over a time window. The time window is defined in the SQL statement as consisting of the rows 3,600 seconds to 1 second before the current row’s departure time. For plotting purposes, I’m limiting the query to flights from Dallas on March 2, 2015. The result is shown in [Figure 8-4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#the\_average\_departure\_and\_arrival\_delay).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0804.png" alt="" height="175" width="600"><figcaption></figcaption></figure>

**Figure 8-4. The average departure and arrival delays increased over the course of Mar 2, 2015.**

Adding the rolling average feature to the training dataset involves code similar to the code used for plotting previously, except that we make sure to partition the window by the origin airport (so that the moving average is computed only on flights that depart from the same airport):

<pre><code>...
SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
<strong>  AVG(dep_delay) OVER (origin_time_window) AS avg_dep_delay,
</strong>  taxi_out,
   ...
FROM dsongcp.flights_tzcorr f
...
WINDOW origin_time_window AS (PARTITION BY ORIGIN
                              ORDER BY UNIX_SECONDS(dep_time) 
                              RANGE BETWEEN 3600 PRECEDING AND 1 PRECEDING)
</code></pre>

### Causality

Adding these two time-based features and training the model with BigQuery defaults, we get an RMSE of 0.2040 compared to the 0.2072 we got without these features. The additional data gives us a boost on par with hyperparameter tuning. And we still have hyperparameter tuning in our back pocket!

However, this is not strictly correct. I cheated a bit. Did you notice where I cheated?

The mischief started with this line:

<pre><code>WITH taxiout_by_airport AS (
   SELECT 
<strong>    ORIGIN, AVG(taxi_out) AS avg_taxi_out
</strong>   FROM
    dsongcp.flights_tzcorr
<strong>   GROUP BY ORIGIN
</strong>)
</code></pre>

What am I computing the average of? The average taxi-out at each airport over all the training flights? No, I am using the evaluation flights too! Oops. That’s relatively easy to fix. I could add a `WHERE` clause. But there is another problem. Suppose I am evaluating the prediction that happened on May 5, 2015. Am I allowed to use the average delay of flights that happened in December 2015 just because they are in the training data? How would I provide this value in production? Shouldn’t the global average be kept up-to-date, so that predictions on May 5, 2015, use the average delay of flights from the start of the dataset until May 2015 (or maybe the average delay of flights that happened in the 12 months preceding May 2015?).

We used the average departure delay at the origin airport. What if we also want to include the average arrival delay at the destination airport? How would we partition the time window? Not based on the time window of the current flight—it hasn’t arrived yet! I suppose it is possible to do this in SQL, but it requires greater SQL skills than I have. Also, I don’t trust myself to not make causality mistakes like the ones in the previous paragraph.

The moment we start including time-based averages in our ML models, we have to be very careful about causality. In [Chapter 11](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch11.html#time\_windowed\_features\_for\_real\_time\_ma), we’ll look at how to compute time-windowed features in a less error-prone way by using a stream analytics system.

## Time Features

Time windows introduce a lot of complexity, but time-based features are quite important for this problem. Is there a simpler approach to incorporate time?

### Departure Hour

What if, instead of computing hourly averages, we use the hour as an input field? If we have sufficiently large data, the model will learn to associate different behavior with different hours. Thus, for example, the model might be able to learn that high taxi-out times are common during rush hour and infer that the flight would still be able to arrive on-time.

But we did try adding the hour as an input in [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml) and found that it didn’t improve the performance. Trying out the same action a second time and expecting a different result might seem strange. However, it’s not quite the same thing that we are trying. A linear model might not be able to easily differentiate between 5 p.m. in New York and 5 p.m. in a smaller airport. The nonlinear XGBoost model that we are using here has more expressive power and might be able to learn the difference. So, it is worth giving the hour feature another try.

The hour is not the only part of the timestamp that matters. Flights tend to be more delayed on weekdays than on weekends. So, let’s also add the day of the week as an input. To do so, we can adapt the query that creates the training dataset to be:[5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn159)

<pre><code>SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
  origin,
  dest,
<strong>  EXTRACT(hour FROM dep_time) AS dep_hour,
</strong><strong>  EXTRACT(dayofweek FROM dep_time) AS dep_day,
</strong>  IF(is_train_day = 'True', False, True) AS is_eval_day
FROM dsongcp.flights_tzcorr f
JOIN dsongcp.trainday t
ON f.FL_DATE = t.FL_DATE
WHERE
  f.CANCELLED = False AND 
  f.DIVERTED = False
</code></pre>

This creates a dataset that looks like this:

| `Row` | `ontime` | `dep_delay` | `taxi_out` | `distance` | `origin` | `dest` | `dep_hour` | `dep_day` | `is_eval_day` |
| ----- | -------- | ----------- | ---------- | ---------- | -------- | ------ | ---------- | --------- | ------------- |
| `1`   | `ontime` | `-5.0`      | `10.0`     | `399.0`    | `ANC`    | `BET`  | `3`        | `5`       | `true`        |
| `2`   | `late`   | `33.0`      | `13.0`     | `1046.0`   | `FLL`    | `SJU`  | `14`       | `7`       | `false`       |
| `3`   | `ontime` | `-3.0`      | `8.0`      | `95.0`     | `SIT`    | `JNU`  | `13`       | `5`       | `false`       |
| `4`   | `ontime` | `5.0`       | `9.0`      | `201.0`    | `LIH`    | `OGG`  | `22`       | `6`       | `true`        |
| `5`   | `ontime` | `-4.0`      | `5.0`      | `204.0`    | `BRW`    | `SCC`  | `4`        | `4`       | `false`       |

There is a problem with simply extracting features and adding them to the dataset. When we want the prediction for a flight, we will need to provide the departure hour and departure day because that’s what the model was trained on (see [Figure 8-5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#the\_model\_is\_trained\_with\_hour\_and\_day)). However, it is unclear to a programmer who’s coding up the client program how the hour needs to be provided. Should 7 a.m. be 07 or 7? Should this hour be in local time or in UTC? Similarly, should the day of the week be Thu or 5 or 05? What is the first day of the week? All the questions that we successfully resolved in [Chapter 4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch04.html#streaming\_data\_publication\_and\_ingest) will again raise their heads.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0805.png" alt="" height="86" width="600"><figcaption></figcaption></figure>

**Figure 8-5. The model is trained with hour and day-of-week as features, but they are not directly present in the input data feed. Instead, they are extracted from the departure timestamp.**

### Transform Clause

Ideally, the machine learning model takes, as input, the timestamp (which is what is present in the datafeed) and internally knows how to transform the departure time into hour and day-of-week. This transformation can be carried out identically both during training and during inference.

The way to specify such transformations in BigQuery ML is to use the `TRANSFORM` clause:

<pre><code>CREATE OR REPLACE MODEL dsongcp.arr_delay_airports_timefeatures
<strong>TRANSFORM(
</strong><strong>   * EXCEPT(dep_time),
</strong><strong>   EXTRACT(hour FROM dep_time) AS dep_hour,
</strong><strong>   EXTRACT(dayofweek FROM dep_time) AS dep_day
</strong><strong>)
</strong>OPTIONS(input_label_cols=['ontime'], 
        model_type='boosted_tree_classifier',
        ...)

AS

SELECT
  IF(arr_delay &#x3C; 15, 'ontime', 'late') AS ontime,
  dep_delay,
  taxi_out,
  distance,
  origin,
  dest,
<strong>  dep_time,
</strong>  IF(is_train_day = 'True', False, True) AS is_eval_day
...
</code></pre>

Note that the training dataset (the `SELECT` statement) has the `dep_time` column as-is. The `TRANSFORM` clause pulls in all the columns from the `SELECT` statement but replaces the `dep_time` column with two columns extracted from the departure time.

At this time, I will take advantage of the hyperparameter tuning that I have already done and change the L2 regularization and maximum tree depth from their default values to be the value that was best:

<pre><code>OPTIONS(input_label_cols=['ontime'], 
        model_type='boosted_tree_classifier',
        data_split_method='custom',
        data_split_col='is_eval_day',
<strong>        l2_reg=2.5,
</strong><strong>        max_tree_depth=10)
</strong></code></pre>

On training an XGBoost model with these settings, I get a model whose RMSE on the evaluation dataset is 0.2043. This is quite close to the value that we got from using time windows. It’s also a lot simpler because there is no need to build real-time infrastructure that computes moving averages. Of course, we don’t know whether using time windows will provide an additional improvement. Let’s defer this discussion to [Chapter 11](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch11.html#time\_windowed\_features\_for\_real\_time\_ma).

In large-scale ML, you can get much of the benefit of time-windowed averages by using time features. Time features are a lot simpler from an engineering perspective than real-time pipelines.

### Categorical Variable

Although we got pretty good performance from using the departure hour and day of the week as-is, there is a small problem. By default, BigQuery ML treats all numbers as numeric features and all strings as categorical features. The day of the week as extracted from the timestamp is not a string (e.g., Thursday), but is a number (5). Therefore, BigQuery ML would have treated it as a numeric input. This is usually okay, but it is not the case that Saturday is greater than Monday.

Let’s try treating the day of the week as categorical. While we could simply cast the integer into a string, let’s try adding a bit of prior knowledge, that days 1 and 7 are weekends:

<pre><code>TRANSFORM(
   * EXCEPT(dep_time),
   EXTRACT(hour FROM dep_time) AS dep_hour,
<strong>   IF(EXTRACT(dayofweek FROM dep_time) BETWEEN 2 and 6, 
</strong><strong>      'weekday', 'weekend') AS dep_day
</strong>)
</code></pre>

On training with the day of the week as categorical, we get an RMSE of 0.2042, a very slight improvement over treating it as numeric. We’ll stick with this because it is a better representation.

### Feature Cross

There is a difference between 5 p.m. on Friday in New York versus 5 p.m. on Friday in a smaller airport such as Columbus, Ohio. The way to capture this important combination is to concatenate the three fields (hour, day of week, and origin airport) and treat them as a single categorical variable. This is called a _feature cross_, and it can be expressed in BigQuery ML as:

<pre><code>TRANSFORM(
   * EXCEPT(dep_time),
<strong>   ML.FEATURE_CROSS(STRUCT(
</strong><strong>     ML.BUCKETIZE(EXTRACT(hour FROM dep_time), 
</strong><strong>                  [0, 4, 8, 12, 16, 20]) AS dep_hour,
</strong><strong>     IF(EXTRACT(dayofweek FROM dep_time) BETWEEN 2 and 6, 
</strong><strong>                'weekday', 'weekend') AS dep_day,
</strong><strong>     origin
</strong><strong>   )) AS day_hour
</strong>)
</code></pre>

On training with the feature cross, we get an RMSE of 0.2043—the feature cross hasn’t helped. This might be because of sparsity—one of the problems with a feature cross is that it greatly increases the number of possible values. There are 24 possible hours, 2 possible values for `dep_day` (weekday and weekend), and more than 300 values for the origin airport. Because we are combining the possibilities, and treating each unique combination independently, the feature cross results in a categorical variable with 24 × 2 × 300 values. Bucketizing the hour into 6 buckets of 4 hours each helps reduce the number of combinations. Obviously, that wasn’t enough. In [Chapter 9](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#machine\_learning\_with\_tensorflow\_in\_ver), we will look at a machine learning concept called embedding that will help with this sparsity problem (see sidebar).

Another thing to consider is that we don’t have the hour or day-of-week by itself anymore. Perhaps the feature cross needs to be an additional feature, instead of replacing the individual columns.

The last few changes we have tried have had minimal impact on the performance of the model. At some point, with feature engineering, we hit diminishing returns. So, this seems as good a time as any to stop.

**WHEN TO USE LOW-CODE AND NO-CODE SYSTEMS**

What we observed with sparsity and the need for an embedding is a pretty common scenario in software tools and frameworks—whether the framework is for building mobile applications or user interfaces, websites, or machine learning models.[6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn160)

A _no-code_ tool is the easiest to use. Point-and-click and you are done. AutoML on Google Cloud is a no-code system for creating and deploying machine learning models (we will encounter it in [Chapter 10](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch10.html#getting\_ready\_for\_mlops\_with\_vertex\_ai)). It is completely GUI-driven.

A _low-code_ system is one where there is a library or framework that provides common use cases via simple APIs. BigQuery ML is a low-code system. All we need is SQL to do a wide variety of use cases, ranging from regression and classification to time-series forecasting, _k_-means clustering, and product recommenders. Even though we write SQL, BigQuery ML delegates the actual work to C++ code running on BigQuery slots or to TensorFlow code running in Vertex AI. All this is abstracted away from us.

Low-code systems are easier to use than the sophisticated underlying software that actually does the work. At some point, however, you will need a capability that has not been wrapped around by the designer of the low-code or no-code framework. At that point, you will want to directly use the more sophisticated framework. The need for an embedding is when we reached that point with BigQuery ML, but every low-code and no-code tool eventually reaches a breaking point.

When you are choosing tooling for your data science platform, low-code and no-code tools can be tempting, but you should always verify that, if needed, you can drop down to code. Also verify that the code that you then write is portable, can be version-controlled, and uses standard and popular APIs.

Use AutoML and BigQuery ML whenever you can, confident that you can drop down to Vertex AI and TensorFlow if necessary. Don’t overcorrect and use only TensorFlow code—you will be sacrificing a lot of productivity if you thumb your nose at low-code and no-code tools.

## Summary

BigQuery ML provides a simple and powerful SQL interface for doing machine learning. We created a classifier model for predicting flight delays using BigQuery ML. We were able to evaluate this model and use it for batch predictions with just SQL.

We then created a more sophisticated model using gradient boosted trees and saw an improvement over the simple logistic regression model we used earlier. The scale and simplicity of BigQuery allowed us to add additional features like airport codes. We saw that the addition of these features resulted in improved performance.

We also saw that we could get a worthwhile performance boost using hyperparameter tuning and AutoML. Because of how time-consuming these two options are, we should be using them at the end of our experimentation process, after we have exhausted all the data improvements.

We experimented with adding time-windowed moving averages. Although the SQL syntax is quite straightforward, the semantics of causality are hard to keep track of. It’s better to compute time averages in a stream analytics system—we will do this in [Chapter 10](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch10.html#getting\_ready\_for\_mlops\_with\_vertex\_ai).

Considering the difficulty of including time-windowed features, we explored whether directly using different parts of time would be a good alternative. We found that we could match the performance improvement of the time-windowed moving average by including the hour and day of week as input features.

Carrying out transformation like this is hard to keep track of, and so we put all our transformations into the `TRANSFORM` clause. That way, they are automatically applied to the input data during prediction.

We finally hit diminishing returns with feature engineering, so we stopped.

## Suggested Resources

BigQuery ML is one of my favorite go-to products in Google Cloud. So, I’ve written a large number of blogs about BigQuery ML features. Here are a few of the superpowers of BigQuery ML that we didn’t have time to cover in this chapter:

* Time-series forecasting models. See Lak Lakshmanan, [“How To Do Time Series Forecasting in BigQuery”](https://oreil.ly/7IKFZ), _Towards Data Science_ (blog), March 30, 2020.
* Recommendation models. See Lak Lakshmanan, [“Training a Recommendation Model for Google Analytics Data Using BigQuery ML”](https://oreil.ly/VDsOj), _Towards Data Science_ (blog), April 20, 2020.
* K-means clustering. See Lak Lakshmanan, [“How to Use K-Means Clustering in BigQuery ML to Understand and Describe Your Data Better”](https://oreil.ly/vuBaX), _Towards Data Science_ (blog), April 10, 2019.
* Anomaly detection. See Lak Lakshmanan, [“Anomaly Detection in Time Series Data Using BigQuery ML”](https://oreil.ly/QCe2N), _Medium_ (blog), July 14, 2021.
* Export trained models to Vertex AI for online prediction. See Lak Lakshmanan, [“How to Export a BigQuery ML Model and Deploy It for Online Prediction”](https://oreil.ly/jrG4T), _Towards Data Science_ (blog), May 17, 2020.
* Import trained TensorFlow models for batch prediction. See Lak Lakshmanan, [“How to Do Batch Predictions of TensorFlow Models Directly in BigQuery”](https://oreil.ly/bHsw0), _Towards Data Science_ (blog), April 10, 2019
* Explaining a BigQuery ML model. See Lak Lakshmanan, [“Explaining a BigQuery ML Model”](https://oreil.ly/KRLEE), _Towards Data Science_ (blog), July 29, 2021.

How about specific use cases? Many common use cases in BigQuery ML are often just a web search away:

* Propensity to buy. See Damodar Panigrahi, [“How to Build an End-to-End Propensity to Purchase Solution Using BigQuery ML and Kubeflow Pipelines”](https://oreil.ly/PpYa0), _Google Cloud - Community_ (blog), September 8, 2020.
* E-commerce recommendations. See Polong Lin, [“How to Build a Recommendation System on E-Commerce Data Using BigQuery ML”](https://oreil.ly/UenSu), _Google Cloud - Community_ (blog), July 13, 2020.
* Audience segmentation. See Tai Conley, [“How to Build Audience Clusters With Website Data Using BigQuery ML”](https://oreil.ly/Vwz83), _Google Cloud - Community_ (blog), November 4, 2020.

If there is only one Google Cloud data product you can learn, it should be BigQuery. Fortunately, there is an excellent book on BigQuery by your favorite author, [_Google BigQuery: The Definitive Guide_](https://www.oreilly.com/library/view/google-bigquery-the/9781492044451/) by Valliappa Lakshmanan and Jordan Tigani (O’Reilly).

[1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn155-marker) See _bqml\_logistic.ipynb_ in the GitHub repository of this book. You can run this in Vertex Workbench.

[2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn156-marker) The code for this section is in _bqml\_nonlinear.ipynb_.

[3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn157-marker) AutoML supports a custom data split method. We’ll use it in [Chapter 9](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#machine\_learning\_with\_tensorflow\_in\_ver). It’s AutoML as invoked in SQL through BigQuery ML that doesn’t.

[4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn158-marker) The code is in the notebook _bqml\_timewindow.ipynb_.

[5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn159-marker) The code is in _bqml\_timetxf.ipynb_.

[6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#ch01fn160-marker) It is quite likely that the BigQuery ML team will read this and will have added support for embeddings by the time you read this book. The general principle still holds though.
