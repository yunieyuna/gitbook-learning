# 6. Bayesian Classifier With Apache Spark On Cloud Dataproc

## Chapter 6. Bayesian Classifier with Apache Spark on Cloud Dataproc

Having become accustomed to running queries in BigQuery where there were no clusters to manage, I’m dreading going back to configuring and managing Hadoop clusters. But I did promise you a tour of data science on the cloud, and in many companies, Hadoop plays an important role in that.

In this chapter, we tackle the next stage of our data science problem, by creating a Bayes model to predict the likely arrival delay of a flight. We will do this through an integrated workflow that involves BigQuery and Spark SQL.

All of the code snippets in this chapter are available in the folder [_06\_dataproc_ of the book’s GitHub repository](https://github.com/GoogleCloudPlatform/data-science-on-gcp). See the _README.md_ file in that directory for instructions on how to do the steps described in this chapter.

## MapReduce and the Hadoop Ecosystem

MapReduce was described in [a paper by Jeff Dean and Sanjay Ghemawat](https://oreil.ly/oMGK8) as a way to process large datasets on a cluster of machines. They showed that many real-world tasks can be decomposed into a sequence of two types of functions: `map` functions that process key-value pairs to generate intermediate key-value pairs, and `reduce` functions that merge all the intermediate values associated with the same key. A flexible and general-purpose framework can run programs that are written following this MapReduce model on a cluster of commodity machines. Such a MapReduce framework will take care of many of the details that make writing distributed system applications so difficult—the framework, for example, will partition the input data appropriately, schedule running the program across a set of machines, and handle job or machine failures.

### How MapReduce Works

Imagine that you have a large set of documents and you want to compute word frequencies on that dataset. Before MapReduce, this was an extremely difficult problem. One approach you might take would be to scale up—that is, to get an extremely large, powerful machine.[1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn110) The machine will hold the current word frequency table in memory, and every time a word is encountered in the document, this word frequency table will be updated. Here it is in pseudocode:

```
wordcount(Document[] docs):
   wordfrequency = {}
   for each document d in docs:
      for each word w in d:
           wordfrequency[w] += 1
   return wordfrequency
```

We can make this a multithreaded solution by having each thread work on a separate document, sharing the word frequency table between the threads, and updating this in a thread-safe manner. You will at some point, though, run into a dataset that is beyond the capabilities of a single machine. At that point, you will want to scale out, by dividing the documents among a cluster of machines. Each machine on the cluster then processes a fraction of the complete document collection. The programmer implements two methods, `map` and `reduce`:

```
map(String docname, String content):
   for each word w in content:
      emitIntermediate(w, 1)

reduce(String word, Iterator<int> intermediate_values):
    int result = 0;
    for each v in intermediate_values:
      result += v;
    emit(result);
```

The framework manages the orchestration of the maps and reduces and interposes a group-by-key in between (i.e., it’s the framework that makes these calls—not the programmer):

```
wordcount(Document[] docs):
   for each doc in docs:
        map(doc.name, doc.content)
   group-by-key(key-value-pairs)
   for each key in key-values:
        reduce(key, intermediate_values)
```

To improve speed in an environment in which network bisection bandwidth (see [Chapter 2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch02.html#ingesting\_data\_into\_the\_cloud)) is low,[2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn111) the documents are stored on local drives attached to the compute instance. The map operations are then scheduled by the MapReduce infrastructure in such a way that each map operation runs on a compute instance that already has the data it needs (this assumes that the data has been presharded on the cluster), as shown in [Figure 6-1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#mapreduce\_is\_an\_algorithm\_for\_distribut).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0601.png" alt="" height="387" width="600"><figcaption></figcaption></figure>

**Figure 6-1. MapReduce is an algorithm for distributed processing of datasets in which the data are presharded onto compute instances such that each map operation can access the data it needs using a local filesystem call.**

As the diagram indicates, there can be multiple map and reduce jobs assigned to a single machine. The key capability that the MapReduce framework provides is the orchestration and massive group-by-key after the map tasks complete and before the reduce jobs can begin.

### Apache Hadoop

When Dean and Ghemawat published the MapReduce paper, they did not make Google’s MapReduce implementation open source.[3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn112) [Hadoop](https://oreil.ly/Ozqzy) is open source software that was created from parts of [Apache Nutch](https://oreil.ly/Q2UnK), an open source web crawler created by Doug Cutting based on a couple of Google papers. Cutting modeled the distributed file system in his crawler on Google’s descriptions of the [Google File System](https://oreil.ly/3bx4I) (a predecessor of the [Colossus filesystem](https://oreil.ly/lFUq0) that is in use within Google Cloud Platform today) and the data processing framework on Dean and Ghemawat’s MapReduce paper. These two parts were then factored out into Hadoop in 2006 as the Hadoop Distributed File System (HDFS) and the MapReduce engine.

Hadoop today is managed by the Apache Software Foundation. It is a framework that runs applications using the MapReduce algorithm, enabling these applications to process data in parallel on a cluster of commodity machines. Apache Hadoop provides Java libraries necessary to write MapReduce applications (i.e., the `map` and `reduce` methods) that will be run by the framework. In addition, it provides a scheduler, called YARN, and a distributed file system (HDFS). To run a job on Hadoop, the programmer submits a job by specifying the location of the input and output files (typically, these will be in HDFS) and uploading a set of Java classes that provide the implementation of the `map` and `reduce` methods.

## Google Cloud Dataproc

Normally, the first step in writing Hadoop jobs is to get a Hadoop installation going. This involves setting up a cluster, installing Hadoop on it, and configuring the cluster so that the machines all know about one another and can communicate with one another in a secure manner. Then, you’d start the YARN and MapReduce processes and finally be ready to write some Hadoop programs.

On Google Cloud, [Google Cloud Dataproc](https://oreil.ly/Z8d48) makes it convenient to spin up a Hadoop cluster that is capable of running MapReduce, Pig, Hive, Presto, and Spark.

If you are using Spark, Dataproc offers a fully managed, serverless Spark environment—you can simply submit a Spark program and Dataproc will execute it. In this way, Dataproc is to Apache Spark what Dataflow is to Apache Beam. In fact, Dataproc and Dataflow share backend services. At the time I’m writing this chapter (December 2021), this serverless execution environment in Dataproc supports only Spark, although there are plans to expand it to other frameworks commonly used in Hadoop clusters.

Even if you are not using Spark, Dataproc will still reduce the toil associated with running Hadoop workloads in several ways:

* Dataproc ties into Cloud identity and access management (IAM), Cloud Logging, etc., so that you don’t have to manage security or logging on a cluster-by-cluster basis.
* It is autoscaling and will shrink or grow to accommodate your workloads, so you don’t have to manage and provision machines yourself.
* It reads directly off Cloud Storage, so you don’t have to manage the storage yourself.
* It offers a metadata service so that, even if you run clusters only for the duration of the job, Hive jobs can have persistent metadata.

We can create a fully configured Dataproc cluster by using the following single `gcloud` command:[4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn113)

```
gcloud dataproc clusters create ch6cluster \
  --enable-component-gateway \
  --region us-central1 --zone us-central1-a \
  --master-machine-type n1-standard-4 \
  --master-boot-disk-size 500 --num-workers 2 \
  --worker-machine-type n1-standard-4 \
  --worker-boot-disk-size 500 --image-version 2.0 \
  --properties dataproc:dataproc.personal-auth.user=$EMAIL \  
  --optional-components JUPYTER --project $PROJECT \
  --scopes https://www.googleapis.com/auth/cloud-platform
```

A minute or so later, the Cloud Dataproc cluster is created, all ready to go. The `--num-workers`, `--worker-machine-type`, and `--master-machine-type` parameters specify the hardware configuration of the cluster. The `scopes` parameter indicates what Cloud IAM roles this cluster’s service account should have. For example, to create a cluster that will run programs that will need to administer Cloud Bigtable and invoke BigQuery queries, you could specify the scope as follows:

```
--scopes=https://www.googleapis.com/auth/bigtable.admin,bigquery
```

Here, I’m allowing the cluster to work with all Google Cloud Platform products. Cloud Dataproc allows you to specify an image version, so that any work you carry out is repeatable. Leave out `--image-version` to use the latest stable version. The `--enable-component-gateway` parameter creates readily accessible, but secure, https proxy endpoints for various services running on the cluster. Besides the standard Hadoop services, we also want Jupyter, and so we specify it as an optional component. If your data (that will be processed by the cluster) is in a single-region bucket on Google Cloud Storage, you should create your cluster in that same zone to take advantage of the high bisection bandwidth within a Google data center; that’s what the `--zone` specification does.

Although the cluster creation command supports a `--bucket` option to specify the location of a staging bucket to store such things as configuration and control files, best practice is to allow Cloud Dataproc to determine its own staging bucket. This allows you to keep your data separate from the staging information needed for the cluster to carry out its tasks. Cloud Dataproc will create a separate bucket in each geographic region, choose an appropriate bucket based on the zone in which your cluster resides, and reuse such Cloud Dataproc–created staging buckets between cluster create requests if possible.[5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn114)

Because we specified `--enable-component-gateway`, we can verify that Hadoop is running by visiting the Cloud Dataproc section of the Google Cloud Platform web console and accessing the HDFS NameNode web interface (from the Web Interfaces section of the cluster details). You should be able to see the list of data nodes.

If you want to use Secure Shell (SSH) to connect to the cluster, you can, but you’d have to give the master node an external IP in order to do so. This is generally not a good idea. Instead, interact with the cluster through the available web interfaces. Later in this chapter, I’ll show you how to install software on startup so that you don’t need to SSH into the cluster to install software.

### Need for Higher-Level Tools

The word count example is embarrassingly parallel, and therefore trivial to implement in terms of a single map and a single reduce operation. However, it is nontrivial to cast more complex data processing algorithms into sequences of map and reduce operations. Higher-level solutions are called for, and as different organizations implemented add-ons to the basic Hadoop framework and made these additions available as open source, the Hadoop ecosystem was born.

[Apache Pig](http://pig.apache.org/) provided one of the first ways to simplify the writing of MapReduce programs to run on Hadoop. Apache Pig requires you to write code in a language called _Pig Latin_; these programs are then converted to sequences of MapReduce programs, and these MapReduce programs are executed on Apache Hadoop. Because Pig Latin (sometimes just referred to as Pig) comes with a command-line interpreter, it is very conducive to interactive creation of programs meant for large datasets. At the same time, it is possible to save the interactive commands and execute the script on demand. This provides a way to achieve both embarrassingly parallel data analysis and data flow sequences consisting of multiple interrelated data transformations. Pig can optimize the execution of MapReduce sequences, thus allowing the programmer to express tasks naturally without worrying about efficiency.

[Apache Hive](https://hive.apache.org/) provides a mechanism to project structure onto data that is already in distributed storage. With the structure (essentially a table schema) projected onto the data, it is possible to query, update, and manage the dataset using SQL. Typical interactions with Hive use a command-line tool or a Java Database Connectivity (JDBC) driver.

Pig and Hive both rely on the distributed storage system to store intermediate results. [Apache Spark](http://spark.apache.org/), on the other hand, takes advantage of in-memory processing and a variety of other optimizations. Because many data pipelines start with large, out-of-memory data, but quickly aggregate it to something that can be fit into memory, Spark can provide dramatic speedups when compared to Pig and as well as speedups for Spark SQL when compared to Hive.[6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn115) In addition, because Spark (like Pig and BigQuery) optimizes the directed acyclic graph (DAG) of successive processing stages, it can provide gains over handwritten Hadoop operations. With the growing popularity of Spark, a variety of machine learning, data mining, and streaming packages have been written for it. Hence, in this chapter, we focus on Spark solutions. Cloud Dataproc, though, provides an execution environment for Hadoop jobs regardless of the abstraction level (i.e., whether you submit jobs in Hadoop, Pig, Hive, or Spark). All these software packages are installed by default on Cloud Dataproc.

### Jobs, Not Clusters

We will look at how to submit jobs to the Cloud Dataproc clusters shortly, but after you are done with the cluster, delete it by using the following:

```
gcloud dataproc clusters delete ch6cluster
```

You can even set the cluster up so that it is automatically deleted if it’s idle for a specific time duration.

This is not the typical Hadoop workflow—if you are used to an on-premises Hadoop installation, you might have set up the cluster a few months ago and it has remained up since then. The better practice on Google Cloud Platform, however, is to delete the cluster after you are done. The reasons are twofold. First, it typically takes less than two minutes to start a cluster. Because cluster creation is fast and can be automated, it is wasteful to keep unused clusters around—you are paying for the cluster regardless of whether you are running anything useful on them. Second, one reason that on-premises Hadoop clusters are kept always on is because the data is stored on HDFS. Although you can use HDFS in Cloud Dataproc (recall that we looked at HDFS NameNode to get the status of the Hadoop cluster), it is not recommended. Instead, it is better to keep your data on Google Cloud Storage and directly read from Cloud Storage in your MapReduce jobs—the original MapReduce practice of assigning map processes to nodes that already have the necessary data came about in an environment in which network bisection speeds were low. On the Google Cloud Platform, for which network bisection speeds are on the order of a petabit per second, the best practice has changed. Instead of sharding your data onto HDFS, keep your data on Cloud Storage and read the data into an ephemeral cluster, as demonstrated in [Figure 6-2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#because\_network\_bisection\_speeds\_on\_goo).

Because of the high network speed that prevails within the Google data center, reading from Cloud Storage is competitive with HDFS in terms of speed for sustained reads of large files (the typical Hadoop use case). If your use case involves frequently reading small files, reading from Cloud Storage could be slower than reading from HDFS. However, even in this scenario, you can counteract this lower speed by simply creating more compute nodes—because storage and compute are separate, you are not limited to the number of nodes that happen to have the data. Because Hadoop clusters tend to be underutilized, you will often save money by creating an ephemeral cluster many times the size of an always-on cluster with an HDFS filesystem. Getting the job done quickly with a lot more machines and deleting the cluster when you are done is often the more frugal option (you should measure this on your particular workflow, of course, and estimate the cost of different scenarios).[7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn116) This method of operating with short-lived clusters is also quite conducive to the use of [preemptible instances](https://oreil.ly/8gF35)—you can create a cluster with a given number of standard instances and many more preemptible instances, thus getting a lower cost for the full workload.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0602.png" alt="" height="365" width="600"><figcaption></figcaption></figure>

**Figure 6-2. Because network bisection speeds on Google Cloud are on the order of a petabit per second, best practice is to keep your data on Cloud Storage and simply spin up short-lived compute nodes to perform the map operations. These nodes will read the data across the network. In other words, there is no need to preshard the data.**

### Preinstalling Software

Creating and deleting clusters on demand is fine if you want a plain, vanilla Hadoop cluster, but what if you need to install specific software on the individual nodes?

There are two approaches. One is to create your own custom Docker images and ask Dataproc to use those:

```
gcloud dataproc clusters create --image=...
```

You can create these images starting from an existing Dataproc base image and adding any other packages you require in your Dockerfile.

The second option is to use _initialization actions_. These are simply startup executables, stored on Cloud Storage, that will be run on the nodes of the cluster. For example, suppose that we want a specific Python package:

*   Create a script to carry out whatever software we want preinstalled:[8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn117)

    ```
    #!/bin/bash

    # Things to do on both Master and Worker
    apt-get -y update
    apt-get install python-dev
    apt-get install python-pip
    pip install --upgrade google-api-python-client

    ROLE=$(/usr/share/google/get_metadata_value attributes/dataproc-role)
    if [[ "${ROLE}" == 'Master' ]]; then
      cd home/dataproc
      git clone https://github.com/GoogleCloudPlatform/data-science-on-gcp
    fi
    ```

    Now, when the cluster is created, the specified packages will exist on all the nodes and the GitHub repository will exist on the Master node.
*   Save the script on Cloud Storage:

    ```
    #!/bin/bash
    BUCKET=cloud-training-demos-ml
    ZONE=us-central1-a
    INSTALL=gs://$BUCKET/flights/dataproc/install_on_cluster.sh

    # upload install file
    gsutil cp install_on_cluster.sh $INSTALL
    ```
*   Supply the script to the cluster creation command:[9](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn118)

    ```
    gcloud dataproc clusters create \
       --num-workers=2 \
       ...
       --initialization-actions=$INSTALL \
       ch6cluster
    ```

Some components, like Jupyter, are already available for installation in Cloud Dataproc. For Jupyter, we could get away with just specifying it as one of the `--optional-components` to be installed.

## Quantization Using Spark SQL

So far, we have used only one variable in our dataset—the departure delay—to make our predictions of the arrival delay of a flight. However, we know that the distance the aircraft needs to fly must have some effect on the ability of the pilot to make up for delays en route. The longer the flight, the more likely it is that small delays in departure can be made up in flight. So, let’s build a statistical model that uses two variables—the departure delay and the distance to be traveled.

One way to do this is to put each flight into one of several bins, as shown in [Table 6-1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#quantizing\_distance\_and\_departure\_delay).

|               | < 10 min                                                                                                                                                                              | 10–12 min | 12–15 min | > 15 min |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------- | --------- | -------- |
| < 100 miles   | <p>For example:</p><ul><li>Arrival Delay ≥ 15 min: 150 flights</li><li>Arrival Delay &#x3C; 15 min: 850 flights</li><li>85% of flights have arrival delay &#x3C; 15 minutes</li></ul> |           |           |          |
| 100–500 miles |                                                                                                                                                                                       |           |           |          |
| > 500 miles   |                                                                                                                                                                                       |           |           |          |

For each bin, I can look at the number of flights within the bin that have an arrival delay of more than 15 minutes and the number of flights with an arrival delay of less than 15 minutes, and then determine which category is higher. The majority vote then becomes our prediction for that entire bin. Because our threshold for decisions is 70% (recall that we want to cancel the meeting if there is a 30% likelihood that the flight will be late), we’ll recommend canceling the meeting for flights that fall into a bin if the fraction of arrival delays of less than 15 minutes is less than 0.7. This method is called _Bayesian classification_, and the statistical model is simple enough that we can build it from scratch with a few lines of code.

The probability that the flight will be late given that the distance _x_`0` is 120 miles and the departure delay `x1` is 8 minutes is called the _conditional probability_,[10](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn119) written as `P(Clate | x0,xi)`. Within each bin, we are calculating the conditional probability `P(Contime | x0, x1)` and `P(Clate | x0, x1)` where `(x0, x1)` is the pair of predictor variables (mileage and departure delay) and `Ck` is one of two classes depending on the value of the arrival delay of the flight. Because the probability of a specific value of a continuous variable is zero, we need to estimate the probability over an interval, and, in this case, the intervals are given by the bins. Thus, to estimate`P(Contime | x0, x1)`, we find the bin that `(x0, x1)` falls into and use that as the estimate of `P(Contime)`. If this is less than 70%, our decision will be to cancel the meeting.

Of all the ways of estimating a conditional probability, the way we are doing it—by divvying up the dataset based on the values of the variables—is the easiest, but it will work only if we have large enough populations in each of the bins. This method of directly computing the probability tables works with two variables, but will it work with 20 variables? How likely is it that there will be enough flights for which the departure airport is TUL, the distance is about 350 miles, the departure delay is about 10 minutes, the taxi-out time is about 4 minutes, and the hour of day that the flight departs is around 7 a.m?

As the number of variables increases, we will need more sophisticated methods in order to estimate the conditional probability. A scalable approach that we can employ if the predictor variables are independent is a method called _Naive Bayes_. In the Naive Bayes approach, we compute the probability tables by taking each variable in isolation (i.e., computing `P(Contime | x0)` and `P(Contime | x1)` separately) and then multiplying them to come up with `P(Ck | xi)`.[11](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn120) However, for just two variables, for a dataset this big, we can get away with binning the data and directly estimating the conditional probability.

### JupyterLab on Cloud Dataproc

Developing the Bayesian classification from scratch requires being able to interactively carry out development. Although we could spin up a Cloud Dataproc cluster, connect to it via SSH, and do development on the Spark read–eval–print loop (REPL), it would be better to use JupyterLab and get a notebook experience similar to how we worked with BigQuery in [Chapter 5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch05.html#interactive\_data\_exploration\_with\_verte).

Among the web interfaces that we enabled with `--enable-component-gateway` was that for JupyterLab. Hence, we can connect to it similar to the way we connected to the HDFS NameNode, from the Google Cloud web console, in the Web Interfaces part of the cluster details section.

In Jupyter, use the File Browser on the left to navigate to _/home/dataproc_ on the local disk and open the notebook _06\_dataproc/quantization.ipynb_ in the clone of the course repository that you find there.

### Independence Check Using BigQuery

Before we can get to computing the proportion of delayed flights in each bin, we need to decide how to quantize the delay and distance. What we do not want are bins with very few flights—in such cases, statistical estimates will be problematic. In fact, if we could somehow spread the data somewhat evenly between bins (using _quantization_), it would be ideal.

For simplicity, we would like to choose the quantization thresholds for distance and for departure delay separately, but we can do this only if they are relatively independent. Let’s verify that this is the case. Cloud Dataproc is integrated with the managed services on Google Cloud Platform, so even though we have our own Hadoop cluster, we can still call out to BigQuery from the notebook that is running on Cloud Dataproc. Using BigQuery, Pandas, and seaborn as we did in [Chapter 5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch05.html#interactive\_data\_exploration\_with\_verte), here’s what the query looks like:

```
sql = """
SELECT DISTANCE, DEP_DELAY
FROM dsongcp.flights_tzcorr
WHERE RAND() < 0.001 AND dep_delay > -20
    AND dep_delay < 30 AND distance < 2000
"""
df = bq.query(sql).to_dataframe()sns.set_style("whitegrid")
g = sns.jointplot(x=df['DISTANCE'], y=df['DEP_DELAY'], kind="hex",
                  height=10, joint_kws={'gridsize':20})
```

The query samples the full dataset, pulling in 1/1,000 of the flights’ distance and departure delay fields (that lie within reasonable ranges) into a Pandas dataframe. This sampled dataset is sent to the seaborn plotting package and a hexbin plot is created. The resulting graph is shown in [Figure 6-3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#the\_hexbin\_plot\_shows\_the\_joint\_distrib).

Each hexagon of a hexagonal bin plot is colored based on the number of flights in that bin, with darker hexagons indicating more flights. It is clear that at any distance, a wide variety of departure delays is possible and for any departure delay, a wide variety of distances is possible. The distribution of distances and departure delays in turn is similar across the board. There is no obvious trend between the two variables—in [Figure 6-3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#the\_hexbin\_plot\_shows\_the\_joint\_distrib), note that the Pearson correlation coefficient is 0.07. This indicates that we can treat the two variables as independent.

The distribution plots at the top and right of the center panel of the graph show how the distance and departure delay values are distributed. This will affect the technique that we can use to carry out quantization. Note that the distance is distributed relatively uniformly until about 1,000 miles, beyond which the number of flights begins to taper off. The departure delay, on the other hand, has a long tail and is clustered around −5 minutes. We might be able to use equispaced bins for the distance variable (at least in the 0- to 1,000-mile range), but for the departure delay variable, our bin size must be adaptive to the distribution of flights. In particular, our bin size must be wide in the tail areas and relatively narrow where there are lots of points.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0603.png" alt="" height="590" width="600"><figcaption></figcaption></figure>

**Figure 6-3. The hexbin plot shows the joint distribution of departure delay and the distance flown. You can use such a plot to verify whether the fields in question are independent.**

There is one issue with the hexbin plot in [Figure 6-3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#the\_hexbin\_plot\_shows\_the\_joint\_distrib): we have used data that we are not allowed to use. Recall that our model must be developed using only the training data. While we used it only for some light exploration, it is better to be systematic about excluding days that will be part of our evaluation dataset from all model development. To do that, we need to join with the `traindays` table and retain only days for which `is_train_day` is `True`. We could do that in BigQuery, but even though Cloud Dataproc is integrated with other Google Cloud Platform services, invoking BigQuery from a Hadoop cluster feels like a cop-out. So, let’s try to recreate the same plot as before, but this time using Spark SQL, and this time using only the training data.

### Spark SQL in JupyterLab

A Spark session can be created by typing the following into a code cell:

```
from pyspark.sql import SparkSession
spark = SparkSession \
    .builder \
    .appName("Bayes classification using Spark") \
    .getOrCreate()
```

With the `spark` variable in hand, we can read in the time-corrected JavaScript Object Notation (JSON) files that we wrote to Google Cloud Storage in [Chapter 4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch04.html#streaming\_data\_publication\_and\_ingest):

```
inputs = 'gs://{}/flights/tzcorr/all_flights-*'.format(BUCKET))
flights = spark.read.json(inputs)
```

Even though we do want to ultimately read all the flights and create our model from all of the data, we will find that development goes faster if we read a fraction of the dataset. So, let’s change the input from `all_flights-*` to `all_flights-00000-*`:

```
inputs = 'gs://{}/flights/tzcorr/all_flights-00000-*'.format(BUCKET))
```

Because I had 26 JSON files, doing this change means that I will be processing just the first file, and we will notice an increase in speed of 26 times during development. Of course, we should not draw any conclusions from processing such a small sample other than that the code works as intended.[12](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn121) After the code has been developed on 4% of the data, we’ll change the string so as to process all the data and increase the cluster size so that this is also done in a timely manner. Doing development on a small sample on a small cluster ensures that we are not underutilizing a huge cluster of machines while we are developing the code.

With the flights dataframe created as shown previously, we can employ SQL on the dataframe by creating a temporary view (it is available only within this Spark session):

```
flights.createOrReplaceTempView('flights')
```

Now, we can employ SQL to query the `flights` view, for example by doing this:

```
results = spark.sql('SELECT COUNT(*) FROM flights WHERE dep_delay >
-20 AND distance < 2000')
results.show()
```

On my development subset, this yields the following result:

```
+--------+
|count(1)|
+--------+
|  59665 |
+--------+
```

This is just about right to comfortably fit in memory, but even if it were somewhat larger I dare not go any smaller than 2%–3% of the data, even in development.

To create the `traindays` dataframe, we can follow the same steps, but for a CSV file this time:

<pre><code>traindays = spark.read \
<strong>    .option("header", "true") \
</strong><strong>    .option("inferSchema", "true") \
</strong>    .csv('gs://{}/flights/trainday.csv'.format(BUCKET))
traindays.createOrReplaceTempView('traindays')
</code></pre>

A quick check illustrates that `traindays` has been read, and the column names and types are correct:

```
results = spark.sql('SELECT * FROM traindays')
results.head(5)
```

This yields the following:

```
[Row(FL_DATE='2015-01-01', is_train_day=True),
 Row(FL_DATE='2015-01-02', is_train_day=False),
 Row(FL_DATE='2015-01-03', is_train_day=False),
 Row(FL_DATE='2015-01-04', is_train_day=True),
 Row(FL_DATE='2015-01-05', is_train_day=True)]
```

To restrict the `flights` dataframe to contain only training days, we can do a SQL join:

<pre><code>statement = """
SELECT
  f.FL_DATE AS date,
  CAST(distance AS FLOAT) AS distance,
  dep_delay,
  IF(arr_delay &#x3C; 15, 1, 0) AS ontime
FROM flights f
<strong>JOIN traindays t
</strong><strong>ON f.FL_DATE == t.FL_DATE
</strong>WHERE
  t.is_train_day AND
  f.dep_delay IS NOT NULL
ORDER BY
  f.dep_delay DESC
"""
flights = spark.sql(statement)
</code></pre>

Now, we can use the `flights` dataframe for the hexbin plots after clipping the x-axis and y-axis to reasonable limits:

```
df = flights[(flights['distance'] < 2000) & \
    (flights['dep_delay'] > -20) & \
    (flights['dep_delay'] < 30)]
```

When we drew the hexbin plot in the previous section, we sampled the data to 1/1,000, but that was because we were passing in a Pandas dataframe to seaborn. This sampling was done so that the Pandas dataframe would fit into memory. However, whereas a Pandas dataframe must fit into memory, a Spark dataframe does not. As of this writing (i.e., December 2021), though, there is no way to directly plot a Spark dataframe either—you must convert it to a Pandas dataframe; therefore, we will still need to sample it, at least when we are processing the full dataset.

Because there are about 50,000 rows on 1/25 of the data, we expect the full dataset to have about 6 million rows. Let’s sample this down to about 100,000 records, which would be about 0.02 of the dataset:

<pre><code><strong>pdf = df.sample(False, 0.02, 20).toPandas()
</strong>g = sns.jointplot(x=pdf['distance'], y=pdf['dep_delay'], kind="hex",
                  height=10, joint_kws={'gridsize':20})
</code></pre>

This yields a hexbin plot that is not very different from the one we ended up with in the previous section. The conclusion—that we need to create adaptive-width bins for quantization—still applies. Just to be sure, though, this is the point at which I’d repeat the analysis on the entire dataset to ensure our deductions are correct had I done only the Spark analysis. However, we did do it on the entire dataset in BigQuery, so let’s move on to creating adaptive bins.

### Histogram Equalization

To choose the quantization thresholds for the departure delay and the distance in an adaptive way (wider thresholds in the tails and narrower thresholds where there are a lot of flights), we will adopt a technique from image processing called _histogram equalization_.[13](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn122)

Low-contrast digital images have histograms of their pixel values distributed such that most of the pixels lie in a narrow range. Take, for example, the photograph in [Figure 6-4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#original\_photograph\_of\_the\_pyramids\_of).[14](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn123)

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0604.png" alt="" height="400" width="600"><figcaption></figcaption></figure>

**Figure 6-4. Original photograph of the pyramids of Giza used to demonstrate histogram equalization.**

As depicted in [Figure 6-5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#histogram\_of\_pixel\_values\_in\_photograph), the histogram of pixel values in the Pyramids image is clustered around two points: the dark pixels in the shade, and the bright pixels in the sun.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0605.png" alt="" height="170" width="522"><figcaption></figcaption></figure>

**Figure 6-5. Histogram of pixel values in photograph of the pyramids.**

Let’s remap the pixel values such that the full spectrum of values is present in the image, so that the new histogram looks like that shown in [Figure 6-6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#histogram\_of\_pixels\_after\_remapping\_the).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0606.png" alt="" height="170" width="518"><figcaption></figcaption></figure>

**Figure 6-6. Histogram of pixels after remapping the pixels to occupy the full range.**

The remapping is of pixel values and has no spatial component. For example, all pixel values of 125 in the old image might be changed to a pixel value of 5 in the new image regardless of where they are in terms of horizontal and vertical position. [Figure 6-7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#note\_that\_after\_the\_histogram\_equalizat) presents the remapped image.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0607.png" alt="" height="400" width="600"><figcaption></figcaption></figure>

**Figure 6-7. Note that after the histogram equalization, the contrast in the image is enhanced.**

What we implicitly did was to remap the pixel values, such that each section of the spectrum from black to white now has approximately the same number of pixels (whereas previously they were all in the gray middle). Histogram equalization has helped to enhance the contrast in the image and bring out finer details. Look, for example, at the difference in the rendering of the sand in front of the pyramid or of the detail of the midsection of Khafre’s pyramid (the tall one in the middle).[15](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn124)

How is this relevant to what we want to do? We are also looking to remap values when we seek to find quantization intervals. In the image case, the output had the same range as the input. But in our flight example, we’d like to remap a distance value of 422 miles to a quantized value of perhaps 3. As in histogram equalization, we want the bin values to be uniformly distributed. We can, therefore, apply the same technique as is employed in the image processing filter to achieve this.

What we want to do is to divide the spectrum of distance values into, say, five bins. The first bin will contain all values in \[0, `d0`), the second will contain values in \[`d0`, `d1`], and so on, until the last bin contains values in \[`d4`, ∞). Histogram equalization requires that `d0`, `d1`, and so on be such that the number of flights in each bin is approximately equal—that is, for the data to be uniformly distributed after quantization. As in the example photograph of the pyramids, it won’t be perfectly uniform because the input values are also discrete. However, the goal is to get as close to an equalized histogram as possible.

With histogram equalization, at any specific departure delay, the number of flights at each distance and delay bin should remain large enough that our conclusions are statistically valid. Assuming independence and 6 million total flights, if we divvy up the data into 100 bins (10 bins per variable), we will have about 60,000 flights in each bin. That’s probably still okay, but let’s be safe and divvy up the data into just five bins each. Divvying up the data into five bins implies a probability range of 0, 0.2, ..., 0.8 or five probabilistic thresholds:

```
np.arange(0, 1.0, 0.2)
```

Finding thresholds that make the two quantized variables uniformly distributed is quite straightforward using the approximate quantiles method discussed in [Chapter 5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch05.html#interactive\_data\_exploration\_with\_verte). There is an `approxQuantile()` method available on the Spark dataframe also:

```
distthresh = flights.approxQuantile('distance',
                   list(np.arange(0, 1.0, 0.2)), 0.02)
delaythresh = flights.approxQuantile('dep_delay',
                   list(np.arange(0, 1.0, 0.2)), 0.02)
```

On the development dataset, here’s what the distance thresholds turn out to be:

```
[130.0, 370.0, 621.0, 1009.0]
```

The zeroth percentile is essentially the minimum. The next ones are the 25th percentile, median, and 75th percentile. In order to have have all bin boundaries, we can tack on infinity at the end:

```
distthresh[-1] = float('inf')
```

Other than setting the policy (histogram equalization), we don’t need to be in the business of choosing distance thresholds. This automation is important because it allows us to dynamically update thresholds if necessary on the most recent data,[16](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn125) taking care to use the same set of thresholds in prediction as was used in training.

We can similarly quantize the departure delay thresholds into equal boundaries, and we get:

```
[-22.0, -5.0, -3.0, 0.0, inf]
```

Unfortunately, this variable is not as well-behaved as the distance—more than 75% of flights depart on-time or early, so the really interesting delayed departures are all hidden in the last bin. This is going to be a problem that we will fix shortly.

## Bayesian Classification

Now that we have the quantization thresholds, what we need to do is find out the recommendation (whether to cancel the meeting) for each bin based on whether 70% of flights in that bin are on time or not.

### Bayes in Each Bin

We can find the flights that belong to the `m`th distance bin and `n`th delay bin by slicing the full set of flights:

```
bdf = flights[(flights['distance'] >= distthresh[m])
             & (flights['distance'] < distthresh[m+1])
             & (flights['dep_delay'] >= delaythresh[n])
             & (flights['dep_delay'] < delaythresh[n+1])]
```

Once we do that, we can compute the fraction of flights that arrive on time for this bin:

```
ontime_frac = (bdf.agg(F.sum('ontime')).collect()[0][0] /
               bdf.agg(F.count('ontime')).collect()[0][0])
```

Looping through the first on-time fractions for the first few bins, we immediately notice a problem:

<pre><code>m n ontime_frac
0 0 0.9853403141361257                                                                               
0 1 0.9847756410256411
0 2 0.9753028890959925
<strong>0 3 0.6346045989904655
</strong>1 0 0.9721913236929922
1 1 0.9650856389986825
1 2 0.9711299153807864
<strong>1 3 0.5715380684721513
</strong></code></pre>

The on-time fraction is nearly 100% for all the delay bins except the largest value for `n`. This makes perfect sense because only the last departure delay bin has any delayed flights.

We’ll have to fix this—one way to do so is to hand-select the departure delay bins. Because we already looked at thresholding the departure delay in [Chapter 3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch03.html#creating\_compelling\_dashboards), we know that the interesting range is between 10 and 20 minutes and that departure delays are reported in integer minutes. So, we simply need to try delay variables of 10, 11, 12, …, 20 minutes.

So, let’s change the delay thresholds and look at them in increments of one minute:

```
delaythresh = range(10, 20)
```

To find the delay threshold for each distance threshold where the value is closest to the 0.70 decision boundary (see _quantization.ipynb_ in the GitHub repository):

```
df['score'] = abs(df['frac_ontime'] - 0.7)
bayes = (df.sort_values(['score']).groupby('dist_thresh')
         .head(1).sort_values('dist_thresh'))
```

The resulting model is a _lookup table_ that consists of a delay threshold for each distance bin:

| `Distance bin` | `delay_thresh` |
| -------------- | -------------- |
| `[130, 370]`   | `17`           |
| `[370, 621]`   | `13`           |
| `[621, 1009]`  | `17`           |
| `[1009, inf]`  | `18`           |

If the departure delay is greater than the threshold corresponding to how far the flight is, then we will cancel the meeting because we expect the flight to be late. We are finding the delay beyond which we need to cancel flights for each distance and saving just that threshold. This makes it quite easy to productionize the model—just write out the preceding table as a CSV file, perhaps, and ask the developer of the application to apply the appropriate threshold based on the lookup table.

For example, what is the appropriate decision for a flight with a distance of 800 miles that departs 16 minutes late? The flight falls into the \[621, 1009] bin. For such flights, we need to cancel the meeting only if the flight departs 17 or more minutes late—a shorter departure delay is something that can be made up en route.

### Evaluating the Model

How well does this model do? To evaluate the model, we have to look at flights that were not used in creating the model. The held-out days are obtained by looking for:

```
t.is_train_day == 'False'
```

We can compute the contingency table values for any given bin using:

```
SELECT
ROUND(SUM(IF(dep_delay < {2:f} AND arr_delay < 15, 1, 0))/COUNT(*), 2)    
         AS correct_nocancel,
ROUND(SUM(IF(dep_delay >= {2:f} AND arr_delay < 15, 1, 0))/COUNT(*), 2) 
         AS false_positive,
ROUND(SUM(IF(dep_delay < {2:f} AND arr_delay >= 15, 1, 0))/COUNT(*), 2) 
         AS false_negative,
ROUND(SUM(IF(dep_delay >={2:f} AND arr_delay >= 15, 1, 0))/COUNT(*), 2)
         AS correct_cancel,
COUNT(*) AS total_flights
FROM flights f
JOIN traindays t
ON f.FL_DATE == t.FL_DATE
WHERE
  t.is_train_day == 'False' AND
  f.distance >= {0:f} AND f.distance < {1:f}
""".format( distthresh[m], distthresh[m+1], 
            bayes[ 
              bayes['dist_thresh'] == distthresh[m] 
            ]['delay_thresh'].values[0] ) 
```

When I did this, I got the results shown in [Figure 6-8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#results\_of\_evaluating\_the\_bayes\_modeldo). We can not put too much stock in this model, though, because it was trained on just 1/25 of the data. Let’s fix that next.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0608.png" alt="" height="287" width="600"><figcaption></figcaption></figure>

**Figure 6-8. Results of evaluating the Bayes model.**

### Dynamically Resizing Clusters

The thresholds in the previous section have been computed on about 1/25 of the data (recall that our input was only one shard: `all-flights-00000-of-*`). So, we should find the actual thresholds that we will want to use by repeating the processing on all of the training data at hand. To do this in a timely manner, we will also want to increase our cluster size. Fortunately, we don’t need to bring down our Cloud Dataproc cluster in order to add more nodes.

Let’s add machines to the cluster so that it has 20 workers, 15 of which are _secondary_ and so are heavily discounted in price:[17](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn126)

```
gcloud dataproc clusters update ch6cluster\
   --num-secondary-workers=15 --num-workers=5 --region=us-central1
```

The secondary machines are preemptible. These machines are provided by Google Cloud Platform at a large (fixed) discount to standard Google Compute Engine instances in return for users’ flexibility in allowing the machines to be taken away at very short notice.[18](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn127) They are particularly helpful on Hadoop workloads because Hadoop is fault-tolerant and can deal with machine failure—it will simply reschedule those jobs on the machines that remain available. Using preemptible machines on your jobs is a frugal choice—here, the five standard workers are sufficient to finish the task in a reasonable time. However, the availability of 15 more machines means that our task could be completed four times faster and much more inexpensively than if we have only standard machines in our cluster.[19](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn128)

We can navigate to the Google Cloud Platform console in a web browser and check that our cluster now has 20 workers, as illustrated in [Figure 6-9](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#the\_cluster\_now\_has\_twozero\_workersdot).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0609.png" alt="" height="224" width="600"><figcaption></figcaption></figure>

**Figure 6-9. The cluster now has 20 workers.**

Now, go to the JupyterLab Notebook and change the input variable to process the full dataset. Next, in the JupyterLab Notebook, click Kernel > “Restart Kernel and Clear All Outputs” to avoid mistakenly using a value corresponding to the development dataset. Then, click on Run > “Run all Cells.”

All the graphs and charts are updated. After we have the results, we can resize the cluster back to something smaller so that we are not wasting cluster resources:

```
gcloud dataproc clusters update ch6cluster\
   --num-secondary-workers=0 --num-workers=2
```

On the full dataset, the lookup table is:

| `Distance bin` | `delay_thresh` |
| -------------- | -------------- |
| `[31, 328]`    | `14`           |
| `[328, 541]`   | `15`           |
| `[541, 802]`   | `15`           |
| `[802, inf]`   | `17`           |

Note that the thresholds changed (the quantiles are different once we add the remaining 95% of information). The delay threshold also changes quite smoothly as the distance increases. The behavior matches our intuition that we can be tolerant of longer delays on longer flights.

### Comparing to Single Threshold Model

Yes, but is this better than the single, universal threshold that we used in [Chapter 5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch05.html#interactive\_data\_exploration\_with\_verte)? How well does this new two-variable model perform? We can modify the evaluation BigQuery query from [Chapter 5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch05.html#interactive\_data\_exploration\_with\_verte) to add in a distance criterion and supply the appropriate threshold for that distance:

<pre><code>SELECT
<strong>  SUM(IF(DEP_DELAY = 14
</strong>      AND arr_delay &#x3C; 15,
      1,
      0)) AS wrong_cancel,
  SUM(IF(DEP_DELAY = 14
      AND arr_delay >= 15,
      1,
      0)) AS correct_cancel
  FROM (
    SELECT
      DEP_DELAY,
      ARR_DELAY
    FROM
      dsongcp.flights_tzcorr f
    JOIN
      dsongcp.trainday t
    ON
      f.FL_DATE = t.FL_DATE
    WHERE
      t.is_train_day = 'False'
<strong>      AND f.DISTANCE &#x3C; 328)
</strong></code></pre>

In this query, 14 minutes is the newly determined threshold for distances under 328 miles and the `WHERE` clause is now limited to flights over distances of less than 328 miles. The result is:

| `Row` | `wrong_cancel` | `correct_cancel` |   |
| ----- | -------------- | ---------------- | - |
| `1`   | `1244`         | `582`            |   |

This indicates that we cancel meetings when it is correct to do so 582 / (582 + 1,244) or 32% of the time—remember that our goal was 30%. Similarly, we can do the other four distance categories. Both with this model and with a model that took into account only the departure delay (as in [Chapter 5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch05.html#interactive\_data\_exploration\_with\_verte)), we are able to get reliable predictions—canceling meetings when the flight has more than a 30% chance of being delayed.

When we have two models that perform equally well on the primary metric, it is possible that we can see if they differ on a secondary metric that also matters to us. Even if two models have the same reliability (of 30%), a model that allows us to achieve that reliability while canceling fewer meetings would be preferable. Or perhaps there is a certain category of meetings that are more important than others. The more complex model is worthwhile if we end up canceling fewer important meetings or if we can be more fine-grained in our decisions (i.e., change which meetings we cancel). If our secondary metric is the total number of meetings canceled, we can compute the sum of `correct_cancel` and `wrong_cancel` over all flights. In the case of using only the departure delay variable, we used a threshold of 16 minutes, and we would have canceled 270k meetings. How about now? Let’s look at the total number of flights in the test set that would cause us to cancel our meetings:

<pre><code>SELECT
<strong>  SUM(IF(DEP_DELAY >= 14 AND DISTANCE &#x3C; 328, 1, 0)) +
</strong><strong>  SUM(IF(DEP_DELAY >= 15 AND DISTANCE >= 328 AND DISTANCE &#x3C; 541, 1, 0)) +
</strong>  SUM(IF(DEP_DELAY >= 15 AND DISTANCE >= 541 AND DISTANCE &#x3C; 802, 1, 0)) +
  SUM(IF(DEP_DELAY >= 17 AND DISTANCE >= 802, 1, 0))
  AS cancel
FROM (
  SELECT
    DEP_DELAY,
    ARR_DELAY,
    DISTANCE
  FROM
    dsongcp.flights_tzcorr f
  JOIN
    dsongcp.trainday t
  ON
    f.FL_DATE = t.FL_DATE
  WHERE
<strong>    t.is_train_day = 'False')
</strong></code></pre>

This turns out to be 275k. It appears, then, that our simpler univariate model got us pretty much the same results as this more complex model using two variables.[20](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn129) However, the decision surfaces are different—in the single-variable threshold, we cancel meetings whenever the flight is delayed by 16 minutes or more. However, when we take into account distance, we cancel more meetings corresponding to shorter flights (threshold is now 14–15 minutes) and cancel fewer meetings corresponding to longer flights (threshold is now 17 minutes). One reason to use this two-variable Bayes model over the one-variable threshold determined empirically is to make such finer-grained decisions. This might or might not be important—it comes down to whether longer flights are typically those corresponding to more important meetings.

Why did we not get an improvement in the number of canceled meetings? Perhaps the round-off in the delay variables (they are rounded off to the nearest minute) has hurt our ability to locate more precise thresholds. Also, maybe the extra variable would have helped if I’d used a more sophisticated model—direct evaluation of conditional probability on relatively coarse-grained quantization bins is a very simple method. In [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml), we explore a more complex approach.

## Orchestration

So far, in this chapter, we have developed and run the Spark jobs interactively. Once you have done so, you will want to operationalize the job and run it routinely. Although you can productionize a Jupyter Notebook using tools such as [Papermill](https://oreil.ly/t05D8), I recommend that you convert the code into a Python program that you can execute in a standalone way.

Although you can just copy-paste the code cells out of a Jupyter Notebook into a Python file, a more systematic way is to convert the Jupyter Notebook to a Python program using a tool called [nbconvert](https://oreil.ly/U50EE). After that, we can do minor editing to get rid of the display cells (such as plotting the hexbin plots). The Python program corresponding to the Jupyter Notebook that we’ve developed so far is in the GitHub repository as _bayes\_in\_spark.py_.

### Submitting a Spark Job

We already have a Dataproc cluster that we have been using during development—our Jupyter Notebook is running on a Dataproc cluster. We can submit our Python program to this cluster from Cloud Shell:

```
gcloud dataproc jobs submit pyspark \
   --cluster ch6cluster --region $REGION \
   bayes_in_spark.py \
   -- \
   --bucket $BUCKET --debug  
```

This is the approach you’d take if you have an already running cluster and wish to submit Spark jobs to it. However, this will require ensuring that the cluster has enough resources to handle your job. If you happen to submit your job at the same time as some other team that is already utilizing the cluster, your job might run very slowly. The solution for this problem is to use job-specific clusters.

### Workflow Template

I recommend that you create ephemeral clusters, run jobs on them, and then delete them when you are done. Instead of doing them manually, you can automate it using a _workflow template_:

```
TEMPLATE=ch6eph
MACHINE_TYPE=n1-standard-4
CLUSTER=ch6eph

gcloud dataproc --quiet workflow-templates create $TEMPLATE 
  
```

The first step of the template will be to create a cluster of the appropriate size and set it to be a managed cluster so that it gets deleted once all the steps in the template are complete:

<pre><code><strong>gcloud dataproc workflow-templates set-managed-cluster $TEMPLATE \
</strong>    --master-machine-type $MACHINE_TYPE \
    --worker-machine-type $MACHINE_TYPE \
    --initialization-actions $STARTUP_SCRIPT \
    --num-preemptible-workers=3 --num-workers 2 \
    --image-version 2.0 \
    --cluster-name $CLUSTER
</code></pre>

Then, you can add jobs to the template. For example, to run a Pig program, we’d do:

```
gcloud dataproc workflow-templates add-job \
  pig gs://$BUCKET/bayes_final.pig \
  --step-id create-report \
  --workflow-template $TEMPLATE \
  -- --bucket=$BUCKET
```

Finally, instantiate the template to run the jobs and delete the cluster once done:

```
gcloud dataproc workflow-templates instantiate $TEMPLATE
```

One key change that we have to make to our program is to ensure that the output of the Spark program goes to a Cloud Storage location (rather than a local file on disk) because the cluster will be deleted once the job is complete:

```
bayes.to_csv('gs://${BUCKET}/flights/bayes.csv'.format(BUCKET), 
              index=False)
```

### Cloud Composer

If your Dataproc job is part of a larger data pipeline, you will typically write the data pipeline in Apache Airflow. Cloud Composer provides a fully managed experience for Airflow on Google Cloud.

Within your Airflow graph, you can [launch the workflow template](https://oreil.ly/tkMHJ) using an Airflow operator:

```
start_template_job = DataprocInstantiateWorkflowTemplateOperator(
        …
    )
```

Your considerations might change, however, if your company owns a Hadoop cluster on premises. In that case, you will submit Spark jobs to that long-lived cluster and will typically be concerned with ensuring that the cluster is not overloaded.

For the scenario in which you own an on-premises cluster, you might want to consider using a public cloud as a spillover in those situations for which there are more jobs than your cluster can handle. You can achieve this by monitoring YARN jobs and sending such spillover jobs to Cloud Dataproc. Cloud Composer provides the necessary plug-ins to be able to do this, but discussing how to set up such a hybrid system is beyond the scope of this book.

### Autoscaling

When we created the workflow template, we specified the number of workers in the cluster. When we were developing the Spark program, we resized the cluster to add workers when we were ready to create the model on the full dataset. In both scenarios, we have to know what size of cluster we need. This can be difficult for new workloads and for spiky jobs.

On a production system, it is possible to tell Dataproc to _autoscale_—the autoscaler monitors the cluster and, when it sees that the machines are getting maxed out, it adds more workers. When it sees machines on the cluster being idle, it shuts down a few workers. To do this, specify an autoscaling policy when creating the Dataproc cluster:

```
gcloud dataproc clusters create ch6cluster \
    --autoscaling-policy=ch6policy \
    …
```

The autoscaling policy is specified in a YAML file with the syntax:

```
workerConfig:
  minInstances: 3
  maxInstances: 10
  weight: 1
secondaryWorkerConfig:
  minInstances: 0
  maxInstances: 20
  weight: 1
basicAlgorithm:
  cooldownPeriod: 2m
  yarnConfig:
    scaleUpFactor: 0.05
    scaleDownFactor: 1.0
    scaleUpMinWorkerFraction: 0.0
    scaleDownMinWorkerFraction: 0.0
    gracefulDecommissionTimeout: 1h
```

Note how the range of the number of primary and secondary workers is specified, as is the rate by which workers are scaled up. Once the autoscaling policy is specified, it is registered using `gcloud`:

```
gcloud dataproc autoscaling-policies import ch6policy \
    --source=filepath/filename.yaml \
    --region=region
```

Then, submit jobs to the cluster as and when you need them to be run:

```
gcloud dataproc jobs submit pyspark \
   --cluster=ch6cluster bayes_final.py \
   -- --bucket=$BUCKET
```

The cluster will be autoscaled based on the resources needed by the job subject to the limits specified in the policy.

### Serverless Spark

However, even autoscaling requires a cluster to be running.

An even better approach would be if we can simply submit a Spark program to a Dataproc service, and the service starts the cluster, runs the job, autoscales it if necessary, and deletes the cluster. We’d like our Spark job to be _serverless_.

To do so, we put the script itself on Cloud Storage:

```
gsutil cp bayes_on_spark.py gs://$BUCKET/
```

and submit the job using `gcloud`:

```
gcloud beta dataproc batches submit pyspark \
   --project=$(gcloud config get-value project) \
   --region=$REGION \
   gs://${BUCKET}/bayes_on_spark.py \
   -- \
   --bucket ${BUCKET} --debug
```

See _submit\_serverless.sh_ in the GitHub repository for details.

Once we do this, Dataproc takes care of all the infrastructure details. It runs our job and puts the lookup table in Cloud Storage. We can see the status of the job and examine its logs using the GCP console (see [Figure 6-10](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#to\_view\_the\_status\_of\_the\_serverless\_sp)).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0610.png" alt="" height="256" width="600"><figcaption></figcaption></figure>

**Figure 6-10. To view the status of the serverless Spark job, visit the Dataproc section of the GCP web console.**

When I did this, I got:

```
dist_thresh,delay_thresh,frac_ontime,score
31.0,14.0,0.6874006359300477,0.012599364069952212
328.0,15.0,0.6958465263550009,0.004153473644999073
544.0,15.0,0.7054307116104869,0.005430711610486916
802.0,17.0,0.6874393150322182,0.012560684967781732
```

This matches the lookup table that we got when we ran the notebook on the full dataset:

| `Distance bin` | `delay_thresh` |
| -------------- | -------------- |
| `[31, 328]`    | `14`           |
| `[328, 541]`   | `15`           |
| `[541, 802]`   | `15`           |
| `[802, inf]`   | `17`           |

Because running the job involves only a single `gcloud` command, it is possible to schedule the Spark program to run every month, or whenever a new month of data is received by updating the Cloud Run and Cloud Scheduler solution that we created in [Chapter 2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch02.html#ingesting\_data\_into\_the\_cloud).

## Summary

In this chapter, we explored how to create a two-variable Bayes model to provide insight as to whether to cancel a meeting based on the likely arrival delay of a flight. We quantized the two variables (distance and departure delay), created a conditional probability lookup table, and examined the on-time arrival percentage in each bin. We carried out the quantization using histogram equalization and on-time arrival percentage computations in Spark.

Upon discovering that equalizing the full distribution of departure delays resulted in a very coarse sampling of the decision surface, we chose to go with the highest possible resolution in the crucial range of departure delay.[21](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn130) However, to ensure that we would have statistically valid groupings, we also made our quantization thresholds coarser in distance. On doing this, we discovered that the probability of the arrival delay being less than 15 minutes varied rather smoothly. Because of this, our conditional probability lookup reduced to a table of thresholds that could be applied cleanly using `IF-THEN` rules.

On evaluating the two-variable model, we found that we would be canceling about the same number of meetings as with the single-variable model while retaining the same overall accuracy. We hypothesize that the improvement isn’t higher because the departure delay variable has already been rounded off to the nearest minute, limiting the scope of any improvement we can make.

In terms of tooling, we created a three-node Cloud Dataproc cluster for development and resized it on the fly to 20 workers when our code was ready to be run on the full dataset. Cloud Dataproc goes a long way toward making this a low-touch endeavor—we saw that it is possible to create and schedule ephemeral jobs because Dataproc provides a serverless experience for Spark. The reason that Dataproc can create, resize, and delete the clusters for our job is that our data is held not in HDFS, but on Google Cloud Storage. We carried out development in JupyterLab, which gives us an interactive notebook experience. We also found that we were able to integrate BigQuery and Spark SQL into our workflow on the Hadoop cluster.

Finally, we converted the notebook into a Python Spark program that can be run routinely in production. We explored different ways of doing this: submitting the Spark to an already running cluster, creating a Workflow template, using Cloud Composer, and running Spark in a serverless way. Of these, serverless Spark involves the least amount of fiddling around with infrastructure. If you can do serverless, do serverless.

## Suggested Resources

The most common reason that organizations use Dataproc today is that they used to have Hadoop clusters on premises. On-premises Hadoop workloads are typically lifted-and-shifted to Dataproc, optimized to take advantage of cloud computing (for example, using ephemeral clusters), and then modernized over time to BigQuery and Dataflow. This [technical guide](https://oreil.ly/2lcEG) steps you through the considerations in moving the data, migrating the jobs, and connecting various types of clients and security tools.

One common question is whether to use Dataflow or Dataproc—both these products support data ingest and data processing. The flowchart in [Figure 6-11](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#choosing\_between\_dataproc\_and\_dataflowd), from the Google Cloud documentation, suggests that this depends on whether you want to use Hadoop tools like Spark.

As the flowchart suggests, the second common reason that organizations use Dataproc is that they wish to have some degree of control over their infrastructure. Perhaps they have tasks that have to be carried out on premises for regulatory reasons. When doing so it is important to adopt [best practices](https://oreil.ly/nOnsX) for storage, compute, and operations. I would add a third consideration here—Dataflow is much better at streaming than any alternative on Hadoop. My colleague Grace Mollison has [collected these flow charts](https://oreil.ly/nyhmH) on her website.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0611.png" alt="" height="489" width="600"><figcaption></figcaption></figure>

**Figure 6-11. Choosing between Dataproc and Dataflow.**

[1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn110-marker) In [Chapter 2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch02.html#ingesting\_data\_into\_the\_cloud), we discussed scaling up, scaling out, and data in situ from the perspective of data center technologies. This background is useful to have here.

[2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn111-marker) See [Slide 6 of Dean and Ghemawat’s original presentation](https://oreil.ly/8EOyd)—the MapReduce architecture they proposed assumes that the cluster has limited bisection bandwidth and local, rather slow drives.

[3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn112-marker) Now, research papers from Google are often accompanied by open source implementations—Kubernetes, Apache Beam, TensorFlow, and Inception are examples.

[4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn113-marker) As discussed in [Chapter 3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch03.html#creating\_compelling\_dashboards), the `gcloud` command makes a REST API call, so this can be done programmatically. You could also use the Google Cloud Platform web console. This command is available in the GitHub repository as _05\_dataproc/create\_cluster.sh_.

[5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn114-marker) To find the name of the staging bucket created by Cloud Dataproc, run `gcloud dataproc clusters describe`.

[6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn115-marker) Hive has been sped up in recent years through the use of a new application framework ([Tez](https://oreil.ly/zHGQP)) and a variety of optimizations for [long-lived queries](https://oreil.ly/T8n0V).

[7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn116-marker) For a tool to estimate costs quickly, go to the [Google Cloud Pricing Calculator](https://oreil.ly/osWqs).

[8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn117-marker) One efficient use of initialization actions is to preinstall all the third-party libraries you might need, so that they don’t have to be submitted with the job. This script is _06\_dataproc/install\_on\_cluster.sh_.

[9](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn118-marker) This script is in the GitHub repository of this book as _06\_dataproc/create\_cluster.sh_.

[10](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn119-marker) For a good, intuitive introduction to conditional probability, see [Statistics How To](https://oreil.ly/gwqcb).

[11](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn120-marker) The exact calculation involves dividing by a scaling factor so that the outcome is the probability. See the [Wikipedia entry on the Naive Bayes classifier](https://oreil.ly/4BdyQ) for more details on the mathematics.

[12](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn121-marker) Just as an example, the Google Cloud Dataflow job that wrote out this code could have ordered the JSON file by date, and in that case, this file will contain only the first 14 days of the year.

[13](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn122-marker) For examples of histogram equalization applied to improve the contrast of images, go to [OpenCV.org](https://oreil.ly/IhYKh).

[14](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn123-marker) Photograph by the author.

[15](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn124-marker) Not the tallest, though. Khufu’s pyramid (the tall pyramid in the forefront) is taller and larger, but has been completely stripped of its alabaster topping and is situated on slightly lower ground.

[16](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn125-marker) If, for example, there is a newfangled technological development that enables pilots to make up time in the air better or, more realistically, if new regulations prompt airline schedulers to start padding their flight-time estimates.

[17](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn126-marker) Trying to increase the number of workers might have you hitting against (soft) quotas on the maximum number of CPUs, drives, or addresses. If you hit any of these soft quotas, request an increase from the Google Cloud Platform console’s [section on Compute Engine quotas](https://oreil.ly/NMXtu). Besides the necessary CPU quota, you may need to ask for an increase in `Persistent Disk` and `In-use IP addresses`. Because a Cloud Dataproc cluster is in a single region, these are _regional_ quotas. See the [documentation on resource quotas in Compute Engine](https://oreil.ly/3KHNQ) for details. In [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml), I had to ask for additional CPUs, and the process of getting a quota increased is explained there as well. If you are in an organization where increasing the quota is a bureaucratic process, ask for the larger quota you will need for [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml) now.

[18](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn127-marker) Less than a minute’s notice as of this writing in December 2021.

[19](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn128-marker) If the preemptible instances cost 20% of a standard machine (as they do as of this writing in December 2021), the 15 extra machines cost us only as much as three standard machines.

[20](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn129-marker) Occam’s razor suggests that we should pick the simpler model whenever its performance is comparable to a more complex model—it costs money and time to collect the data corresponding to additional features and keep them quality-controlled. Famously, although Netflix paid out $1 million to a team that developed a better recommendation algorithm, it also [announced that it had no plans](https://oreil.ly/zDsC9) to put that algorithm into production because of the combination of additional engineering effort and changes to Netflix’s business model. We have to balance this desire for simplicity against the additional expressive power offered by the more complex model. For example, greater granularity might raise interesting questions to get you greater performance later—perhaps we can investigate the reason behind the dip in the second quartile, identify the city pairs driving this degradation, and impose rules that address the scenario.

[21](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#ch01fn130-marker) One-minute increments in the range (10, 20).
