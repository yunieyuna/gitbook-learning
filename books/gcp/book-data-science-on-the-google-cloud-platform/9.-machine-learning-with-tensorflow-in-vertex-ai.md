# 9. Machine Learning With TensorFlow In Vertex AI

## Chapter 9. Machine Learning with TensorFlow in Vertex AI

In [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml), we built a machine learning model in Spark but ran into problems when trying to scale it out and make it operational. We were able to address the scalability challenge by using BigQuery ML in [Chapter 8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#machine\_learning\_with\_bigquery\_ml), but the operationalization challenges still remain. In addition, although BigQuery ML was scalable, we were not able to build the most expressive ML model possible. Briefly, there are four challenges that we identified:

* One-hot encoding of categorical columns caused an explosion in the size of the dataset because of the increased size of the columns. BigQuery ML was able to handle this, but Spark wasn’t.
* Embeddings would have involved special bookkeeping in Spark, and this was not an option in BigQuery ML.
* Putting the model into production requires the machine learning library to be portable to environments beyond the Hadoop cluster or BigQuery data warehouse on which the model is trained.
* Preventing training–serving skew when using a time-windowed aggregate feature requires being able to use the same data preparation code for both historical data (which is batch) and real-time data (which is streaming).

We will solve the fourth problem, of time-windowed aggregates, in [Chapter 11](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch11.html#time\_windowed\_features\_for\_real\_time\_ma) by using Apache Beam and its ability to employ the same code for both batch and stream.

The solution to the first three problems requires a portable machine learning library that is (1) powerful enough to carry out training using accelerators such as GPUs and Tensor Processing Units (TPUs) in a distributed manner, (2) flexible enough to support the latest machine learning research such as wide-and-deep networks,[1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#idm46519165744784) and (3) portable enough to support both massively parallel prediction on custom application-specific integrated circuits (ASICs) and prediction carried out on handheld devices. [TensorFlow](https://tensorflow.org/), the open source machine learning library developed at Google, meets all these objectives.

If you skipped ahead to this chapter without reading Chapters [7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml) and [8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#machine\_learning\_with\_bigquery\_ml), please go back and read them. Those two chapters look at logistic regression using Spark and using BigQuery ML, and I introduce a number of machine learning concepts that are essential to understanding this one. In particular, understanding the limitations of the approaches presented in Chapters [7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml) and [8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#machine\_learning\_with\_bigquery\_ml) will help you to understand the architecture of the TensorFlow/Keras model that we develop here.

All of the code snippets in this chapter are available in the folder [_09\_vertexai_ of the GitHub repository](https://github.com/GoogleCloudPlatform/data-science-on-gcp). See the _README.md_ file in that directory for instructions on how to do the steps described in this chapter.

## Toward More Complex Models

Normally, when you want a computer to do something for you, you need to program the computer to do it by using an explicit set of rules. For example, if you want a computer to look at an image of a screw on a manufacturing line and figure out whether the screw is faulty or not, you need to code up a set of rules: Is the screw bent? Is the screw head broken? Is the screw discolored? With machine learning, you turn the problem around on its head. Instead of coming up with all kinds of logical rules for why a screw might be bad, you show the computer a whole bunch of data. Maybe you show it 5,000 images of good screws and 5,000 images of faulty screws that your (human) operators discarded for one reason or the other. Then, you let the computer learn how to identify a bad screw from a good one. The computer is the “machine” and it’s “learning” to make decisions based on data. In this particular case, the “machine” is learning a discriminant function from the manually labeled training data, which separates _good_ screws from _bad_ screws. This kind of machine learning is called “supervised” because there is a ground truth supplied by an expert—in this analogy, the human quality inspectors function as the supervisors of the machine learning algorithm.

Our approach in Chapters [6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#bayesian\_classifier\_with\_apache\_spark\_o)–[8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#machine\_learning\_with\_bigquery\_ml) involved machine learning. We took all of the data, chose a model (Bayesian classification in [Chapter 6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch06.html#bayesian\_classifier\_with\_apache\_spark\_o), logistic regression in [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml), and boosted tree classification in [Chapter 8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#machine\_learning\_with\_bigquery\_ml)), and asked the computer to figure out the parameters in the model (the empirical probabilities in Bayes, the weights in logistic regression, breakpoints in boosted trees). We then could use the “trained” model to make predictions on new data points.

Even plain old linear regression, in this view, can be thought of as machine learning—that is, if the model is effective at capturing the nuances of the data. Many real-world problems are much more complex than can be adequately captured by linear regression or similarly simple models. When people talk of machine learning, they are usually thinking of more complex models with many more parameters.

Tell a statistician about complex models with lots of parameters, and you’ll get back a lecture on the dangers of overfitting, of building a model that (instead of capturing the nuances of the problem) is simply fitting observation noise in the data. So, another aspect of machine learning is that you need to counteract the dangers of overfitting when using very complex models by training the model on extremely large and highly representative datasets.[2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn161) Additionally, even though these complex models may be more accurate, the trade-off is that you cannot readily analyze them to retroactively derive logical rules and reasoning. When people think of machine learning, they think of complex models like random forests, support vector machines, and neural networks.

For our problem, we could use random forests, support vector machines, or neural networks, and I suspect that we will get very similar results. This is true of many real-world problems—the biggest return for your effort is going to be in terms of finding additional data to provide to the training model or in devising better input features using the available data. In contrast, changing the machine learning model doesn’t provide as much benefit. However, for a specific class of problems—those with extremely dense and highly correlated inputs such as audio and images,[3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn162) deep neural networks begin to shine. In general, you should try to use a linear model if you can and reserve the use of more complex models (deep neural networks, convolutional networks, transformers, recurrent neural networks, etc.) only if the particular problem warrants it. For the flight delay use case, I will use a _wide-and-deep_ model that consists of two parts: a wide or linear part for input features that are sparse and a part consisting of deep layers for input features that are continuous.

To train the model, we will use TensorFlow, an open source software library developed at Google to carry out numerical computation for machine learning research. The guts of the library are written in C++ to permit you to deploy computation to one or more CPUs or GPUs in a desktop or the cloud. Come prediction time, the trained model can be run on CPUs, GPUs, a server that uses Google’s custom ASIC chips for machine learning (called Tensor Processing Units or TPUs), or even a mobile device. However, it is not necessary to program in C++ to use TensorFlow because the programming paradigm is to build a data flow graph and then stream data into that graph. It is possible to control the graph creation and streaming from Python without losing the efficiency of C++, or the ability to do GPU and ASIC computations. Nodes in the graph represent mathematical operations (such as the summation and sigmoid function that we used in logistic regression), whereas the graph edges represent the multidimensional data arrays (tensors) communicated between these nodes.

In fact, we could have expressed logistic regression as a simple neural network consisting of a single node and done the training using TensorFlow rather than Spark, as illustrated in [Figure 9-1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#logistic\_regression\_can\_be\_expressed\_as).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0901.png" alt="" height="223" width="600"><figcaption></figcaption></figure>

**Figure 9-1. Logistic regression can be expressed as a simple neural network with only one node. The X’s are the model inputs (the features) and the W’s are the weights of the model.**

For comparison purposes, the first neural network that we will build in this chapter will be precisely this. We will then be able to examine the impact of the additional input features while keeping the model (logistic regression) the same as what was used in [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml).

Having done the comparison, though, we will move on to building a neural network that will have many more nodes and will be distributed in more layers. We’ll keep the output node a sigmoid so that the output is restricted to lie in \[0,1] but add in intermediate layers and nodes with other activation functions. The number of nodes and layers is something that we must determine via experimentation. At some point, increasing the number of nodes and layers will begin to result in overfitting, and the exact point is dependent on the size of your dataset (both the number of labeled examples and the number of predictor variables), the extent to which the predictor variables do predict the label, and the extent to which the predictors are independent. This problem is hairy enough that there is no real way to know beforehand how big and large you can afford your neural network to be. If your neural network is too small, it won’t fit all the nuances of the problem adequately and your training error will be large. Again, you won’t know that your neural network is too small unless you try a slightly larger neural network. The relationship is not going to be nice and smooth because there are random seeds involved in all the optimization methods that you will use to find the weights and biases. Because of that, machine learning is going to have to involve many, many runs. The best advice is to try out different numbers of nodes and layers and different activation functions (different ones work better for different problems) and see what works well for your problem. Having a cloud platform that supports this sort of experimentation to be carried out on your complete dataset in a timely manner is very important. When it’s time to run our experiment on the full dataset, we will use [Vertex AI](https://oreil.ly/7nHXR).

Every node in a neural network adds up all the weighted inputs and then applies an _activation function_ to the weighted sum. In a classifier, the activation function of the output node is the sigmoid (or s-shaped) function that we saw earlier in logistic regression. For the intermediate layers, we will use Rectified Linear Units (ReLUs)[4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn163) as the activation functions. The ReLU has a linear activation function that is clamped to nonnegative values. Essentially the input of the node is passed through to the output after thresholding it at 0—so if the weighted sum of the inputs is 3, the output is 3, but if the weighted sum of the inputs is −3, the output is 0.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0902.png" alt="" height="235" width="600"><figcaption></figcaption></figure>

**Figure 9-2. A typical neural network node in the intermediate (hidden) layers of a neural network consists of the weighted sum of its inputs transformed by a nonlinear function.**

### Preparing BigQuery Data for TensorFlow

There are four approaches that we can take in order to train a TensorFlow model on data that is in BigQuery:

* Use the BigQuery client library to load the data from BigQuery into an in-memory Pandas dataframe. Then, we can use [`tf.convert_to_tensor`](https://oreil.ly/fmseF) to read the Pandas data frame into TensorFlow. You should use this approach only on datasets that will fit comfortably into memory.
* Use [`BigQueryReader`](https://oreil.ly/XaWF7) to iterate through a BigQuery table (or a subset of it) into a TensorFlow dataset. The BigQueryReader uses BigQuery’s Storage API and is therefore very efficient and can be invoked in parallel if we are doing distributed training. However, the Storage API is not free, and so we will end up paying to read the data each time.[5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn164) Use this for quick experimentation, but this approach can get expensive because training an ML model involves reading data multiple times. Nevertheless, you should use this approach for fast-changing data.
* Export the subset of BigQuery data you need to files on Google Cloud Storage (GCS), and read these files from the ML pipeline.
* Train the model in BigQuery ML using `model_type=dnn_classifier` or `model_type=automl_classifier` and then export the trained model for use in Vertex AI. These model types train a TensorFlow model in Vertex AI. However, you are restricted to the model types supported by BigQuery ML.

I’m going to take the third approach because it is the least expensive option that will work for large datasets and allow me to create a custom TensorFlow model. I will create a temporary table in BigQuery to contain the data we need, export the table to CSV files on Google Cloud Storage, and delete the temporary table (see _flights\_model\_tf2.ipynb_ in the code repository):

```
CREATE OR REPLACE TABLE dsongcp.flights_train_data AS

SELECT
  IF(arr_delay < 15, 1.0, 0.0) AS ontime,
  dep_delay,
  taxi_out,
  distance,
  origin,
  dest,
  EXTRACT(hour FROM dep_time) AS dep_hour,
  IF (EXTRACT(dayofweek FROM dep_time) BETWEEN 2 AND 6, 1, 0) AS is_weekday,
  UNIQUE_CARRIER AS carrier,
  dep_airport_lat,
  dep_airport_lon,
  arr_airport_lat,
  arr_airport_lon
FROM dsongcp.flights_tzcorr f
JOIN dsongcp.trainday t
ON f.FL_DATE = t.FL_DATE
WHERE
  f.CANCELLED = False AND 
  f.DIVERTED = False AND
  is_train_day = 'True'
```

Then, I extract it to a CSV file using:

```
for dataset in "train" "eval" "all"; do
  TABLE=dsongcp.flights_${dataset}_data
  CSV=gs://${BUCKET}/ch9/data/${dataset}.csv
  bq extract --destination_format=CSV $TABLE $CSV
  bq rm -f $TABLE
done
```

Note that my data now includes a few more parameters that I used in the previous chapter. There is one more categorical variable (the airline company, or carrier) and the location of the departure and arrival airports.

Note also that my label is 1.0 if the flight is on time (arrives less than 15 minutes after the scheduled time) and 0.0 if it is not.

### Reading Data into TensorFlow

To read the CSV files from GCS into TensorFlow, we use a method from the `tf.data` package:

```
training_data_uri = 'gs://{}/ch9/data/train*'.format(BUCKET)
dataset = tf.data.experimental.make_csv_dataset(
                 training_data_uri, batch_size=5) 
```

Let’s write a `read_dataset()` function that reads the training data, yielding `batch_size` examples each time, which allows us to stop iterating once a certain number of examples have been read. This is the function that we want:

```
def read_dataset(pattern, batch_size,
                 mode, truncate):
```

The reason for the `mode` parameter is that the function needs to behave differently when reading the training versus when reading the evaluation data. During evaluation, we need to read the entire dataset only once. During training, though, we need to read the dataset and pass it through the model several times. In addition, if we are training on multiple workers, we want the workers to see different examples. We can achieve this by calling `shuffle()` with a large enough buffer. Finally, it’s efficient to prefetch a batch of data using the CPU while the GPU is busy crunching the data. Putting these concepts together, we have:[6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn165)

```
if mode == tf.estimator.ModeKeys.TRAIN:
  dataset = dataset.shuffle(batch_size*10)
  dataset = dataset.repeat()
dataset = dataset.prefetch(1)
if truncate is not None:
  dataset = dataset.take(truncate)
```

Shuffling the order in which the sharded input data is read each time is important for distributed training. The way distributed training is carried out is that each of the workers is assigned a batch of data to process. The workers compute the gradient on their batch and send it to _parameter servers_ that maintain a shared state of the training run.[7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#idm46519166323680) For reasons of fault tolerance, the results from very slow workers might be discarded. If there was a consistently slow worker and the same data was always assigned to the same worker, that data might always be discarded and never used. Therefore, it is important that the same batch of data not be assigned to the same slow worker in each run. Shuffling the data before it gets assigned to each worker helps mitigate this possibility.

The dataset contains all the columns in the CSV file, named according to the header line. The data consists of both features and the label. It’s better to separate them to make the later code easier to read. Hence, we’ll apply a `map()` function to the dictionary and return a tuple of features and labels:

```
def features_and_labels(features):
  label = features.pop('ontime')
  return features, label

dataset = dataset.map(features_and_labels)
```

At this point, a batch that is read will consist of a tuple. The first item of the tuple will be a dictionary of features. The second item of the tuple will be a _tensor_ of labels. (A tensor is just an array of arbitrary dimensions.) Assuming the batch size is 2, the labels tensor will be of shape (2,) as will each of the feature tensors:

<pre><code>[
(OrderedDict([
  ('dep_delay', 
    &#x3C;tf.Tensor: shape=(2,), dtype=int32, 
     numpy=array([-11,   9], dtype=int32)>), 
<strong>  ('taxi_out', 
</strong><strong>    &#x3C;tf.Tensor: shape=(2,), dtype=int32, 
</strong><strong>     numpy=array([10, 10], dtype=int32)>), 
</strong>  … ,
  ('arr_airport_lon', 
    &#x3C;tf.Tensor: shape=(2,), dtype=float32, 
     numpy=array([-149.99806 ,  -72.683334], dtype=float32)>)
]), 
<strong>&#x3C;tf.Tensor: shape=(2,), dtype=int32, 
</strong><strong> numpy=array([1, 1], dtype=int32)>)
</strong>]
</code></pre>

Every time the TensorFlow model needs a new batch of data, it is a tuple like this that it will get.

Now that we have set up the data pipeline, let’s move on to implementing the model itself.

## Training and Evaluation in Keras

Keras is an open source library that simplifies the writing of machine learning models and can work with a variety of backends, including TensorFlow. We first create a Keras model and then call `fit()` on the model to train it, passing it the training dataset. Once the model is trained, we can also call `evaluate()` and `predict()` on the model.

To create a Keras model, we need to specify the inputs, the feature engineering to be performed, the model function, the optimization algorithm, and the evaluation metrics.

### Model Function

In [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml), we built a logistic regression model based on three continuous variables: departure delay, taxi-out time, and distance. We then tried to add one more variable—the origin airport—and because the origin is a categorical variable, it needed to be one-hot encoded. One-hot encoding the origin airport ended up creating more than a hundred new columns, making the model two orders of magnitude more complex. Thus, the addition of this fourth variable caused the Spark ML model to collapse (although BigQuery ML was able to handle this just fine).

Here, let’s build a logistic regression model in Keras, but because we do have many more columns now, let’s use them all. As discussed earlier in this chapter, logistic regression is simply a linear model with a sigmoidal output node:

```
output = tf.keras.layers.Dense(1,
              activation='sigmoid', name='pred')(inputs)
model = tf.keras.Model(inputs, output)
```

The model contains a single layer that is fully connected (dense) to its inputs, has one output, and has a sigmoid activation function.

But how do we get the input layer?

Recall from [Chapter 8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#machine\_learning\_with\_bigquery\_ml) that there is a difference between _inputs_ and _features_—a structured data model takes raw data as input, and then creates new features from those inputs. It’s these features that are actually used by the model for training. So, what we need is to create features from the inputs and pass those features to the model:

<pre><code>inputs = … 
<strong>features = tf.keras.layers.DenseFeatures(…)(inputs)
</strong>
output = tf.keras.layers.Dense(1,
<strong>              activation='sigmoid', name='pred')(features)
</strong>model = tf.keras.Model(inputs, output)
</code></pre>

This is because we cannot pass the input values as-is into the neural network. We will have to convert all the inputs into a single vector of floating point values. The process of converting the raw inputs into floating point values that are amenable to being input into a machine learning model is called _feature engineering_. In Keras, the raw inputs are Input layers, and the conversion is carried out by feature columns and a special layer called `DenseFeatures`. Let’s look at those next.

### Features

We typically create one feature for every column in our tabular data. Keras has support for feature columns, opening up the ability to represent structured data using standard feature engineering techniques like embedding, bucketizing, and feature crosses.

We know that numeric data can be passed in directly to the ML model. So, let’s keep the real-valued columns separate from the _sparse_ (or string) columns:

```
real = {
    colname : numeric_column(colname) 
          for colname in 
            (
                'dep_delay,taxi_out,distance,dep_hour,is_weekday,' +
                'dep_airport_lat,dep_airport_lon,' +
                'arr_airport_lat,arr_airport_lon'
            ).split(',')
}
sparse = {
      'carrier': categorical_column_with_vocabulary_list(
                    'carrier',
                    vocabulary_list=(
                     'AS,VX,F9,UA,US,WN,HA,EV,MQ,DL,OO,B6,NK,AA'
                     .split(','))),
      'origin' : categorical_column_with_hash_bucket(
                   'origin', hash_bucket_size=1000),
      'dest'   : categorical_column_with_hash_bucket(
                   'dest', hash_bucket_size=1000),
}
```

Features that are discrete (and have to be one-hot encoded \[see [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml)]) are represented by `categorical_column`. The airline carrier can be one of the following strings:

```
AS,VX,F9,UA,US,WN,HA,EV,MQ,DL,OO,B6,NK,AA
```

Thus, it is represented by a sparse column with those specific keys. This is called the _vocabulary_ of the column; to find the vocabulary of the carrier codes, I used BigQuery:

```
SELECT
  DISTINCT UNIQUE_CARRIER
FROM
  flights.tzcorr
```

Although I could have done the same thing for the origin and destination airport codes (most likely by saving the airport codes from the BigQuery result set to a file and reading that file from Python), I decided to use a shortcut by mapping the airport codes to hashed buckets; rather than find all the origin airports in the dataset, I ask TensorFlow to create a deterministic hash of the airport code and then discretize the hash number into one thousand buckets (a number larger than the number of unique airports).[8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn166) Provided the hash works as intended, the airports will be uniformly discretized into one thousand bins. For any bucket with only one airport in it, this is equivalent to one-hot encoding. However, there is likely to be some small amount of collision, and so using the hash rather than explicitly specifying the keys will be somewhat worse.

The hashed feature design pattern also helps when the categorical features have an incomplete vocabulary. This will help if a new airport gets built, for example. See _Machine Learning Design Patterns_ by Valliappa Lakshmanan, Sara Robinson, Michael Munn (O’Reilly) for details. Summarized notes from the book are available in a 2021 _Geek Culture_ blog post, [“Data Representation Design Patterns”](https://oreil.ly/5THuF), by Manoj Kumar Patra.

### Inputs

All these features come directly from the input file (and will have to be provided by any client that wants a prediction for a flight). Because the Input layers map 1:1 to the input features and their types, rather than repeat the column names, I can create an Input layer for each of these columns, specifying the right data type (either a float or a string):

<pre><code>inputs = {
    colname : tf.keras.layers.Input(
<strong>          name=colname, shape=(), dtype='float32') 
</strong><strong>          for colname in real.keys()
</strong>}
inputs.update({
    colname : tf.keras.layers.Input(
<strong>          name=colname, shape=(), dtype='string') 
</strong><strong>          for colname in sparse.keys()
</strong>})     
</code></pre>

At this point, we have an Input layer for each of the feature columns in the training data file.

The feature columns are applied to the inputs using `DenseFeatures`, and the resulting features are passed to the subsequent Dense layer:

```
features = tf.keras.layers.DenseFeatures(
    list(sparse) + list(real), name='features')(inputs)

output = tf.keras.layers.Dense(1,
              activation='sigmoid', name='pred')(features)
model = tf.keras.Model(inputs, output)
```

At this point, the model has been created. Let’s move on to training the model.

### Training the Keras Model

Once we have created the Keras model, we can call methods such as `fit()`, `evaluate()`, and `predict()` on the model. The distribution strategy will take care of calling the optimizer for the model in a distributed way (i.e., across several accelerators or across machines) to adjust the weights of the model every time a batch of training examples is read.[9](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn167)

Before we can train the model, though, we have to _compile_ it, specifying the optimizer, the loss metric, and any evaluation metrics that we want to report during training:

```
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
```

Then, we call `fit()` to train the model, passing in the training dataset and the validation dataset on which to report metrics as the model is being trained:

```
train_dataset = read_dataset('gs://…/train*',
                             train_batch_size)
eval_dataset = read_dataset('gs://…/valid*',
                            eval_batch_size,
                            tf.estimator.ModeKeys.EVAL,
                            num_eval_examples)

history = model.fit(train_dataset,
                    validation_data=eval_dataset,
                    epochs=epochs,
                    steps_per_epoch=steps_per_epoch,
                    validation_steps=10)
```

The history object will contain the training loss and evaluation metrics after each epoch. We can plot it using:

```
for idx, key in enumerate(['loss', 'accuracy']):
    ax = fig.add_subplot(nrows, ncols, idx+1)
    plt.plot(history.history[key])
    plt.plot(history.history['val_{}'.format(key)])
    plt.title('model {}'.format(key))
    plt.ylabel(key)
    plt.xlabel('epoch')
    plt.legend(['train', 'validation'], loc='upper left');
```

In [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml), we discussed the need for a metric that is independent of threshold and captures the full spectrum of probabilities. For comparison purposes, therefore, it would be good to also compute the RMSE. We can do this by adding an evaluation metric to the `model` definition:[10](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn168)

```
metrics=['accuracy', rmse]
```

The `rmse()` function is defined as follows:

```
def rmse(y_true, y_pred):
    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))
```

### Saving and Exporting

In order for us to be able to deploy the model to serve requests, we need to save it in a format that can be deployed:

```
export_dir = os.path.join(OUTPUT_DIR,
                          'export/flights_{}'.format(
                          time.strftime("%Y%m%d-%H%M%S")))
tf.saved_model.save(model, export_dir)
```

With all the components in place, we are now ready to run the code.

### Deep Neural Network

Making sure that the Vertex AI Workbench notebook that I’m working on has a GPU attached to it, I can now launch off the training job. The model being trained is a simple one, of course—a linear regression model. Even though I’ve added several new features (carrier, airport locations), the resulting RMSE hasn’t budged from when we did linear regression in BigQuery ML. This is not surprising—there is a limit to the expressiveness of linear models. We should try a more complex model.

What happens if we change our model from a linear model to a deep neural network? In Keras, if we want two hidden layers with 64 and 8 nodes, we would insert a couple of Dense layers that have a `relu` activation function:

<pre><code>features = tf.keras.layers.DenseFeatures(
    list(sparse) + list(real), name='features')(inputs)
<strong>h1 = tf.keras.layers.Dense(
</strong><strong>    64, activation='relu', name='pred')(features)h2 = tf.keras.layers.Dense(
</strong><strong>    8, activation='relu', name='pred')(h1)
</strong>output = tf.keras.layers.Dense(
    1, activation='sigmoid', name='pred')(h2)
model = tf.keras.Model(inputs, output)
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
</code></pre>

In BigQuery ML, we could achieve this by changing the model type:

<pre><code>CREATE OR REPLACE MODEL dsongcp.arr_delay_airports_dnn
OPTIONS(input_label_cols=['ontime'],
<strong>        model_type='dnn_classifier',
</strong><strong>        hidden_units=[64, 8],
</strong></code></pre>

The result with a deep neural network is an RMSE of 0.205, which is not a meaningful difference. But let’s not give up just yet!

Now that we have more data, TensorFlow/Keras in our tool chest, and the ability to train machine learning models on the larger dataset, why not also improve our machine learning modeling?

## Wide-and-Deep Model in Keras

An influential paper suggests using a hybrid model that the authors call a _wide-and-deep model_ on structured data.[11](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#idm46519166214480) In the wide-and-deep model, there are two parts. One part directly connects the inputs to the outputs; in other words, it is a linear model. The other part connects the inputs to the outputs via a deep neural network. The modeler places the sparse columns in the linear part of the model, and the real-valued columns in the deep part of the model.

### Representing Air Traffic Corridors

Recall that we have two Python dictionaries of features: one is a dict of real-valued columns, and the other is a dict of sparse columns. Among the real-valued columns are the latitude and longitude of the departure and arrival airports. The precise latitudes themselves should not have much of an impact on a flight being early or late, but rather the general location of the airport and the flight path between pairs of cities do play a part. For example, flights along the West Coast of the United States are rarely delayed, whereas flights that pass through the high-traffic area between Chicago and New York tend to experience a lot of delays. This is true even if the flight in question does not originate in Chicago or New York.

Indeed, the Federal Aviation Administration in the United States manages airplanes in flight in terms of air traffic corridors or areas (see [Figure 9-3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#air\_traffic\_in\_the\_usa\_is\_managed\_by\_th)). We could make the machine learning problem easier for the model if there were a way to provide this human insight directly, instead of expecting it to be learned directly from the raw latitude and longitude data.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0903.png" alt="" height="391" width="600"><figcaption></figcaption></figure>

**Figure 9-3. Air traffic in the USA is managed by the US Federal Aviation Administration (FAA) in terms of separate traffic corridors, shown here as boxes. Image courtesy FAA.**

### Bucketing

Real-valued columns whose precision is overkill (thus, likely to cause overfitting) can be discretized and made into categorical columns. For example, if we have a column for the age of the aircraft, we might discretize into just three bins—less than 5 years old, 5 to 20 years old, and more than 20 years old.

Even though we could explicitly program in the air traffic corridors, let’s use the discretization shortcut: we can discretize the latitudes and longitudes (the thick arrows in [Figure 9-4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#bucketizing\_latitude\_and\_longitude\_esse)) and cross the buckets—this will result in breaking up the country into grids and yield the grid point into which a specific latitude and longitude falls.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0904.png" alt="" height="546" width="542"><figcaption></figcaption></figure>

**Figure 9-4. Bucketizing latitude and longitude essentially separates out the space into grid boxes.**

The following code takes the real-valued latitude and longitude columns and discretizes them into `nbuckets` each:

```
latbuckets = np.linspace(20.0, 50.0, NBUCKETS).tolist()  # USA
lonbuckets = np.linspace(-120.0, -70.0, NBUCKETS).tolist() # USA
disc = {}
disc.update({
       'd_{}'.format(key) : tf.feature_column.bucketized_column(real[key],
  latbuckets)
          for key in ['dep_lat', 'arr_lat']
})
disc.update({
       'd_{}'.format(key) : tf.feature_column.bucketized_column(real[key],
  lonbuckets)
          for key in ['dep_lon', 'arr_lon']
})
```

The dictionary `disc` at this point contains four discretized columns: `d_dep_lat`, `d_arr_lat`, `d_dep_lon`, and `d_arr_lat`.

### Feature Crossing

Finally, we apply feature crossing to categorical features that work well in combination. As discussed in [Chapter 8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#machine\_learning\_with\_bigquery\_ml), we can think of a feature cross as being an `AND` condition. If you have a column for colors and another column for sizes, the feature cross of colors and sizes will result in sparse columns for color-size combinations such as red-medium.

We can take the discretized columns corresponding to the lats and lons and cross them to create two sparse columns: one for the box within which the departure `lat-lon` falls, and another for the box within which the arrival `lat-lon` falls:

```
sparse['dep_loc'] = tf.feature_column.crossed_column(
     [disc['d_dep_lat'], disc['d_dep_lon']], NBUCKETS*NBUCKETS)
sparse['arr_loc'] = tf.feature_column.crossed_column(
     [disc['d_arr_lat'], disc['d_arr_lon']], NBUCKETS*NBUCKETS)
```

We can also create a feature cross of the pair of departure and arrival grid cells, essentially capturing flights between two boxes. In addition, we can also feature cross the departure and arrival airport codes (e.g., ORD–JFK for flights that leave Chicago’s O’Hare airport and arrive at New York’s John F. Kennedy airport):[12](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn169)

```
sparse['dep_arr'] = tf.feature_column.crossed_column(
      [sparse['dep_loc'], sparse['arr_loc']], NBUCKETS ** 4)
sparse['ori_dest'] = tf.feature_column.crossed_column(
      ['origin', 'dest'], hash_bucket_size=1000)
```

Even though we want to use the sparse columns directly in the linear part of the model, we would also like to perform dimensionality reduction on them and use them in the deep part of the model:

```
embed = {
       'embed_{}'.format(colname) :
           tf.feature_column.embedding_column(col, dimension=10)
               for colname, col in sparse.items()
}
real.update(embed)
```

An embedding is a learnable data representation that maps high-cardinality data (e.g., there are 300 unique airports) to a low-dimensional space (say, 10 dimensions). Unlike one-hot encoding, which would treat all airports as independent, embeddings allow us to capture similarities between airports. For more on the Embedding Design Pattern, please see (you guessed it) the O’Reilly Media book _Machine Learning Design Patterns_.

### Wide-and-Deep Classifier

With the sparse and real feature columns thus enhanced beyond the raw inputs, we can create a `wide_and_deep_classifier` passing in the linear and deep feature columns separately:

```
def wide_and_deep_classifier(inputs,
  linear_feature_columns, dnn_feature_columns, dnn_hidden_units):
    deep = tf.keras.layers.DenseFeatures(
               dnn_feature_columns, name='deep_inputs')(inputs)
    for layerno, numnodes in enumerate(dnn_hidden_units):
        deep = tf.keras.layers.Dense(numnodes,
          activation='relu', name='dnn_{}'.format(layerno+1))(deep)
    wide = tf.keras.layers.DenseFeatures(
          linear_feature_columns, name='wide_inputs')(inputs)
    both = tf.keras.layers.concatenate([deep, wide], name='both')
    output = tf.keras.layers.Dense(
          1, activation='sigmoid', name='pred')(both)
    model = tf.keras.Model(inputs, output)
    model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model
```

The model function that results is shown in [Figure 9-5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#the\_wide\_and\_deep\_keras\_modeldot).

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0905.png" alt="" height="351" width="600"><figcaption></figcaption></figure>

**Figure 9-5. The wide-and-deep Keras model.**

This wide-and-deep model with feature crosses that match human intuition yielded an RMSE of 0.196, which is the best yet.

## Deploying a Trained TensorFlow Model to Vertex AI

Now that we have trained a TensorFlow model and exported it, how do we deploy the model so that any client can get predictions from it? We use Vertex AI, the managed service for training, deploying, monitoring, and orchestrating machine learning models in Google Cloud Platform.

### Concepts

There are a few important concepts here, so refer to [Figure 9-6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#steps\_to\_deploy\_a\_model\_to\_vertex\_aidot) as we go along. The code snippets are in the notebook _flights\_model\_tf2.ipynb_ in the code repository.

<figure><img src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098118945/files/assets/dsg2_0906.png" alt="" height="277" width="600"><figcaption></figcaption></figure>

**Figure 9-6. Steps to deploy a model to Vertex AI.**

The basic idea is that clients access an endpoint. Every endpoint is associated with a URL. The clients send a HTTP `POST` request with a JSON payload that contains the input to the prediction method.

The endpoint contains a number of Vertex AI Model objects among which it splits traffic. [Figure 9-6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#steps\_to\_deploy\_a\_model\_to\_vertex\_aidot) depicts 80% of traffic going to Model 1, 10% to Model 2, and the remainder to Model 3.

A Vertex AI Model is an object that references models built in a wide variety of frameworks (TensorFlow, PyTorch, XGBoost, etc.). There are pre-built container images for each framework. You can also bring in your containers if you are using an ML framework that is not directly supported by Vertex AI.

The TensorFlow container image looks for SavedModel files, the format that Keras/TensorFlow 2.0 models are exported into by default when you call `model.save(…)` or `tf.saved_models.save()` from your training code.

Deploying a model involves uploading the model artifacts to Vertex AI, creating an endpoint, and deploying the model to the endpoint.

### Uploading Model

The first step is to upload the saved model files, specifying the [pre-built Vertex container](https://oreil.ly/3zH67) for your ML framework. Here, I’m using the TensorFlow 2.6 container built for serving using CPUs:

```
CONTAINER=us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest
gcloud ai models upload --region=$REGION \
     --display-name=$MODEL_NAME \
     --container-image-uri=$CONTAINER \
     --artifact-uri=$EXPORT_PATH
```

What’s the `MODEL_NAME`?

I recommend that you use a unique display name for every model (Vertex AI does assign a unique model ID, but it’s an opaque number that is not human readable):

| Name                    | ID                  |
| ----------------------- | ------------------- |
| flights-20211102-064051 | 3935868997391613952 |

An easy way is to append a timestamp to the name that you want to use, so each time you upload a model you have a new name:

```
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
MODEL_NAME=flights-${TIMESTAMP}
```

**BIGQUERY ML MODELS IN VERTEX AI**

BigQuery supports exporting trained models in TensorFlow SavedModel format. Here’s how to export the BigQuery ML model we trained in [Chapter 8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch08.html#machine\_learning\_with\_bigquery\_ml) into a SavedModel:

```
EXPORT_PATH=gs://${BUCKET}/bqml_model_export/
bq extract -m dsongcp.arr_delay_lm $EXPORT_PATH
```

Use the `EXPORT_PATH` as the artifact URI when uploading the model to Vertex AI:

```
CONTAINER=us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest
gcloud ai models upload --region=$REGION \
     --display-name=$MODEL_NAME \
     --container-image-uri=$CONTAINER \
     --artifact-uri=$EXPORT_PATH
```

Nearly all BigQuery ML models—AutoML, DNN, KMeans, Matrix Factorization, PCA, and linear models—[can be exported](https://oreil.ly/ulXJD) in TensorFlow SavedModel format.

The exception is that boosted tree models are written out as _.bst_ files in XGBoost 0.82 format. Fortunately, Vertex AI also provides pre-built containers for XGBoost. All we have to do is to change the container that is being used from the TensorFlow one to the one for XGBoost 0.82:

```
CONTAINER=us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.0-82:latest
```

The rest of the steps remain the same.

### Creating Endpoint

We need a unique name for the endpoint as well, but we will not be creating multiple endpoints. Just one. This is because the URL at which the model predictions can be accessed will be based on the endpoint ID. So you want to reuse the endpoint so that you can update models without breaking existing clients. Therefore, there is no need for a timestamp. Just verify that the endpoint doesn’t exist before you create it:

```
ENDPOINT_NAME=flights
if [[ $(gcloud ai endpoints list --region=$REGION \
  --format='value(DISPLAY_NAME)' --filter=display_name=${ENDPOINT_NAME}) ]]; then
    echo "Endpoint $ENDPOINT_NAME already exists"
else
    # create model
    echo "Creating Endpoint $ENDPOINT_NAME for $MODEL_NAME"
    gcloud ai endpoints create --region=${REGION} --display-name=${ENDPOINT_NAME}
fi
```

### Deploying Model to Endpoint

Now that we have a model and an endpoint, we can deploy the model to the endpoint:

```
gcloud ai endpoints deploy-model $ENDPOINT_ID \
  --region=$REGION \
  --model=$MODEL_ID \
  --display-name=$MODEL_NAME \
  --machine-type=n1-standard-2 \
  --min-replica-count=1 \
  --max-replica-count=1 \
  --traffic-split=0=100
```

Note how I am making sure to specify the traffic split and the machine type I need (I could add GPUs at this point, but I don’t need GPUs to serve predictions for a tabular data model). Because this is the first model, we send 100% of the traffic to this one with:

```
--traffic-split=0=100
```

If we had an older model, we’d specify the relative split between two models. To send 10% of the traffic to this new model and 90% to an older model, we’d do:

```
--traffic-split=0=10,OLD_DEPLOYED_MODEL_ID=90
```

Note that all these commands require the model ID and endpoint ID (not the model name and endpoint name). To get the ID from the name (assuming you are using unique names as I recommended):

```
MODEL_ID=$(gcloud ai models list --region=$REGION \
           --format='value(MODEL_ID)' \
           --filter=display_name=${MODEL_NAME})
ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION \
              --format='value(ENDPOINT_ID)' \
              --filter=display_name=${ENDPOINT_NAME})
```

If necessary, you can get the ID of the most recently deployed model or endpoint by adding a sort:

```
ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION \
              --format='value(ENDPOINT_ID)'\
              --filter=display_name=${ENDPOINT_NAME} \
              --sort-by=creationTimeStamp | tail -1)
```

### Invoking the Deployed Model

Here’s how client programs can invoke the model that we have deployed. Assume that they have the input data in a JSON file called _example\_input.json_:

```
{"instances": [
  {"dep_hour": 2, "is_weekday": 1, "dep_delay": 40, "taxi_out": 17, 
   "distance": 41, "carrier": "AS", "dep_airport_lat": 58.42527778, 
   "dep_airport_lon": -135.7075, "arr_airport_lat": 58.35472222,
   "arr_airport_lon": -134.57472222, "origin": "GST", "dest": "JNU"},
  {"dep_hour": 22, "is_weekday": 0, "dep_delay": -7, "taxi_out": 7, 
   "distance": 201, "carrier": "HA", "dep_airport_lat": 21.97611111, 
   "dep_airport_lon": -159.33888889, "arr_airport_lat": 20.89861111, 
   "arr_airport_lon": -156.43055556, "origin": "LIH", "dest": "OGG"}
]} 
```

They can send an HTTP `POST` request:

```
curl -X POST\
-H "Authorization: Bearer "$(gcloud auth application-default print-access-token)\
-H "Content-Type: application/json; charset=utf-8"\
-d @example_input.json\
"https://...${PROJECT}/locations/${REGION}/endpoints/${ENDPOINT_ID}:predict"
```

Of course, you need to tell them the region, project, and endpoint ID at which the model is deployed. Many times, it’s easier to hide this URL behind a simpler URL that redirects to this. Such a level of indirection also helps with throttling and with charging for each invocation. On Google Cloud, you can do this using [Apigee](https://oreil.ly/cCxSB).

Clients who send the HTTP `POST` request will get the result back as JSON:

```
{
  "predictions": [
    [
      0.228779882
    ],
    [
      0.766132474
    ]
  ],
  "deployedModelId": "2339101036930662400",
  "model": "projects/379218021631/locations/us-central1/models/39358689973916",
  "modelDisplayName": "flights-20211102-064051"
}
```

Of course, it’s a REST API, so you can invoke it from pretty much any language. There are also client API libraries available.

Vertex AI provides a fully managed, autoscaling, serverless environment for machine learning models. You get the benefits of paying for any compute resources (such as CPUs or GPUs) only when you are using them. Because the models are containerized, dependency management is taken care of. The endpoints take care of traffic splits, allowing you to do A/B testing in a convenient way.

The benefits go beyond not having to manage infrastructure. Once your model is deployed to Vertex AI, you get a lot of neat capabilities without any additional code—explainability, drift detection, monitoring, etc.

At this point, we have written the model in Python in a Jupyter Notebook and deployed the model using `gcloud` commands that you can run from a Unix shell. This sort of hybrid language and environment is hard to automate.

Much better would be if we could do it all from plain Python programs—following a clean separation of responsibility between model code and operations code will also make the MLOps teams happy. Let’s look at how to do that next.

## Summary

In this chapter, we extended the machine learning approach that we started in [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml), but using the TensorFlow library instead of Spark MLlib. Realizing that categorical columns result in an explosion of the dataset features, we used TensorFlow to carry out GPU-accelerated training. Another advantage that TensorFlow provides is that its design allows a computer scientist to go as low-level as they need to, and so many machine learning research innovations are implemented in TensorFlow. As machine learning practitioners, therefore, using TensorFlow allows us to use innovative machine learning research soon after it is published rather than wait for a reimplementation in some other framework. Finally, using TensorFlow allows us to deploy the model rather easily into our data pipelines regardless of where they are run because TensorFlow is portable across a wide variety of hardware platforms.

We trained a logistic regression model on all of the input values and learned that the model was unable to effectively use the new features like airport locations.

We discussed that, intuitively, the nodes in a deep neural network help provide decision hyperplanes, and that successive layers help to combine individual hyperplanes into more complex decision surfaces. Using a deep neural network instead of logistic regression didn’t provide any benefit with our inputs, though. However, bringing in human insight in the form of additional features that bucketed some of the continuous features, creating feature crosses, and using a wide-and-deep model yielded a further reduction in the RMSE. We deployed this model and invoked it using REST APIs to do online prediction.

## Suggested Resources

The most important skill in machine learning is being able to formulate the problem in such a way that ML can be successful at solving it. That is the focus of the course [“Managing Machine Learning Projects with Google Cloud”](https://oreil.ly/q2Dme) by Google Cloud Training on Coursera.

To learn more about being an ML practitioner, check out these books:

* [_Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) by Aurélien Géron (O’Reilly).
* [_Machine Learning Design Patterns_](https://www.oreilly.com/library/view/machine-learning-design/9781098115777/) by Lakshmanan, Robinson, and Munn (O’Reilly).

The [Vertex AI samples GitHub repository](https://oreil.ly/wMNeD) is a gold mine of examples.

[1](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#idm46519165744784-marker) Heng-Tze Cheng et al., “Wide & Deep Learning for Recommender Systems,” arXiv, June 24, 2016. https://arxiv.org/abs/1606.07792.

[2](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn161-marker) If you come from a statistics background, training a machine learning model is the same thing as fitting a statistical model or function to data.

[3](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn162-marker) In this context, _dense_ inputs are those where small differences in numeric values are meaningful—that is, where the inputs are continuous numbers.

[4](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn163-marker) Using ReLU rather than sigmoidal (or tanh) activation functions is a trade-off—the sigmoid activation function saturates between 0 and 1 (see the graphs in [Chapter 7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch07.html#logistic\_regression\_using\_spark\_ml)), and therefore the output won’t blow up. However—and this is where the trade-off comes in—the outputs of neurons with ReLU activation functions can reach really large, positive magnitudes. Some of the theoretical advances in machine learning over the past few years have been on how to initialize and train ReLUs without having the intermediate outputs of the neural network go flying off the handle.

[5](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn164-marker) As opposed to the approaches in #1 and #3 where we query the data only once.

[6](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn165-marker) I encourage you to read [_Machine Learning Design Patterns_](https://www.oreilly.com/library/view/machine-learning-design/9781098115777/) by Valliappa Lakshmanan, Sara Robinson, and Michael Munn (O’Reilly) for many tips on applying ML in real-world scenarios.

[7](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#idm46519166323680-marker) Mu Li et al., “Scaling Distributed Machine Learning with the Parameter Server,” Operating Systems Design and Implementation (OSDI), USENIX (2014): 583–98. https://research.google.com/pubs/pub44634.html.

[8](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn166-marker) A _hash function_ is a function that maps input values as evenly as possible over its output range. Python has a built-in hash function called `hash()` that returns an integer—it is common to override the `hash()` function in classes to take into account some unique combination of attributes (called the keys) of the object.

[9](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn167-marker) The default option—`MirroredStrategy`—works for zero or more GPUs on a single machine. Since that’s what I’m doing, you will not see the strategy referenced explicitly in the code.

[10](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn168-marker) See the full context on [GitHub](https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/main/10\_mlops/model.py).

[11](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#idm46519166214480-marker) Heng-Tze Cheng et al., “Wide & Deep Learning for Recommender Systems.”

[12](https://learning.oreilly.com/library/view/data-science-on/9781098118945/ch09.html#ch01fn169-marker) If we feature cross the airports as categorical variables, what extra information could there be in the categorical variable that is the feature cross between the departure box and the arrival box? Answer: feature crossing the airports gives us the precise airport pair, whereas feature crossing the boxes gives us general neighborhoods. Thus, the latter helps us treat all airports in Alaska or New York City similarly.
